[0m21:17:17.225239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8262B0260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E828A771A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E828A75A00>]}


============================== 21:17:17.229889 | 3e0b6fd0-b5ae-4b48-a5e5-f0332a9402b3 ==============================
[0m21:17:17.229889 [info ] [MainThread]: Running with dbt=1.10.13
[0m21:17:17.230917 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'write_json': 'True', 'invocation_command': 'dbt debug', 'profiles_dir': 'C:\\Users\\gboct\\.dbt', 'printer_width': '80', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m21:17:17.252342 [info ] [MainThread]: dbt version: 1.10.13
[0m21:17:17.253342 [info ] [MainThread]: python version: 3.12.10
[0m21:17:17.253342 [info ] [MainThread]: python path: D:\Projects\DBT_TUTORIAL\.venv\Scripts\python.exe
[0m21:17:17.253342 [info ] [MainThread]: os info: Windows-11-10.0.26200-SP0
[0m21:17:18.129246 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:17:18.130244 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:17:18.130244 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:17:18.817713 [info ] [MainThread]: Using profiles dir at C:\Users\gboct\.dbt
[0m21:17:18.817713 [info ] [MainThread]: Using profiles.yml file at C:\Users\gboct\.dbt\profiles.yml
[0m21:17:18.818712 [info ] [MainThread]: Using dbt_project.yml file at D:\Projects\DBT_TUTORIAL\octy_dbt_learn\dbt_project.yml
[0m21:17:18.818712 [info ] [MainThread]: adapter type: databricks
[0m21:17:18.818712 [info ] [MainThread]: adapter version: 1.10.14
[0m21:17:18.911621 [info ] [MainThread]: Configuration:
[0m21:17:18.912622 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:17:18.912622 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:17:18.913647 [info ] [MainThread]: Required dependencies:
[0m21:17:18.913647 [debug] [MainThread]: Executing "git --help"
[0m21:17:18.944775 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:17:18.944775 [debug] [MainThread]: STDERR: "b''"
[0m21:17:18.944775 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:17:18.945775 [info ] [MainThread]: Connection:
[0m21:17:18.945775 [info ] [MainThread]:   host: dbc-fac7b9b8-bbb6.cloud.databricks.com
[0m21:17:18.946776 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/d365070b8a419a3d
[0m21:17:18.947281 [info ] [MainThread]:   catalog: dbt_tutorial_dev
[0m21:17:18.947281 [info ] [MainThread]:   schema: default
[0m21:17:18.948291 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m21:17:19.242793 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m21:17:19.242793 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m21:17:19.242793 [debug] [MainThread]: Using databricks connection "debug"
[0m21:17:19.242793 [debug] [MainThread]: On debug: select 1 as id
[0m21:17:19.243792 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:17:19.472779 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0af7b-ba85-1c6c-8aaa-c50ea86e47e3) - Created
[0m21:17:19.858224 [debug] [MainThread]: SQL status: OK in 0.610 seconds
[0m21:17:19.859224 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f0af7b-ba85-1c6c-8aaa-c50ea86e47e3, command-id=01f0af7b-ba93-1738-ac93-cc28abe6639d) - Closing
[0m21:17:19.860224 [debug] [MainThread]: On debug: Close
[0m21:17:19.860224 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0af7b-ba85-1c6c-8aaa-c50ea86e47e3) - Closing
[0m21:17:19.938914 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:17:19.939915 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:17:19.940912 [debug] [MainThread]: Command `dbt debug` succeeded at 21:17:19.940912 after 2.91 seconds
[0m21:17:19.940912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8290EBBF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E828E877D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E828E86450>]}
[0m21:17:19.941911 [debug] [MainThread]: Flushing usage events
[0m21:17:20.558146 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:23:39.895268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CE675220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CB9D0E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CDEF1A30>]}


============================== 21:23:39.899269 | 646e5dd5-65e1-451b-a08a-41397af0e123 ==============================
[0m21:23:39.899269 [info ] [MainThread]: Running with dbt=1.10.13
[0m21:23:39.899269 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt ', 'target_path': 'None', 'profiles_dir': 'C:\\Users\\gboct\\.dbt', 'printer_width': '80', 'no_print': 'None', 'warn_error': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_path': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m21:23:40.024909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '646e5dd5-65e1-451b-a08a-41397af0e123', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CE319130>]}
[0m21:23:40.158501 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:23:40.159501 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:23:40.159501 [debug] [MainThread]: Command `cli deps` succeeded at 21:23:40.159501 after 0.38 seconds
[0m21:23:40.161009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CE319130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CEBB8BC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000244CFFA6360>]}
[0m21:23:40.161009 [debug] [MainThread]: Flushing usage events
[0m21:23:41.202315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:38:02.067071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B1DD6840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B1DD6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B16A6CF0>]}


============================== 22:38:02.070072 | 3feb7a1d-ef20-498c-9d37-a334f2ee0406 ==============================
[0m22:38:02.070072 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:38:02.071072 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'write_json': 'True'}
[0m22:38:02.932597 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:38:02.932597 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:38:02.933598 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:38:04.023719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D542AEA0>]}
[0m22:38:04.080382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D53011F0>]}
[0m22:38:04.081383 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m22:38:04.445911 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:38:04.571991 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:38:04.571991 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:38:04.606566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D4985430>]}
[0m22:38:04.675534 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m22:38:04.689763 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m22:38:04.720863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5A593D0>]}
[0m22:38:04.720863 [info ] [MainThread]: Found 6 models, 6 sources, 699 macros
[0m22:38:04.722015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5A828A0>]}
[0m22:38:04.723524 [info ] [MainThread]: 
[0m22:38:04.723524 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:38:04.724534 [info ] [MainThread]: 
[0m22:38:04.724534 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:38:04.725533 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:38:04.731036 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m22:38:04.732043 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m22:38:04.743593 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m22:38:04.744098 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m22:38:04.744098 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:38:04.985120 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af87-02a3-1b24-8daf-911a746b955f) - Created
[0m22:38:05.615973 [debug] [ThreadPool]: SQL status: OK in 0.870 seconds
[0m22:38:05.620070 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af87-02a3-1b24-8daf-911a746b955f, command-id=01f0af87-02b0-113b-ac0f-b8f551e54d9b) - Closing
[0m22:38:05.621094 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m22:38:05.621094 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af87-02a3-1b24-8daf-911a746b955f) - Closing
[0m22:38:05.698892 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_default) - Creating connection
[0m22:38:05.699892 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_default'
[0m22:38:05.709439 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_default"
[0m22:38:05.710439 [debug] [ThreadPool]: On list_dbt_tutorial_dev_default: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'default'

  
[0m22:38:05.710439 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:38:05.901919 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af87-032f-1d1b-b0f2-83d16f25cff3) - Created
[0m22:38:06.613769 [debug] [ThreadPool]: SQL status: OK in 0.900 seconds
[0m22:38:06.616281 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af87-032f-1d1b-b0f2-83d16f25cff3, command-id=01f0af87-033d-1170-a632-711dfe2f5cb4) - Closing
[0m22:38:06.616281 [debug] [ThreadPool]: On list_dbt_tutorial_dev_default: Close
[0m22:38:06.616281 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af87-032f-1d1b-b0f2-83d16f25cff3) - Closing
[0m22:38:06.695860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291AF3D8140>]}
[0m22:38:06.729918 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m22:38:06.731331 [info ] [Thread-1 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m22:38:06.731839 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m22:38:06.732847 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m22:38:06.732847 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m22:38:06.740353 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m22:38:06.743857 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m22:38:06.759768 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:06.760769 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m22:38:06.760769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5B1A9F0>]}
[0m22:38:06.802537 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m22:38:06.803538 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m22:38:06.804730 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m22:38:06.804730 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:06.999631 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-03d9-1d9f-b69d-1ffd558ca4e2) - Created
[0m22:38:10.475036 [debug] [Thread-1 (]: SQL status: OK in 3.670 seconds
[0m22:38:10.476035 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-03d9-1d9f-b69d-1ffd558ca4e2, command-id=01f0af87-03e3-1a8b-af09-450078f2daf4) - Closing
[0m22:38:10.488545 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:10.503948 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m22:38:10.504955 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-03d9-1d9f-b69d-1ffd558ca4e2) - Closing
[0m22:38:10.590163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291AF304620>]}
[0m22:38:10.591164 [info ] [Thread-1 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 3.85s]
[0m22:38:10.592163 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m22:38:10.592163 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m22:38:10.593667 [info ] [Thread-1 (]: 2 of 6 START sql table model default.bronze_date ............................... [RUN]
[0m22:38:10.593667 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m22:38:10.594683 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m22:38:10.594683 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m22:38:10.597683 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m22:38:10.601683 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m22:38:10.603732 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:10.605737 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m22:38:10.606739 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m22:38:10.606739 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  
[0m22:38:10.606739 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:10.827353 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-061f-1df9-9a2e-1db98c875029) - Created
[0m22:38:13.507660 [debug] [Thread-1 (]: SQL status: OK in 2.900 seconds
[0m22:38:13.508661 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-061f-1df9-9a2e-1db98c875029, command-id=01f0af87-062a-1d2e-9c6e-1e2ec521b5b3) - Closing
[0m22:38:13.509662 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:13.510663 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m22:38:13.512061 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-061f-1df9-9a2e-1db98c875029) - Closing
[0m22:38:13.589949 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5A89E50>]}
[0m22:38:13.590950 [info ] [Thread-1 (]: 2 of 6 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 3.00s]
[0m22:38:13.591953 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m22:38:13.591953 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m22:38:13.592953 [info ] [Thread-1 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m22:38:13.593951 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m22:38:13.593951 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m22:38:13.593951 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m22:38:13.599440 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m22:38:13.600492 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m22:38:13.603621 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:13.604674 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m22:38:13.605673 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m22:38:13.606674 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  
[0m22:38:13.607675 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:13.804758 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-07e8-14ac-b8ca-448e2b06fd2f) - Created
[0m22:38:16.431239 [debug] [Thread-1 (]: SQL status: OK in 2.820 seconds
[0m22:38:16.432301 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-07e8-14ac-b8ca-448e2b06fd2f, command-id=01f0af87-07f2-11a4-bf4f-9f0ddb409299) - Closing
[0m22:38:16.433806 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:16.434827 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m22:38:16.435842 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-07e8-14ac-b8ca-448e2b06fd2f) - Closing
[0m22:38:16.515869 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5B71FA0>]}
[0m22:38:16.516865 [info ] [Thread-1 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 2.92s]
[0m22:38:16.516865 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m22:38:16.518329 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m22:38:16.519320 [info ] [Thread-1 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m22:38:16.519320 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m22:38:16.520411 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m22:38:16.520411 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m22:38:16.525481 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m22:38:16.528554 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m22:38:16.531625 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:16.532624 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m22:38:16.533624 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m22:38:16.533624 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m22:38:16.535047 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:16.733623 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-09a7-1bc0-86bb-82404ae3bf83) - Created
[0m22:38:19.354037 [debug] [Thread-1 (]: SQL status: OK in 2.820 seconds
[0m22:38:19.355067 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-09a7-1bc0-86bb-82404ae3bf83, command-id=01f0af87-09b0-1f63-9023-18001d846780) - Closing
[0m22:38:19.356102 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:19.357546 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m22:38:19.357546 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-09a7-1bc0-86bb-82404ae3bf83) - Closing
[0m22:38:19.427412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5B9BF20>]}
[0m22:38:19.428463 [info ] [Thread-1 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 2.91s]
[0m22:38:19.429477 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m22:38:19.430478 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m22:38:19.430478 [info ] [Thread-1 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m22:38:19.431475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m22:38:19.431475 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m22:38:19.431475 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m22:38:19.437644 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m22:38:19.438656 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m22:38:19.441672 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:19.443596 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m22:38:19.445142 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m22:38:19.445142 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  
[0m22:38:19.445142 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:19.630452 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-0b60-142d-b786-fde916e9f5b2) - Created
[0m22:38:22.147362 [debug] [Thread-1 (]: SQL status: OK in 2.700 seconds
[0m22:38:22.148362 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-0b60-142d-b786-fde916e9f5b2, command-id=01f0af87-0b6a-1231-84d0-fbf1bebb85a1) - Closing
[0m22:38:22.149362 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:22.151361 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m22:38:22.151361 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-0b60-142d-b786-fde916e9f5b2) - Closing
[0m22:38:22.231354 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5B65610>]}
[0m22:38:22.232370 [info ] [Thread-1 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 2.80s]
[0m22:38:22.232370 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m22:38:22.232370 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m22:38:22.233875 [info ] [Thread-1 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m22:38:22.234883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m22:38:22.235882 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m22:38:22.235882 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m22:38:22.240882 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m22:38:22.246940 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m22:38:22.251207 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:38:22.253207 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m22:38:22.254207 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m22:38:22.255410 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m22:38:22.255410 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:38:22.464231 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-0d0f-1c2a-b82b-b033aa6d6209) - Created
[0m22:38:24.990641 [debug] [Thread-1 (]: SQL status: OK in 2.740 seconds
[0m22:38:24.992676 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af87-0d0f-1c2a-b82b-b033aa6d6209, command-id=01f0af87-0d1a-17a5-9406-5ea107e23dbf) - Closing
[0m22:38:24.992676 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:38:24.995187 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m22:38:24.995187 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af87-0d0f-1c2a-b82b-b033aa6d6209) - Closing
[0m22:38:25.060631 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3feb7a1d-ef20-498c-9d37-a334f2ee0406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5B28590>]}
[0m22:38:25.061630 [info ] [Thread-1 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 2.83s]
[0m22:38:25.062685 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m22:38:25.064211 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:38:25.064211 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:38:25.065749 [info ] [MainThread]: 
[0m22:38:25.065749 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 20.34 seconds (20.34s).
[0m22:38:25.067827 [debug] [MainThread]: Command end result
[0m22:38:25.205463 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m22:38:25.207712 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m22:38:25.214258 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m22:38:25.215265 [info ] [MainThread]: 
[0m22:38:25.215265 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:38:25.216273 [info ] [MainThread]: 
[0m22:38:25.216273 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m22:38:25.217271 [debug] [MainThread]: Command `dbt run` succeeded at 22:38:25.217271 after 23.32 seconds
[0m22:38:25.217271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B21BFCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B1A5BBF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291D5835F40>]}
[0m22:38:25.218513 [debug] [MainThread]: Flushing usage events
[0m22:38:25.986980 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:44:50.366585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEACA8380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEB36FDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEB36DBE0>]}


============================== 22:44:50.370624 | b146ad9d-21e4-4b33-81ea-075172fe6e15 ==============================
[0m22:44:50.370624 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:44:50.371772 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'write_json': 'True', 'cache_selected_only': 'False', 'no_print': 'None', 'invocation_command': 'dbt clean', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m22:44:50.484524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b146ad9d-21e4-4b33-81ea-075172fe6e15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BE8C85520>]}
[0m22:44:50.514235 [debug] [MainThread]: Command `dbt clean` succeeded at 22:44:50.514235 after 0.31 seconds
[0m22:44:50.515426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEB5C1D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEB781850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BEBC37080>]}
[0m22:44:50.515426 [debug] [MainThread]: Flushing usage events
[0m22:44:51.174818 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:53:13.439041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC8112BA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC819FBEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC81CE0C20>]}


============================== 22:53:13.443041 | 0fb7907a-02ce-419b-88b1-96b9cef1eb36 ==============================
[0m22:53:13.443041 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:53:13.444038 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'invocation_command': 'dbt run', 'no_print': 'None', 'write_json': 'True', 'log_format': 'default', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m22:53:14.222601 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:53:14.223598 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:53:14.223598 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:53:14.888157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC8155F8C0>]}
[0m22:53:14.945340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA5224440>]}
[0m22:53:14.946339 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m22:53:15.258484 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:53:15.387497 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:53:15.388001 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:53:15.418113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC821C7AD0>]}
[0m22:53:15.486111 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m22:53:15.489150 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m22:53:15.498075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA57CC590>]}
[0m22:53:15.498075 [info ] [MainThread]: Found 6 models, 6 sources, 699 macros
[0m22:53:15.499080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA4F64830>]}
[0m22:53:15.501200 [info ] [MainThread]: 
[0m22:53:15.501200 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:53:15.501200 [info ] [MainThread]: 
[0m22:53:15.502259 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:53:15.502259 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:53:15.508128 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m22:53:15.509167 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m22:53:15.519975 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m22:53:15.519975 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m22:53:15.520975 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:15.923445 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af89-218d-1bed-9c6c-ccd7a30b59e3) - Created
[0m22:53:30.222797 [debug] [ThreadPool]: SQL status: OK in 14.700 seconds
[0m22:53:30.226798 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af89-218d-1bed-9c6c-ccd7a30b59e3, command-id=01f0af89-21a8-1195-ba61-6bc16eeff748) - Closing
[0m22:53:30.499174 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m22:53:30.500181 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af89-218d-1bed-9c6c-ccd7a30b59e3) - Closing
[0m22:53:30.596707 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_default) - Creating connection
[0m22:53:30.597710 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_default'
[0m22:53:30.604760 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_default"
[0m22:53:30.605762 [debug] [ThreadPool]: On list_dbt_tutorial_dev_default: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'default'

  
[0m22:53:30.605762 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:30.829848 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af89-2a7a-15a7-aab3-e50fcd11dc6c) - Created
[0m22:53:37.766532 [debug] [ThreadPool]: SQL status: OK in 7.160 seconds
[0m22:53:37.769035 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af89-2a7a-15a7-aab3-e50fcd11dc6c, command-id=01f0af89-2a89-1249-bc92-22fb1c72fd1e) - Closing
[0m22:53:37.915001 [debug] [ThreadPool]: On list_dbt_tutorial_dev_default: Close
[0m22:53:37.915001 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af89-2a7a-15a7-aab3-e50fcd11dc6c) - Closing
[0m22:53:37.985012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCFF128230>]}
[0m22:53:37.988516 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m22:53:37.988516 [info ] [Thread-1 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m22:53:37.989549 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m22:53:37.989549 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m22:53:37.990554 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m22:53:37.998557 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m22:53:38.001827 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m22:53:38.018528 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:53:38.019535 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m22:53:38.019535 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA5884380>]}
[0m22:53:38.071981 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m22:53:38.072979 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m22:53:38.073982 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m22:53:38.074982 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:38.275873 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-2eeb-1a8d-8ffd-503986fbfde2) - Created
[0m22:53:47.132170 [debug] [Thread-1 (]: SQL status: OK in 9.060 seconds
[0m22:53:47.133965 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-2eeb-1a8d-8ffd-503986fbfde2, command-id=01f0af89-2ef6-1657-9a27-8d1698c372e5) - Closing
[0m22:53:47.246534 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:53:47.261857 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m22:53:47.262857 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-2eeb-1a8d-8ffd-503986fbfde2) - Closing
[0m22:53:47.348164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC814E11C0>]}
[0m22:53:47.349165 [info ] [Thread-1 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 9.36s]
[0m22:53:47.349165 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m22:53:47.349165 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m22:53:47.351577 [info ] [Thread-1 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m22:53:47.351577 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m22:53:47.351577 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m22:53:47.352891 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m22:53:47.354888 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m22:53:47.355888 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m22:53:47.370145 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m22:53:47.375413 [debug] [Thread-1 (]: Dropping relation `dbt_tutorial_dev`.`default`.`bronze_date` because it is of type table
[0m22:53:47.382009 [debug] [Thread-1 (]: Applying DROP to: `dbt_tutorial_dev`.`default`.`bronze_date`
[0m22:53:47.387008 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m22:53:47.387008 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */
drop table if exists `dbt_tutorial_dev`.`default`.`bronze_date`
[0m22:53:47.387008 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:47.613209 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-347b-101b-a123-0467cafb351a) - Created
[0m22:53:48.542084 [debug] [Thread-1 (]: SQL status: OK in 1.150 seconds
[0m22:53:48.542084 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-347b-101b-a123-0467cafb351a, command-id=01f0af89-3487-1a75-a3cc-764375d5e8c3) - Closing
[0m22:53:48.551641 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`default`.`bronze_date`
[0m22:53:48.552640 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m22:53:48.553640 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m22:53:48.553640 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`default`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m22:53:49.248748 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m22:53:49.250312 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-347b-101b-a123-0467cafb351a, command-id=01f0af89-3517-144a-a36e-ffb5a7f9505c) - Closing
[0m22:53:49.250312 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:53:49.251421 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m22:53:49.251421 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-347b-101b-a123-0467cafb351a) - Closing
[0m22:53:49.336635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA320E8A0>]}
[0m22:53:49.337640 [info ] [Thread-1 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 1.99s]
[0m22:53:49.337640 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m22:53:49.339144 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m22:53:49.339144 [info ] [Thread-1 (]: 3 of 6 START sql view model default.bronze_product ............................. [RUN]
[0m22:53:49.339690 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m22:53:49.340708 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m22:53:49.340708 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m22:53:49.343716 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m22:53:49.344716 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m22:53:49.345856 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m22:53:49.346903 [debug] [Thread-1 (]: Dropping relation `dbt_tutorial_dev`.`default`.`bronze_product` because it is of type table
[0m22:53:49.349409 [debug] [Thread-1 (]: Applying DROP to: `dbt_tutorial_dev`.`default`.`bronze_product`
[0m22:53:49.350411 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m22:53:49.350411 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */
drop table if exists `dbt_tutorial_dev`.`default`.`bronze_product`
[0m22:53:49.350411 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:49.535336 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-35a1-1e73-b95c-187eb20416af) - Created
[0m22:53:50.022100 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m22:53:50.023101 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-35a1-1e73-b95c-187eb20416af, command-id=01f0af89-35ac-1aec-a06d-81ebd0b76650) - Closing
[0m22:53:50.023101 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`default`.`bronze_product`
[0m22:53:50.024101 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m22:53:50.025100 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m22:53:50.025100 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`default`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m22:53:50.675955 [debug] [Thread-1 (]: SQL status: OK in 0.650 seconds
[0m22:53:50.676956 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-35a1-1e73-b95c-187eb20416af, command-id=01f0af89-35f8-1d8a-817a-04c54c5955b0) - Closing
[0m22:53:50.677999 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:53:50.679230 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m22:53:50.679230 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-35a1-1e73-b95c-187eb20416af) - Closing
[0m22:53:50.755059 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA584FAA0>]}
[0m22:53:50.755059 [info ] [Thread-1 (]: 3 of 6 OK created sql view model default.bronze_product ........................ [[32mOK[0m in 1.42s]
[0m22:53:50.756059 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m22:53:50.757061 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m22:53:50.757061 [info ] [Thread-1 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m22:53:50.758060 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m22:53:50.758060 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m22:53:50.758060 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m22:53:50.764338 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m22:53:50.765339 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m22:53:50.767365 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:53:50.769875 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m22:53:50.769875 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m22:53:50.770880 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m22:53:50.770880 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:50.939869 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-367a-19d1-b98b-ed3c38ec8aa0) - Created
[0m22:53:54.182273 [debug] [Thread-1 (]: SQL status: OK in 3.410 seconds
[0m22:53:54.183271 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-367a-19d1-b98b-ed3c38ec8aa0, command-id=01f0af89-3682-1ad5-bec8-1d7cb97cb11a) - Closing
[0m22:53:54.184270 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:53:54.185270 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m22:53:54.185270 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-367a-19d1-b98b-ed3c38ec8aa0) - Closing
[0m22:53:54.256430 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA591E5A0>]}
[0m22:53:54.257430 [info ] [Thread-1 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 3.50s]
[0m22:53:54.257430 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m22:53:54.258934 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m22:53:54.258934 [info ] [Thread-1 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m22:53:54.259940 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m22:53:54.259940 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m22:53:54.260940 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m22:53:54.263941 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m22:53:54.263941 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m22:53:54.266941 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:53:54.267942 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m22:53:54.268943 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m22:53:54.268943 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  
[0m22:53:54.269987 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:54.476642 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-3893-13eb-8ef6-3bb31c3d126a) - Created
[0m22:53:57.932691 [debug] [Thread-1 (]: SQL status: OK in 3.660 seconds
[0m22:53:57.934475 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-3893-13eb-8ef6-3bb31c3d126a, command-id=01f0af89-389e-1b56-94b3-90fcf830b358) - Closing
[0m22:53:57.935010 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:53:57.936610 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m22:53:57.937147 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-3893-13eb-8ef6-3bb31c3d126a) - Closing
[0m22:53:58.008296 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA56BEDB0>]}
[0m22:53:58.008296 [info ] [Thread-1 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 3.75s]
[0m22:53:58.009295 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m22:53:58.010324 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m22:53:58.010324 [info ] [Thread-1 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m22:53:58.011324 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m22:53:58.011324 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m22:53:58.012324 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m22:53:58.016325 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m22:53:58.019321 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m22:53:58.022423 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m22:53:58.023425 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m22:53:58.037461 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m22:53:58.037461 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m22:53:58.038461 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:53:58.219329 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-3ad0-1c15-a79a-6b399313ddf4) - Created
[0m22:54:01.082223 [debug] [Thread-1 (]: SQL status: OK in 3.040 seconds
[0m22:54:01.083223 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af89-3ad0-1c15-a79a-6b399313ddf4, command-id=01f0af89-3ada-146e-80c6-3be80814d73f) - Closing
[0m22:54:01.084223 [debug] [Thread-1 (]: Applying tags to relation None
[0m22:54:01.085223 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m22:54:01.085223 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af89-3ad0-1c15-a79a-6b399313ddf4) - Closing
[0m22:54:01.163321 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb7907a-02ce-419b-88b1-96b9cef1eb36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA5913470>]}
[0m22:54:01.164324 [info ] [Thread-1 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.15s]
[0m22:54:01.165325 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m22:54:01.166319 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:54:01.166319 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:54:01.167543 [info ] [MainThread]: 
[0m22:54:01.167543 [info ] [MainThread]: Finished running 4 table models, 2 view models in 0 hours 0 minutes and 45.67 seconds (45.67s).
[0m22:54:01.169047 [debug] [MainThread]: Command end result
[0m22:54:01.196034 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m22:54:01.198377 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m22:54:01.206087 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m22:54:01.207166 [info ] [MainThread]: 
[0m22:54:01.207166 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:54:01.208225 [info ] [MainThread]: 
[0m22:54:01.208225 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m22:54:01.209223 [debug] [MainThread]: Command `dbt run` succeeded at 22:54:01.209223 after 47.93 seconds
[0m22:54:01.209223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC81A3ADE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCA51C39B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC80FE1C10>]}
[0m22:54:01.209223 [debug] [MainThread]: Flushing usage events
[0m22:54:01.914557 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:05:36.115989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC5286540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC5285910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC52873B0>]}


============================== 23:05:36.119508 | d6acd92f-db14-4739-82c1-02bde20a192a ==============================
[0m23:05:36.119508 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:05:36.120509 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'invocation_command': 'dbt run', 'no_print': 'None', 'target_path': 'None', 'printer_width': '80', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m23:05:36.920553 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:05:36.920553 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:05:36.920553 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:05:37.579135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC27B52E0>]}
[0m23:05:37.635350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC5930110>]}
[0m23:05:37.635350 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m23:05:37.952324 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:05:38.080461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:05:38.081463 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:05:38.087975 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m23:05:38.114034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8A64980>]}
[0m23:05:38.182431 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:05:38.184434 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:05:38.193950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8EA94F0>]}
[0m23:05:38.193950 [info ] [MainThread]: Found 6 models, 6 sources, 700 macros
[0m23:05:38.193950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8ED46B0>]}
[0m23:05:38.195949 [info ] [MainThread]: 
[0m23:05:38.196952 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:05:38.196952 [info ] [MainThread]: 
[0m23:05:38.196952 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:05:38.197991 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:05:38.204286 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m23:05:38.204286 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m23:05:38.215405 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m23:05:38.215405 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m23:05:38.216915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:38.778732 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-dc3e-17c2-9649-6d83e36abeb4) - Created
[0m23:05:55.247402 [debug] [ThreadPool]: SQL status: OK in 17.030 seconds
[0m23:05:55.251464 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8a-dc3e-17c2-9649-6d83e36abeb4, command-id=01f0af8a-dc6c-155a-83f5-df7cb3e81af8) - Closing
[0m23:05:55.454186 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m23:05:55.454186 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-dc3e-17c2-9649-6d83e36abeb4) - Closing
[0m23:05:55.537236 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_dev_bronze) - Creating connection
[0m23:05:55.537236 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_dev_bronze'
[0m23:05:55.538373 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_dev"
schema: "bronze"
"
[0m23:05:55.542695 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_dev_bronze"
[0m23:05:55.543736 [debug] [ThreadPool]: On create_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "create_dbt_tutorial_dev_bronze"} */
create schema if not exists `dbt_tutorial_dev`.`bronze`
  
[0m23:05:55.543736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:55.754291 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-e67b-186e-82fd-9e8bdf52ce52) - Created
[0m23:05:57.137496 [debug] [ThreadPool]: SQL status: OK in 1.590 seconds
[0m23:05:57.138834 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8a-e67b-186e-82fd-9e8bdf52ce52, command-id=01f0af8a-e687-129d-bfbf-3829fe2376e7) - Closing
[0m23:05:57.138834 [debug] [ThreadPool]: On create_dbt_tutorial_dev_bronze: Close
[0m23:05:57.138834 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-e67b-186e-82fd-9e8bdf52ce52) - Closing
[0m23:05:57.210558 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m23:05:57.210558 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m23:05:57.217499 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m23:05:57.218888 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m23:05:57.218888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:57.410299 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-e779-1893-a8ff-43ac7d161017) - Created
[0m23:06:02.471875 [debug] [ThreadPool]: SQL status: OK in 5.250 seconds
[0m23:06:02.474037 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8a-e779-1893-a8ff-43ac7d161017, command-id=01f0af8a-e786-1f3e-a8b3-871e4999fcbc) - Closing
[0m23:06:02.475111 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m23:06:02.475111 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8a-e779-1893-a8ff-43ac7d161017) - Closing
[0m23:06:02.546176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC2888350>]}
[0m23:06:02.550837 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m23:06:02.551884 [info ] [Thread-1 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:06:02.551884 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m23:06:02.552985 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m23:06:02.552985 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m23:06:02.560159 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m23:06:02.561160 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m23:06:02.579275 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:06:02.579275 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:06:02.580273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8F8E390>]}
[0m23:06:02.621575 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m23:06:02.622575 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m23:06:02.622575 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m23:06:02.623576 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:02.833727 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-eab4-1215-ad3b-0ec4fee208b4) - Created
[0m23:06:15.044102 [debug] [Thread-1 (]: SQL status: OK in 12.420 seconds
[0m23:06:15.045102 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-eab4-1215-ad3b-0ec4fee208b4, command-id=01f0af8a-eac0-1152-b8fb-6d399ab0ff80) - Closing
[0m23:06:15.216556 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:15.231798 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m23:06:15.231798 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-eab4-1215-ad3b-0ec4fee208b4) - Closing
[0m23:06:15.312759 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC4BCD0A0>]}
[0m23:06:15.313757 [info ] [Thread-1 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 12.76s]
[0m23:06:15.313757 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m23:06:15.314758 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m23:06:15.314758 [info ] [Thread-1 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:06:15.315757 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m23:06:15.315757 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m23:06:15.315757 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m23:06:15.319050 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m23:06:15.320049 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m23:06:15.333180 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:06:15.344362 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m23:06:15.344362 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m23:06:15.345362 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m23:06:15.346365 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m23:06:15.346365 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:15.540910 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f249-188d-83fe-75a18a97fb6c) - Created
[0m23:06:16.382616 [debug] [Thread-1 (]: SQL status: OK in 1.040 seconds
[0m23:06:16.382616 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-f249-188d-83fe-75a18a97fb6c, command-id=01f0af8a-f254-11f6-b26b-20de16dac6b3) - Closing
[0m23:06:16.383716 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:16.384782 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m23:06:16.384782 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f249-188d-83fe-75a18a97fb6c) - Closing
[0m23:06:16.459142 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8F3B290>]}
[0m23:06:16.459142 [info ] [Thread-1 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.14s]
[0m23:06:16.460213 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m23:06:16.460213 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m23:06:16.461277 [info ] [Thread-1 (]: 3 of 6 START sql view model bronze.bronze_product .............................. [RUN]
[0m23:06:16.461277 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m23:06:16.462332 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m23:06:16.462332 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m23:06:16.464702 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m23:06:16.465761 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m23:06:16.467838 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:06:16.467838 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m23:06:16.469444 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m23:06:16.469444 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m23:06:16.470467 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m23:06:16.470467 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:16.653742 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f2f1-1ccd-a799-2f366908beed) - Created
[0m23:06:17.273080 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m23:06:17.274084 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-f2f1-1ccd-a799-2f366908beed, command-id=01f0af8a-f2fd-1296-ad4a-8c147d16ac5d) - Closing
[0m23:06:17.275083 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:17.275083 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m23:06:17.276085 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f2f1-1ccd-a799-2f366908beed) - Closing
[0m23:06:17.354088 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8FD9070>]}
[0m23:06:17.355092 [info ] [Thread-1 (]: 3 of 6 OK created sql view model bronze.bronze_product ......................... [[32mOK[0m in 0.89s]
[0m23:06:17.356089 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m23:06:17.356089 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m23:06:17.357088 [info ] [Thread-1 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m23:06:17.357088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m23:06:17.358087 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m23:06:17.358087 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m23:06:17.361691 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m23:06:17.362766 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m23:06:17.368028 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:06:17.369617 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m23:06:17.370141 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m23:06:17.371193 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m23:06:17.371193 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:17.581760 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f37f-111d-b94e-46b542ca3c84) - Created
[0m23:06:21.042384 [debug] [Thread-1 (]: SQL status: OK in 3.670 seconds
[0m23:06:21.043476 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-f37f-111d-b94e-46b542ca3c84, command-id=01f0af8a-f38b-11fb-aa66-c8aecfa65251) - Closing
[0m23:06:21.043476 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:21.044500 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m23:06:21.045501 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f37f-111d-b94e-46b542ca3c84) - Closing
[0m23:06:21.127097 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8FCF590>]}
[0m23:06:21.127097 [info ] [Thread-1 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 3.77s]
[0m23:06:21.128098 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m23:06:21.128098 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m23:06:21.129181 [info ] [Thread-1 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m23:06:21.129181 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m23:06:21.130240 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m23:06:21.130240 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m23:06:21.133439 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m23:06:21.134874 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m23:06:21.137204 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:06:21.138205 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m23:06:21.138205 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m23:06:21.139780 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m23:06:21.139780 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m23:06:21.139780 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:21.348064 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f5bd-1811-918a-6ab11a7fdde8) - Created
[0m23:06:21.921157 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m23:06:21.922277 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-f5bd-1811-918a-6ab11a7fdde8, command-id=01f0af8a-f5ca-1264-a1b8-7241a4fd5c38) - Closing
[0m23:06:21.922277 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:21.923277 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m23:06:21.923277 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f5bd-1811-918a-6ab11a7fdde8) - Closing
[0m23:06:22.004061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8FE0800>]}
[0m23:06:22.005061 [info ] [Thread-1 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 0.87s]
[0m23:06:22.006059 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m23:06:22.006059 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m23:06:22.007059 [info ] [Thread-1 (]: 6 of 6 START sql table model bronze.bronze_store ............................... [RUN]
[0m23:06:22.007059 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m23:06:22.008058 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m23:06:22.008058 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m23:06:22.012084 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m23:06:22.012084 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m23:06:22.015405 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:06:22.016404 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m23:06:22.016404 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m23:06:22.017908 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m23:06:22.017908 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:06:22.202291 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f642-1bc8-9742-61502f47d833) - Created
[0m23:06:25.966086 [debug] [Thread-1 (]: SQL status: OK in 3.950 seconds
[0m23:06:25.967181 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8a-f642-1bc8-9742-61502f47d833, command-id=01f0af8a-f64b-1c8a-97da-f3f65efbad59) - Closing
[0m23:06:25.968181 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:06:25.968181 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m23:06:25.968181 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8a-f642-1bc8-9742-61502f47d833) - Closing
[0m23:06:26.041716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6acd92f-db14-4739-82c1-02bde20a192a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DE8F8DA30>]}
[0m23:06:26.042846 [info ] [Thread-1 (]: 6 of 6 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 4.03s]
[0m23:06:26.042846 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m23:06:26.044910 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:06:26.044910 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:06:26.044910 [info ] [MainThread]: 
[0m23:06:26.045910 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 47.85 seconds (47.85s).
[0m23:06:26.046914 [debug] [MainThread]: Command end result
[0m23:06:26.073814 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:06:26.075815 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:06:26.082408 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m23:06:26.082408 [info ] [MainThread]: 
[0m23:06:26.083577 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:06:26.083577 [info ] [MainThread]: 
[0m23:06:26.083577 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:06:26.084580 [debug] [MainThread]: Command `dbt run` succeeded at 23:06:26.084580 after 50.13 seconds
[0m23:06:26.084580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC4F308C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC1DA8830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020DC4DAA930>]}
[0m23:06:26.085774 [debug] [MainThread]: Flushing usage events
[0m23:06:26.791860 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:09:07.303716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029345B90470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002934660C200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002934660DD00>]}


============================== 23:09:07.307844 | 15d65c57-0479-464b-b2ca-c74a6206ec39 ==============================
[0m23:09:07.307844 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:09:07.308844 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'printer_width': '80', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'partial_parse': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m23:09:08.098729 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:09:08.098729 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:09:08.099816 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:09:08.775833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029367DD7D70>]}
[0m23:09:08.831337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029346C5FFB0>]}
[0m23:09:08.832399 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m23:09:09.143855 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:09:09.270526 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:09:09.270526 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:09:09.277036 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m23:09:09.303638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029369E24350>]}
[0m23:09:09.370250 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:09:09.372387 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:09:09.381866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A193980>]}
[0m23:09:09.381866 [info ] [MainThread]: Found 6 models, 6 sources, 700 macros
[0m23:09:09.382964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A1E4050>]}
[0m23:09:09.383964 [info ] [MainThread]: 
[0m23:09:09.383964 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:09:09.383964 [info ] [MainThread]: 
[0m23:09:09.385598 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:09:09.385598 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:09:09.392606 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m23:09:09.392606 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m23:09:09.402400 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m23:09:09.403904 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m23:09:09.403904 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:09.627373 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-5a0c-1c4a-abec-8455e43e7a88) - Created
[0m23:09:10.157656 [debug] [ThreadPool]: SQL status: OK in 0.750 seconds
[0m23:09:10.161869 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-5a0c-1c4a-abec-8455e43e7a88, command-id=01f0af8b-5a17-1016-a0ea-69c7c2e6ddc6) - Closing
[0m23:09:10.162867 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m23:09:10.162867 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-5a0c-1c4a-abec-8455e43e7a88) - Closing
[0m23:09:10.252513 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m23:09:10.254020 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m23:09:10.261028 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m23:09:10.261028 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m23:09:10.262092 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:10.444713 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-5a87-160b-abf1-e38f6983c1cd) - Created
[0m23:09:11.131897 [debug] [ThreadPool]: SQL status: OK in 0.870 seconds
[0m23:09:11.135416 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-5a87-160b-abf1-e38f6983c1cd, command-id=01f0af8b-5a98-195c-ac98-b4d88cf6e38e) - Closing
[0m23:09:11.136414 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m23:09:11.136414 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-5a87-160b-abf1-e38f6983c1cd) - Closing
[0m23:09:11.249552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A05C080>]}
[0m23:09:11.253870 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m23:09:11.253870 [info ] [Thread-1 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:09:11.255463 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m23:09:11.255463 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m23:09:11.256473 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m23:09:11.264059 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m23:09:11.265315 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m23:09:11.281725 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:09:11.283224 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:09:11.283729 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A3905F0>]}
[0m23:09:11.330149 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m23:09:11.331260 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m23:09:11.332293 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m23:09:11.332293 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:11.526385 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5b2d-1164-9acc-dc9cf20437ac) - Created
[0m23:09:14.900841 [debug] [Thread-1 (]: SQL status: OK in 3.570 seconds
[0m23:09:14.902478 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-5b2d-1164-9acc-dc9cf20437ac, command-id=01f0af8b-5b38-1742-b08c-ca5cff19e12c) - Closing
[0m23:09:14.914052 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:14.929501 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m23:09:14.930501 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5b2d-1164-9acc-dc9cf20437ac) - Closing
[0m23:09:14.999012 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029345F8C620>]}
[0m23:09:15.000013 [info ] [Thread-1 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 3.74s]
[0m23:09:15.001009 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m23:09:15.001009 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m23:09:15.002008 [info ] [Thread-1 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:09:15.002008 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m23:09:15.003023 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m23:09:15.003023 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m23:09:15.005518 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m23:09:15.006518 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m23:09:15.020382 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:09:15.032300 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m23:09:15.032300 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m23:09:15.033810 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m23:09:15.033810 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m23:09:15.034823 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:15.267220 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5d67-1469-9307-12dcbf0b225f) - Created
[0m23:09:15.939643 [debug] [Thread-1 (]: SQL status: OK in 0.900 seconds
[0m23:09:15.940644 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-5d67-1469-9307-12dcbf0b225f, command-id=01f0af8b-5d73-194c-9d48-8f4cb20324aa) - Closing
[0m23:09:15.940644 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:15.942154 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m23:09:15.942154 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5d67-1469-9307-12dcbf0b225f) - Closing
[0m23:09:16.014845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A3366C0>]}
[0m23:09:16.015845 [info ] [Thread-1 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.01s]
[0m23:09:16.016846 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m23:09:16.016846 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m23:09:16.017846 [info ] [Thread-1 (]: 3 of 6 START sql view model bronze.bronze_product .............................. [RUN]
[0m23:09:16.017846 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m23:09:16.018910 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m23:09:16.018910 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m23:09:16.022912 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m23:09:16.022912 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m23:09:16.025425 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:09:16.025425 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m23:09:16.026425 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m23:09:16.027425 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m23:09:16.027425 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m23:09:16.027425 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:16.209021 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5df9-1789-85ff-7a732f313f65) - Created
[0m23:09:16.840576 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m23:09:16.845354 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-5df9-1789-85ff-7a732f313f65, command-id=01f0af8b-5e07-1404-ab46-98d30443b268) - Closing
[0m23:09:16.845354 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:16.846355 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m23:09:16.846355 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5df9-1789-85ff-7a732f313f65) - Closing
[0m23:09:16.939918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A3F97C0>]}
[0m23:09:16.940990 [info ] [Thread-1 (]: 3 of 6 OK created sql view model bronze.bronze_product ......................... [[32mOK[0m in 0.92s]
[0m23:09:16.941508 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m23:09:16.942037 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m23:09:16.942037 [info ] [Thread-1 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m23:09:16.942037 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m23:09:16.943450 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m23:09:16.943450 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m23:09:16.946958 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m23:09:16.947964 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m23:09:16.949958 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:09:16.950959 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m23:09:16.952366 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m23:09:16.952366 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m23:09:16.952366 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:17.128919 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5e86-1589-b557-eafd4970eba2) - Created
[0m23:09:19.282285 [debug] [Thread-1 (]: SQL status: OK in 2.330 seconds
[0m23:09:19.283315 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-5e86-1589-b557-eafd4970eba2, command-id=01f0af8b-5e8f-17c4-91b8-c360975b56fe) - Closing
[0m23:09:19.283315 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:19.284331 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m23:09:19.285482 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5e86-1589-b557-eafd4970eba2) - Closing
[0m23:09:19.360220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A433E60>]}
[0m23:09:19.360220 [info ] [Thread-1 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 2.42s]
[0m23:09:19.361263 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m23:09:19.361263 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m23:09:19.362264 [info ] [Thread-1 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m23:09:19.362264 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m23:09:19.363260 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m23:09:19.363260 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m23:09:19.369023 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m23:09:19.370153 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m23:09:19.372152 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:09:19.373151 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m23:09:19.373151 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m23:09:19.374151 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m23:09:19.374151 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m23:09:19.374151 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:19.547231 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5ff6-12f1-8535-4d86ffe4334e) - Created
[0m23:09:20.180669 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m23:09:20.180669 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-5ff6-12f1-8535-4d86ffe4334e, command-id=01f0af8b-5fff-1a07-847c-c9658da00131) - Closing
[0m23:09:20.182134 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:20.182134 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m23:09:20.183134 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-5ff6-12f1-8535-4d86ffe4334e) - Closing
[0m23:09:20.254335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A3EBA40>]}
[0m23:09:20.254335 [info ] [Thread-1 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 0.89s]
[0m23:09:20.255838 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m23:09:20.255838 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m23:09:20.256903 [info ] [Thread-1 (]: 6 of 6 START sql table model bronze.bronze_store ............................... [RUN]
[0m23:09:20.256903 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m23:09:20.257915 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m23:09:20.257915 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m23:09:20.260935 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m23:09:20.261933 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m23:09:20.264988 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:09:20.265995 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m23:09:20.265995 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m23:09:20.266996 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m23:09:20.266996 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:20.468124 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-6080-1de2-b391-9c86bd116373) - Created
[0m23:09:23.051136 [debug] [Thread-1 (]: SQL status: OK in 2.780 seconds
[0m23:09:23.052135 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-6080-1de2-b391-9c86bd116373, command-id=01f0af8b-608c-1798-b8f6-3e0ff052caec) - Closing
[0m23:09:23.053134 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:23.053134 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m23:09:23.054131 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-6080-1de2-b391-9c86bd116373) - Closing
[0m23:09:23.126960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15d65c57-0479-464b-b2ca-c74a6206ec39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A3E1040>]}
[0m23:09:23.127958 [info ] [Thread-1 (]: 6 of 6 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 2.87s]
[0m23:09:23.128958 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m23:09:23.129958 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:09:23.129958 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:09:23.130958 [info ] [MainThread]: 
[0m23:09:23.130958 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 13.75 seconds (13.75s).
[0m23:09:23.132957 [debug] [MainThread]: Command end result
[0m23:09:23.271990 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:09:23.273990 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:09:23.280284 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m23:09:23.280284 [info ] [MainThread]: 
[0m23:09:23.280284 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:09:23.281283 [info ] [MainThread]: 
[0m23:09:23.281283 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:09:23.282281 [debug] [MainThread]: Command `dbt run` succeeded at 23:09:23.282281 after 16.13 seconds
[0m23:09:23.282281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029343D67E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029346930800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936A2C09B0>]}
[0m23:09:23.283281 [debug] [MainThread]: Flushing usage events
[0m23:09:24.006494 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:09:46.188133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E6F701A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E74B0F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E99364B0>]}


============================== 23:09:46.191133 | a9d9ef80-e258-4043-80ab-3e9180252b49 ==============================
[0m23:09:46.191133 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:09:46.192132 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze_date', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'warn_error': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m23:09:46.991634 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:09:46.991634 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:09:46.992638 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:09:47.649130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7ECB55400>]}
[0m23:09:47.706388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E78D14BC50>]}
[0m23:09:47.706388 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m23:09:48.017566 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:09:48.145213 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:09:48.145213 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:09:48.152228 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m23:09:48.177414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E78D8868D0>]}
[0m23:09:48.244962 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:09:48.247481 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:09:48.255993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E78D8896A0>]}
[0m23:09:48.256990 [info ] [MainThread]: Found 6 models, 6 sources, 700 macros
[0m23:09:48.256990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E78D8B4800>]}
[0m23:09:48.257993 [info ] [MainThread]: 
[0m23:09:48.258991 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:09:48.258991 [info ] [MainThread]: 
[0m23:09:48.259990 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:09:48.259990 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:09:48.261026 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m23:09:48.262025 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m23:09:48.271542 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m23:09:48.272543 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m23:09:48.272543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:48.487746 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-7136-167f-92ad-7629a1864a11) - Created
[0m23:09:48.776721 [debug] [ThreadPool]: SQL status: OK in 0.500 seconds
[0m23:09:48.780721 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-7136-167f-92ad-7629a1864a11, command-id=01f0af8b-7140-1edd-8965-8ef3cb66bf12) - Closing
[0m23:09:48.780721 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m23:09:48.780721 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-7136-167f-92ad-7629a1864a11) - Closing
[0m23:09:48.861307 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m23:09:48.861307 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m23:09:48.867827 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m23:09:48.868828 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m23:09:48.868828 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:49.082533 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-718c-172e-9f1d-8a79bb0f1593) - Created
[0m23:09:49.520576 [debug] [ThreadPool]: SQL status: OK in 0.650 seconds
[0m23:09:49.522579 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-718c-172e-9f1d-8a79bb0f1593, command-id=01f0af8b-719b-139e-8593-cfa5977f1c31) - Closing
[0m23:09:49.523578 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m23:09:49.523578 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-718c-172e-9f1d-8a79bb0f1593) - Closing
[0m23:09:49.604911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7EA07A1E0>]}
[0m23:09:49.608939 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m23:09:49.608939 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:09:49.609999 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m23:09:49.609999 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m23:09:49.611000 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m23:09:49.618738 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m23:09:49.619744 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m23:09:49.633994 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:09:49.637531 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:09:49.638526 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E78D942870>]}
[0m23:09:49.650947 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m23:09:49.662332 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m23:09:49.663331 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m23:09:49.663331 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m23:09:49.663331 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:09:49.834955 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-7205-1549-8f46-f8d10d96ba36) - Created
[0m23:09:50.476832 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m23:09:50.477829 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-7205-1549-8f46-f8d10d96ba36, command-id=01f0af8b-720d-170d-83ac-cdeffcfe31bb) - Closing
[0m23:09:50.488765 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:09:50.489764 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m23:09:50.490767 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-7205-1549-8f46-f8d10d96ba36) - Closing
[0m23:09:50.572621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9d9ef80-e258-4043-80ab-3e9180252b49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E7074680>]}
[0m23:09:50.573625 [info ] [Thread-1 (]: 1 of 1 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 0.96s]
[0m23:09:50.574625 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m23:09:50.575700 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:09:50.575700 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:09:50.576701 [info ] [MainThread]: 
[0m23:09:50.576701 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.32 seconds (2.32s).
[0m23:09:50.577767 [debug] [MainThread]: Command end result
[0m23:09:50.608795 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:09:50.611801 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:09:50.617008 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m23:09:50.618009 [info ] [MainThread]: 
[0m23:09:50.618009 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:09:50.619452 [info ] [MainThread]: 
[0m23:09:50.619452 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m23:09:50.620508 [debug] [MainThread]: Command `dbt run` succeeded at 23:09:50.620508 after 4.55 seconds
[0m23:09:50.620508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E9B73D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E9E94260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7E9E94EF0>]}
[0m23:09:50.621581 [debug] [MainThread]: Flushing usage events
[0m23:09:51.332666 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:10:37.928678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001605A906510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001605A2CF260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001605A2CF2C0>]}


============================== 23:10:37.932193 | f7fac717-f3ef-4d2d-b6ab-f4864dc339dc ==============================
[0m23:10:37.932193 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:10:37.933193 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'printer_width': '80', 'no_print': 'None', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'invocation_command': 'dbt run --select bronze_date bronze_store', 'warn_error': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m23:10:38.735594 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:10:38.735594 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:10:38.736594 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:10:39.361637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607D66BFB0>]}
[0m23:10:39.417632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607DE239E0>]}
[0m23:10:39.418632 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m23:10:39.715625 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:10:39.839774 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:10:39.839774 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:10:39.847051 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m23:10:39.871058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E078500>]}
[0m23:10:39.936106 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:10:39.938108 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:10:39.947109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E529790>]}
[0m23:10:39.948108 [info ] [MainThread]: Found 6 models, 6 sources, 700 macros
[0m23:10:39.948108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607DF76B40>]}
[0m23:10:39.949109 [info ] [MainThread]: 
[0m23:10:39.950106 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:10:39.950106 [info ] [MainThread]: 
[0m23:10:39.951109 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:10:39.951109 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:10:39.957107 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m23:10:39.957107 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m23:10:39.967076 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m23:10:39.968172 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m23:10:39.968172 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:40.178624 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-9005-1647-8b9e-493003c0e415) - Created
[0m23:10:40.483065 [debug] [ThreadPool]: SQL status: OK in 0.510 seconds
[0m23:10:40.487065 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-9005-1647-8b9e-493003c0e415, command-id=01f0af8b-900f-153c-9d87-0ce1ff20f5a5) - Closing
[0m23:10:40.487065 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m23:10:40.488076 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-9005-1647-8b9e-493003c0e415) - Closing
[0m23:10:40.558158 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m23:10:40.558158 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m23:10:40.566161 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m23:10:40.566161 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m23:10:40.566161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:40.764097 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-905f-17fe-8034-3617c3831355) - Created
[0m23:10:41.176242 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m23:10:41.178277 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-905f-17fe-8034-3617c3831355, command-id=01f0af8b-9069-1063-9be0-6a528cbb0c9d) - Closing
[0m23:10:41.179295 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m23:10:41.179295 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-905f-17fe-8034-3617c3831355) - Closing
[0m23:10:41.265508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607DF77AD0>]}
[0m23:10:41.268507 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m23:10:41.269857 [info ] [Thread-1 (]: 1 of 2 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:10:41.269857 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m23:10:41.269857 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m23:10:41.271304 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m23:10:41.278866 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m23:10:41.279862 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m23:10:41.293862 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:10:41.295868 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:10:41.295868 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E5E4680>]}
[0m23:10:41.308185 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m23:10:41.318408 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m23:10:41.318408 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m23:10:41.319408 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m23:10:41.319408 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:10:41.492968 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-90cf-17c6-a043-38bb9daf1f7b) - Created
[0m23:10:42.154691 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m23:10:42.155688 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-90cf-17c6-a043-38bb9daf1f7b, command-id=01f0af8b-90db-14bf-8265-de89e766f27a) - Closing
[0m23:10:42.165733 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:10:42.166735 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m23:10:42.167734 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-90cf-17c6-a043-38bb9daf1f7b) - Closing
[0m23:10:42.243122 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016057E34500>]}
[0m23:10:42.243122 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 0.97s]
[0m23:10:42.244122 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m23:10:42.244122 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m23:10:42.245126 [info ] [Thread-1 (]: 2 of 2 START sql table model bronze.bronze_store ............................... [RUN]
[0m23:10:42.246126 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m23:10:42.246126 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m23:10:42.246126 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m23:10:42.251376 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m23:10:42.252375 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m23:10:42.267820 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:10:42.298986 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m23:10:42.298986 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m23:10:42.299986 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m23:10:42.299986 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:10:42.465345 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-9163-1594-bfd9-bf99b17b7c09) - Created
[0m23:10:44.589540 [debug] [Thread-1 (]: SQL status: OK in 2.290 seconds
[0m23:10:44.589540 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-9163-1594-bfd9-bf99b17b7c09, command-id=01f0af8b-916b-1d6c-90d1-1b692b50d947) - Closing
[0m23:10:44.592552 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:10:44.608173 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m23:10:44.608173 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-9163-1594-bfd9-bf99b17b7c09) - Closing
[0m23:10:44.677962 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7fac717-f3ef-4d2d-b6ab-f4864dc339dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E5AF830>]}
[0m23:10:44.679476 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 2.43s]
[0m23:10:44.680488 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m23:10:44.681483 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:10:44.681483 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:10:44.682482 [info ] [MainThread]: 
[0m23:10:44.682482 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.73 seconds (4.73s).
[0m23:10:44.683483 [debug] [MainThread]: Command end result
[0m23:10:44.708572 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:10:44.710573 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:10:44.715576 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m23:10:44.717023 [info ] [MainThread]: 
[0m23:10:44.717023 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:10:44.718041 [info ] [MainThread]: 
[0m23:10:44.718041 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m23:10:44.719042 [debug] [MainThread]: Command `dbt run` succeeded at 23:10:44.719042 after 6.93 seconds
[0m23:10:44.719042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607DF8D160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E5200E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001607E313020>]}
[0m23:10:44.720043 [debug] [MainThread]: Flushing usage events
[0m23:10:45.354493 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:11:33.365586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCEFF1AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCF0D63F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCF613B60>]}


============================== 23:11:33.369249 | ba4731ea-d820-4a25-9cba-d10bff024d58 ==============================
[0m23:11:33.369249 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:11:33.369249 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select models/bronze', 'write_json': 'True', 'no_print': 'None', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'cache_selected_only': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m23:11:34.127903 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:11:34.129036 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:11:34.129036 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:11:34.754593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCCB11370>]}
[0m23:11:34.810940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF0B91F70>]}
[0m23:11:34.810940 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m23:11:35.098359 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:11:35.221877 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:11:35.221877 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:11:35.229188 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m23:11:35.253188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF31E31D0>]}
[0m23:11:35.320027 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:11:35.323178 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:11:35.331576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF2F8FB60>]}
[0m23:11:35.331576 [info ] [MainThread]: Found 6 models, 6 sources, 700 macros
[0m23:11:35.331576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBD26689B0>]}
[0m23:11:35.334039 [info ] [MainThread]: 
[0m23:11:35.335038 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:11:35.335038 [info ] [MainThread]: 
[0m23:11:35.336039 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:11:35.336039 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:11:35.342300 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m23:11:35.342300 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m23:11:35.352662 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m23:11:35.352662 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m23:11:35.353676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:35.597480 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-b10e-1437-880b-54765be92744) - Created
[0m23:11:35.894302 [debug] [ThreadPool]: SQL status: OK in 0.540 seconds
[0m23:11:35.898992 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-b10e-1437-880b-54765be92744, command-id=01f0af8b-b11c-1940-a70d-f42f9afd3dff) - Closing
[0m23:11:35.900005 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m23:11:35.900005 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-b10e-1437-880b-54765be92744) - Closing
[0m23:11:36.007167 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m23:11:36.008182 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m23:11:36.015618 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m23:11:36.015618 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m23:11:36.015618 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:36.232502 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-b16d-1f56-ac4c-b496ec0b41c0) - Created
[0m23:11:36.627972 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m23:11:36.629970 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0af8b-b16d-1f56-ac4c-b496ec0b41c0, command-id=01f0af8b-b179-1d19-8164-1a44c630552e) - Closing
[0m23:11:36.630972 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m23:11:36.630972 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0af8b-b16d-1f56-ac4c-b496ec0b41c0) - Closing
[0m23:11:36.707573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF0B77F50>]}
[0m23:11:36.711617 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m23:11:36.711617 [info ] [Thread-1 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m23:11:36.712628 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m23:11:36.712628 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m23:11:36.712628 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m23:11:36.720304 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m23:11:36.721320 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m23:11:36.737760 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:11:36.737760 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:11:36.738789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF32C8590>]}
[0m23:11:36.780290 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m23:11:36.781286 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m23:11:36.781286 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m23:11:36.781286 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:36.969266 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b1de-1ed5-a136-296bbfe38aa5) - Created
[0m23:11:39.135401 [debug] [Thread-1 (]: SQL status: OK in 2.350 seconds
[0m23:11:39.136440 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b1de-1ed5-a136-296bbfe38aa5, command-id=01f0af8b-b1ec-13d6-b544-5ec901bf4971) - Closing
[0m23:11:39.147976 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:39.162656 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m23:11:39.162656 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b1de-1ed5-a136-296bbfe38aa5) - Closing
[0m23:11:39.243569 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCEF2D0A0>]}
[0m23:11:39.243569 [info ] [Thread-1 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 2.53s]
[0m23:11:39.244758 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m23:11:39.244758 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m23:11:39.246002 [info ] [Thread-1 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m23:11:39.246002 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m23:11:39.247083 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m23:11:39.247083 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m23:11:39.249114 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m23:11:39.250198 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m23:11:39.263231 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:11:39.274381 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m23:11:39.275476 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m23:11:39.276475 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m23:11:39.276475 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m23:11:39.276475 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:39.460997 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b35c-1377-a353-6d55b737f87c) - Created
[0m23:11:40.145749 [debug] [Thread-1 (]: SQL status: OK in 0.870 seconds
[0m23:11:40.146792 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b35c-1377-a353-6d55b737f87c, command-id=01f0af8b-b365-16dd-9039-718cf1471dc9) - Closing
[0m23:11:40.146792 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:40.147984 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m23:11:40.147984 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b35c-1377-a353-6d55b737f87c) - Closing
[0m23:11:40.214495 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF32CBAD0>]}
[0m23:11:40.215494 [info ] [Thread-1 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 0.97s]
[0m23:11:40.216493 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m23:11:40.216493 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m23:11:40.216493 [info ] [Thread-1 (]: 3 of 6 START sql view model bronze.bronze_product .............................. [RUN]
[0m23:11:40.217637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m23:11:40.217637 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m23:11:40.218735 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m23:11:40.221738 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m23:11:40.222738 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m23:11:40.224772 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:11:40.226067 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m23:11:40.226067 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m23:11:40.227262 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m23:11:40.227262 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m23:11:40.227262 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:40.412471 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b3ec-1382-a13b-eff314c1730e) - Created
[0m23:11:41.002156 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m23:11:41.003158 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b3ec-1382-a13b-eff314c1730e, command-id=01f0af8b-b3f5-1ed4-a775-460a0ef00afd) - Closing
[0m23:11:41.003158 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:41.004159 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m23:11:41.004159 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b3ec-1382-a13b-eff314c1730e) - Closing
[0m23:11:41.079983 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF331A7E0>]}
[0m23:11:41.079983 [info ] [Thread-1 (]: 3 of 6 OK created sql view model bronze.bronze_product ......................... [[32mOK[0m in 0.86s]
[0m23:11:41.080982 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m23:11:41.080982 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m23:11:41.082083 [info ] [Thread-1 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m23:11:41.082083 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m23:11:41.083073 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m23:11:41.083073 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m23:11:41.086426 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m23:11:41.087622 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m23:11:41.089767 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:11:41.090781 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m23:11:41.090781 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m23:11:41.091881 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m23:11:41.091881 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:41.261717 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b46e-1b5e-896a-72e2d90c760f) - Created
[0m23:11:43.271275 [debug] [Thread-1 (]: SQL status: OK in 2.180 seconds
[0m23:11:43.272276 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b46e-1b5e-896a-72e2d90c760f, command-id=01f0af8b-b478-1fc1-b2bc-bcc9bce1a71a) - Closing
[0m23:11:43.273275 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:43.274275 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m23:11:43.274275 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b46e-1b5e-896a-72e2d90c760f) - Closing
[0m23:11:43.358364 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF332B6E0>]}
[0m23:11:43.358364 [info ] [Thread-1 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 2.28s]
[0m23:11:43.359378 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m23:11:43.359378 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m23:11:43.360432 [info ] [Thread-1 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m23:11:43.361431 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m23:11:43.361431 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m23:11:43.361431 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m23:11:43.367995 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m23:11:43.367995 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m23:11:43.370536 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m23:11:43.371631 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m23:11:43.371631 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m23:11:43.372735 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m23:11:43.372735 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m23:11:43.372735 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:43.560402 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b5cc-1e04-b695-b18ad8d851d9) - Created
[0m23:11:44.219451 [debug] [Thread-1 (]: SQL status: OK in 0.850 seconds
[0m23:11:44.221043 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b5cc-1e04-b695-b18ad8d851d9, command-id=01f0af8b-b5d9-1cd7-924c-9abb092dd889) - Closing
[0m23:11:44.221043 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:44.222322 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m23:11:44.223335 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b5cc-1e04-b695-b18ad8d851d9) - Closing
[0m23:11:44.292259 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF3348F20>]}
[0m23:11:44.293466 [info ] [Thread-1 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 0.93s]
[0m23:11:44.294485 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m23:11:44.294485 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m23:11:44.294485 [info ] [Thread-1 (]: 6 of 6 START sql table model bronze.bronze_store ............................... [RUN]
[0m23:11:44.295674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m23:11:44.295674 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m23:11:44.295674 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m23:11:44.299222 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m23:11:44.300374 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m23:11:44.302372 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m23:11:44.303372 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m23:11:44.304372 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m23:11:44.304372 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m23:11:44.304372 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:11:44.501881 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b65c-1a92-be2d-dd38329821b9) - Created
[0m23:11:46.562364 [debug] [Thread-1 (]: SQL status: OK in 2.260 seconds
[0m23:11:46.563365 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0af8b-b65c-1a92-be2d-dd38329821b9, command-id=01f0af8b-b666-19ef-af86-59b01ad46261) - Closing
[0m23:11:46.564432 [debug] [Thread-1 (]: Applying tags to relation None
[0m23:11:46.564432 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m23:11:46.565808 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0af8b-b65c-1a92-be2d-dd38329821b9) - Closing
[0m23:11:46.694202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba4731ea-d820-4a25-9cba-d10bff024d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF0B91E80>]}
[0m23:11:46.695282 [info ] [Thread-1 (]: 6 of 6 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 2.40s]
[0m23:11:46.695282 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m23:11:46.697439 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:11:46.697439 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:11:46.697439 [info ] [MainThread]: 
[0m23:11:46.698483 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 11.36 seconds (11.36s).
[0m23:11:46.699483 [debug] [MainThread]: Command end result
[0m23:11:46.855066 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m23:11:46.858078 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m23:11:46.866859 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m23:11:46.866859 [info ] [MainThread]: 
[0m23:11:46.866859 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:11:46.868075 [info ] [MainThread]: 
[0m23:11:46.868075 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:11:46.869581 [debug] [MainThread]: Command `dbt run` succeeded at 23:11:46.869581 after 13.62 seconds
[0m23:11:46.869581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBCD52E060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBD26689B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBF297EC30>]}
[0m23:11:46.870588 [debug] [MainThread]: Flushing usage events
[0m23:11:47.640073 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:33:02.579005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB07F2540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB013FCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFAFC6D3D0>]}


============================== 10:33:02.609636 | 16d88034-3db4-4095-801a-8b8587a2be8f ==============================
[0m10:33:02.609636 [info ] [MainThread]: Running with dbt=1.10.13
[0m10:33:02.611187 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt ', 'printer_width': '80', 'profiles_dir': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'target_path': 'None', 'log_format': 'default', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'log_path': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m10:33:02.748922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '16d88034-3db4-4095-801a-8b8587a2be8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB09F24B0>]}
[0m10:33:02.783560 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:33:02.784558 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:33:02.785949 [debug] [MainThread]: Command `cli deps` succeeded at 10:33:02.784558 after 0.33 seconds
[0m10:33:02.785949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB1C40F20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB07F1D00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB098B770>]}
[0m10:33:02.785949 [debug] [MainThread]: Flushing usage events
[0m10:33:03.514141 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:45:29.835201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F37F61E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F4A12BA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F1A54140>]}


============================== 10:45:29.839201 | db96920d-0505-4fe4-bc8f-b4935d2bdc13 ==============================
[0m10:45:29.839201 [info ] [MainThread]: Running with dbt=1.10.13
[0m10:45:29.840218 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m10:45:29.951430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'db96920d-0505-4fe4-bc8f-b4935d2bdc13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F5CFEA50>]}
[0m10:45:30.057117 [debug] [MainThread]: Command `dbt clean` succeeded at 10:45:30.057117 after 0.33 seconds
[0m10:45:30.058116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F49150D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F1A54140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F44D12B0>]}
[0m10:45:30.058116 [debug] [MainThread]: Flushing usage events
[0m10:45:30.684683 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:04:35.502876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E1E47E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E195FFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E195DAF0>]}


============================== 11:04:35.506911 | 439fda95-0ab5-470a-8dc7-4376dae0b503 ==============================
[0m11:04:35.506911 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:04:35.507908 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt test', 'no_print': 'None', 'log_format': 'default', 'write_json': 'True', 'printer_width': '80', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m11:04:36.294718 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:04:36.295733 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:04:36.295733 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:04:36.955882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '439fda95-0ab5-470a-8dc7-4376dae0b503', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E1EFF800>]}
[0m11:04:37.011960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '439fda95-0ab5-470a-8dc7-4376dae0b503', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E55D3F80>]}
[0m11:04:37.012960 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:04:37.392726 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:04:37.538734 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:04:37.540185 [debug] [MainThread]: Partial parsing: updated file: octy_dbt_learn://models\bronze\properties.yml
[0m11:04:37.847060 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models\bronze\properties.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('arguments', {'values': ['MegaMart Manhattan', 'MegaMart Brooklyn', 'MegaMart Austin', 'MegaMart San Jose', 'MegaMart Toronto']})] instead (2 keys)
  	@: UnparsedModelUpdate(original_file_path='mode...ne)
[0m11:04:37.848060 [debug] [MainThread]: Command `dbt test` failed at 11:04:37.848060 after 2.50 seconds
[0m11:04:37.849148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172E195FFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172859D70B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017286346210>]}
[0m11:04:37.849148 [debug] [MainThread]: Flushing usage events
[0m11:04:38.514309 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:06:32.408069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85CEBE1E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85CB72960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85CB70DD0>]}


============================== 11:06:32.412065 | a9137e85-a995-4e6f-a09f-3e05ac884690 ==============================
[0m11:06:32.412065 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:06:32.412065 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'printer_width': '80', 'target_path': 'None', 'no_print': 'None', 'use_colors': 'True', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m11:06:33.161417 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:06:33.162418 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:06:33.162418 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:06:33.807876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9137e85-a995-4e6f-a09f-3e05ac884690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85FFEADB0>]}
[0m11:06:33.863301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9137e85-a995-4e6f-a09f-3e05ac884690', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85D0E40B0>]}
[0m11:06:33.864335 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:06:34.153619 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:06:34.241898 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading octy_dbt_learn: bronze\properties.yml - Runtime Error
    Syntax error near line 28
    ------------------------------
    25 |         data_tests:
    26 |           - accepted_values:
    27 |               arguments:
    28 |                 values: values: ['MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto']
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 28, column 31
[0m11:06:34.243402 [debug] [MainThread]: Command `dbt test` failed at 11:06:34.243402 after 1.98 seconds
[0m11:06:34.244425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85D8D09B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E800256A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E800DD4EC0>]}
[0m11:06:34.244932 [debug] [MainThread]: Flushing usage events
[0m11:06:34.909717 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:07:35.070502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B7F235700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B030F3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B035E1850>]}


============================== 11:07:35.074743 | 06c5aff9-0aec-4f2d-a175-198e68c5536b ==============================
[0m11:07:35.074743 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:07:35.074743 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'write_json': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt test', 'printer_width': '80', 'target_path': 'None'}
[0m11:07:35.824217 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:07:35.825218 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:07:35.825218 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:07:36.457035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B02F7F740>]}
[0m11:07:36.512792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B26457EC0>]}
[0m11:07:36.512792 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:07:36.795429 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:07:36.937930 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:07:36.937930 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:07:36.944403 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m11:07:36.981237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B26F65550>]}
[0m11:07:37.056831 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:07:37.084358 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:07:37.257297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B27240A40>]}
[0m11:07:37.258296 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 700 macros
[0m11:07:37.258296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B029EC440>]}
[0m11:07:37.260725 [info ] [MainThread]: 
[0m11:07:37.260725 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:07:37.261855 [info ] [MainThread]: 
[0m11:07:37.261855 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:07:37.261855 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:07:37.268338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m11:07:37.268338 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m11:07:37.281098 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m11:07:37.282122 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m11:07:37.282122 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:07:37.614559 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0afef-b86c-17f3-9dd9-f2ffbf5f10e1) - Created
[0m11:07:39.245829 [debug] [ThreadPool]: SQL status: OK in 1.960 seconds
[0m11:07:39.250824 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0afef-b86c-17f3-9dd9-f2ffbf5f10e1, command-id=01f0afef-b878-15dc-84e0-9340b421aa41) - Closing
[0m11:07:39.250824 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m11:07:39.250824 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0afef-b86c-17f3-9dd9-f2ffbf5f10e1) - Closing
[0m11:07:39.325153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06c5aff9-0aec-4f2d-a175-198e68c5536b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B00C181D0>]}
[0m11:07:39.333455 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:07:39.333455 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:07:39.334456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m11:07:39.335455 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m11:07:39.335455 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:07:39.351259 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:07:39.354261 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:07:39.371558 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:07:39.372883 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:07:39.372883 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:07:39.373880 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:07:39.580548 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-b998-1283-a772-9b4d05fcb9ee) - Created
[0m11:07:43.540063 [debug] [Thread-1 (]: SQL status: OK in 4.170 seconds
[0m11:07:43.542063 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0afef-b998-1283-a772-9b4d05fcb9ee, command-id=01f0afef-b9a7-1553-b27c-e0dcead5c340) - Closing
[0m11:07:43.545062 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m11:07:43.546063 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-b998-1283-a772-9b4d05fcb9ee) - Closing
[0m11:07:43.623263 [info ] [Thread-1 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 4.29s]
[0m11:07:43.624542 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:07:43.625582 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:07:43.625582 [info ] [Thread-1 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m11:07:43.626686 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:07:43.626686 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:07:43.626686 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:07:43.632697 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:07:43.633698 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:07:43.635870 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:07:43.635870 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:07:43.636869 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:07:43.636869 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:07:43.845274 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bc23-1568-bebb-8de11b3d0f2c) - Created
[0m11:07:44.778621 [debug] [Thread-1 (]: SQL status: OK in 1.140 seconds
[0m11:07:44.780622 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0afef-bc23-1568-bebb-8de11b3d0f2c, command-id=01f0afef-bc2f-195a-8a30-554cfdcdd9d8) - Closing
[0m11:07:44.780622 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:07:44.781622 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bc23-1568-bebb-8de11b3d0f2c) - Closing
[0m11:07:44.870691 [info ] [Thread-1 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.25s]
[0m11:07:44.871692 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:07:44.871692 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:07:44.872690 [info ] [Thread-1 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m11:07:44.872690 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:07:44.873688 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:07:44.873688 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:07:44.878691 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:07:44.878691 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:07:44.880691 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:07:44.881691 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:07:44.884691 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:07:44.884691 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:07:45.094689 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bce1-12fe-99e7-57e51f20b776) - Created
[0m11:07:45.829602 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m11:07:45.830602 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0afef-bce1-12fe-99e7-57e51f20b776, command-id=01f0afef-bcef-13ea-8b9c-fd131b86253b) - Closing
[0m11:07:45.831602 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:07:45.831602 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bce1-12fe-99e7-57e51f20b776) - Closing
[0m11:07:45.915130 [info ] [Thread-1 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.04s]
[0m11:07:45.916129 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:07:45.916129 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:07:45.917128 [info ] [Thread-1 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m11:07:45.917128 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:07:45.918130 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:07:45.918130 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:07:45.924128 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:07:45.926130 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:07:45.928128 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:07:45.929128 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:07:45.929128 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:07:45.930129 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:07:46.106162 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bd7e-1c3b-87c9-f5656b4e371c) - Created
[0m11:07:47.053451 [debug] [Thread-1 (]: SQL status: OK in 1.120 seconds
[0m11:07:47.055452 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0afef-bd7e-1c3b-87c9-f5656b4e371c, command-id=01f0afef-bd87-1d9c-9755-05d953e75593) - Closing
[0m11:07:47.055452 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:07:47.056452 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-bd7e-1c3b-87c9-f5656b4e371c) - Closing
[0m11:07:47.127090 [info ] [Thread-1 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.21s]
[0m11:07:47.128092 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:07:47.129091 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:07:47.129091 [info ] [Thread-1 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m11:07:47.130090 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:07:47.130090 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m11:07:47.130090 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:07:47.134090 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:07:47.137096 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:07:47.139091 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:07:47.139091 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:07:47.140093 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:07:47.140093 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:07:47.306009 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-be36-123e-9666-92cd16945f95) - Created
[0m11:07:48.084228 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m11:07:48.086483 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0afef-be36-123e-9666-92cd16945f95, command-id=01f0afef-be3e-1c72-b43e-3262cddb6fb0) - Closing
[0m11:07:48.086988 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:07:48.087495 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0afef-be36-123e-9666-92cd16945f95) - Closing
[0m11:07:48.177646 [info ] [Thread-1 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 1.05s]
[0m11:07:48.178645 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:07:48.179690 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:07:48.179690 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:07:48.180692 [info ] [MainThread]: 
[0m11:07:48.180692 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 10.92 seconds (10.92s).
[0m11:07:48.181691 [debug] [MainThread]: Command end result
[0m11:07:48.308904 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:07:48.310901 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:07:48.316904 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m11:07:48.316904 [info ] [MainThread]: 
[0m11:07:48.317901 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:07:48.317901 [info ] [MainThread]: 
[0m11:07:48.318902 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m11:07:48.318902 [debug] [MainThread]: Command `dbt test` succeeded at 11:07:48.318902 after 13.36 seconds
[0m11:07:48.319903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B26317BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B26061820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B27224620>]}
[0m11:07:48.319903 [debug] [MainThread]: Flushing usage events
[0m11:07:48.921164 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:24:07.223387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1CFCE1E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1A808AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1D47BC50>]}


============================== 11:24:07.226828 | 026e9c67-a15d-4274-a7fc-ffb5593ab574 ==============================
[0m11:24:07.226828 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:24:07.227861 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt test', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m11:24:08.013989 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:24:08.014988 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:24:08.014988 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:24:08.672329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1D47BD70>]}
[0m11:24:08.726915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1D3AE300>]}
[0m11:24:08.727915 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:24:09.025761 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:24:09.169350 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:24:09.170854 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:24:09.176944 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m11:24:09.213738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF410B0710>]}
[0m11:24:09.290801 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:24:09.292330 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:24:09.309567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF40DEC080>]}
[0m11:24:09.309567 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 700 macros
[0m11:24:09.311074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF41123AD0>]}
[0m11:24:09.313106 [info ] [MainThread]: 
[0m11:24:09.313106 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:24:09.313106 [info ] [MainThread]: 
[0m11:24:09.314106 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:24:09.314106 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:24:09.320644 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m11:24:09.321655 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m11:24:09.334225 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m11:24:09.334225 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m11:24:09.335242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:24:09.928761 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-07c2-1620-a0b2-4abcf160a4ba) - Created
[0m11:24:24.056160 [debug] [ThreadPool]: SQL status: OK in 14.720 seconds
[0m11:24:24.060160 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0aff2-07c2-1620-a0b2-4abcf160a4ba, command-id=01f0aff2-07f2-1479-830c-e01a8cf6e6e3) - Closing
[0m11:24:24.309590 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m11:24:24.311133 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-07c2-1620-a0b2-4abcf160a4ba) - Closing
[0m11:24:24.416142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '026e9c67-a15d-4274-a7fc-ffb5593ab574', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF40C01A60>]}
[0m11:24:24.423678 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa
[0m11:24:24.425167 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:24:24.425167 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa) - Creating connection
[0m11:24:24.426180 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa'
[0m11:24:24.426180 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa
[0m11:24:24.444867 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa"
[0m11:24:24.446868 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa
[0m11:24:24.467824 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa"
[0m11:24:24.471328 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa"
[0m11:24:24.471328 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhatten','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:24:24.472590 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:24:24.722897 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-10b4-13a1-9b77-86c5fda9df8e) - Created
[0m11:24:31.854767 [debug] [Thread-1 (]: SQL status: OK in 7.380 seconds
[0m11:24:31.856766 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-10b4-13a1-9b77-86c5fda9df8e, command-id=01f0aff2-10c4-1ba1-8ea1-2a19da3fcd91) - Closing
[0m11:24:31.994544 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa: Close
[0m11:24:31.994544 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-10b4-13a1-9b77-86c5fda9df8e) - Closing
[0m11:24:32.082298 [warn ] [Thread-1 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 7.66s]
[0m11:24:32.083291 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.eb084733aa
[0m11:24:32.083291 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:24:32.084291 [info ] [Thread-1 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m11:24:32.084291 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:24:32.085291 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:24:32.085291 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:24:32.093291 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:24:32.094291 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:24:32.097031 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:24:32.098070 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:24:32.098070 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:24:32.099069 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:24:32.327078 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-153d-1241-bce0-560bb760848b) - Created
[0m11:24:34.034001 [debug] [Thread-1 (]: SQL status: OK in 1.930 seconds
[0m11:24:34.036000 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-153d-1241-bce0-560bb760848b, command-id=01f0aff2-1549-1d60-bf97-cb87c93b4de6) - Closing
[0m11:24:34.037001 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:24:34.037001 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-153d-1241-bce0-560bb760848b) - Closing
[0m11:24:34.110004 [info ] [Thread-1 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.03s]
[0m11:24:34.111190 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:24:34.111190 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:24:34.112288 [info ] [Thread-1 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m11:24:34.112288 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:24:34.113287 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:24:34.113287 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:24:34.117791 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:24:34.118796 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:24:34.123795 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:24:34.123795 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:24:34.124799 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:24:34.124799 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:24:34.323238 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-1670-1ecf-9fd3-efb3c08c79e0) - Created
[0m11:24:34.972696 [debug] [Thread-1 (]: SQL status: OK in 0.850 seconds
[0m11:24:34.974696 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-1670-1ecf-9fd3-efb3c08c79e0, command-id=01f0aff2-1679-1eb5-b833-b25236be207b) - Closing
[0m11:24:34.975696 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:24:34.976696 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-1670-1ecf-9fd3-efb3c08c79e0) - Closing
[0m11:24:35.048047 [info ] [Thread-1 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.94s]
[0m11:24:35.049048 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:24:35.049048 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:24:35.050051 [info ] [Thread-1 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m11:24:35.050051 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:24:35.051048 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:24:35.051048 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:24:35.058048 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:24:35.059048 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:24:35.062047 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:24:35.062047 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:24:35.063048 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:24:35.063048 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:24:35.252627 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-16fc-177d-85d1-6b401af4ce87) - Created
[0m11:24:35.998203 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m11:24:36.001272 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-16fc-177d-85d1-6b401af4ce87, command-id=01f0aff2-1709-1979-9e3e-a7e7597c86cf) - Closing
[0m11:24:36.001272 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:24:36.002288 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-16fc-177d-85d1-6b401af4ce87) - Closing
[0m11:24:36.076654 [info ] [Thread-1 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.03s]
[0m11:24:36.077740 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:24:36.077740 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:24:36.077740 [info ] [Thread-1 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m11:24:36.078832 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:24:36.078832 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m11:24:36.078832 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:24:36.084167 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:24:36.084167 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:24:36.086234 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:24:36.087411 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:24:36.088410 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:24:36.088410 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:24:36.285028 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-1798-1e6c-b576-bacfdee03e62) - Created
[0m11:24:36.854211 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m11:24:36.856326 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-1798-1e6c-b576-bacfdee03e62, command-id=01f0aff2-17aa-11e6-b898-28576145d30b) - Closing
[0m11:24:36.857412 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:24:36.857412 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-1798-1e6c-b576-bacfdee03e62) - Closing
[0m11:24:36.930848 [info ] [Thread-1 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.85s]
[0m11:24:36.931890 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:24:36.932890 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:24:36.932890 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:24:36.932890 [info ] [MainThread]: 
[0m11:24:36.933994 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 27.62 seconds (27.62s).
[0m11:24:36.935022 [debug] [MainThread]: Command end result
[0m11:24:37.083540 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:24:37.085541 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:24:37.092542 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m11:24:37.092542 [info ] [MainThread]: 
[0m11:24:37.093541 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m11:24:37.093541 [info ] [MainThread]: 
[0m11:24:37.094661 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMart_Manhatten__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models\bronze\properties.yml)[0m
[0m11:24:37.094661 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m11:24:37.094661 [info ] [MainThread]: 
[0m11:24:37.096080 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\properties.yml\accepted_values_bronze_store_de7a7d58aefd439788a5ccee808cb498.sql
[0m11:24:37.096080 [info ] [MainThread]: 
[0m11:24:37.096080 [info ] [MainThread]: Done. PASS=4 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m11:24:37.097123 [debug] [MainThread]: Command `dbt test` succeeded at 11:24:37.097123 after 30.02 seconds
[0m11:24:37.098230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1D0C8E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF1D897AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EF403C8D10>]}
[0m11:24:37.098230 [debug] [MainThread]: Flushing usage events
[0m11:24:37.790928 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:26:42.192741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDCB54500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDCF86C60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDCF858B0>]}


============================== 11:26:42.196744 | 6bd2300a-004e-4117-8426-016e64ad4f80 ==============================
[0m11:26:42.196744 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:26:42.196744 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt test', 'printer_width': '80', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'log_format': 'default', 'write_json': 'True', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m11:26:42.984888 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:26:42.985888 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:26:42.985888 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:26:43.639327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDDC1F8C0>]}
[0m11:26:43.695793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC80C86000>]}
[0m11:26:43.695793 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:26:43.984406 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:26:44.130284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:26:44.130284 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:26:44.137597 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m11:26:44.175087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC80EBDAC0>]}
[0m11:26:44.254342 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:26:44.260396 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:26:44.276832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC813B9E20>]}
[0m11:26:44.276832 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 700 macros
[0m11:26:44.278339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEC6E900>]}
[0m11:26:44.279346 [info ] [MainThread]: 
[0m11:26:44.280346 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:26:44.280346 [info ] [MainThread]: 
[0m11:26:44.281346 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:26:44.281346 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:26:44.287358 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m11:26:44.288359 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m11:26:44.300232 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m11:26:44.301237 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m11:26:44.301237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:26:44.532912 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-640c-1016-9af2-b108740d245a) - Created
[0m11:26:45.189591 [debug] [ThreadPool]: SQL status: OK in 0.890 seconds
[0m11:26:45.194588 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0aff2-640c-1016-9af2-b108740d245a, command-id=01f0aff2-6416-159c-bf27-53778be7c989) - Closing
[0m11:26:45.195587 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m11:26:45.195587 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-640c-1016-9af2-b108740d245a) - Closing
[0m11:26:45.288474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bd2300a-004e-4117-8426-016e64ad4f80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC8137E360>]}
[0m11:26:45.291803 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:26:45.292803 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:26:45.292803 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m11:26:45.294167 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m11:26:45.294167 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:26:45.311442 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:26:45.312441 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:26:45.330296 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:26:45.331355 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:26:45.331355 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:26:45.331914 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:26:45.542495 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-64a3-1246-8608-3afa6183414a) - Created
[0m11:26:46.463425 [debug] [Thread-1 (]: SQL status: OK in 1.130 seconds
[0m11:26:46.465426 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-64a3-1246-8608-3afa6183414a, command-id=01f0aff2-64b1-16f7-ab16-5b35cd27e0e6) - Closing
[0m11:26:46.468480 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m11:26:46.468480 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-64a3-1246-8608-3afa6183414a) - Closing
[0m11:26:46.536548 [info ] [Thread-1 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.24s]
[0m11:26:46.537544 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:26:46.537544 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:26:46.538543 [info ] [Thread-1 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m11:26:46.539048 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:26:46.539048 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:26:46.540052 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:26:46.547058 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:26:46.547058 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:26:46.549572 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:26:46.550573 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:26:46.551579 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:26:46.551579 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:26:46.754061 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-655f-118c-8236-5505061d7ece) - Created
[0m11:26:47.038502 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m11:26:47.040777 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-655f-118c-8236-5505061d7ece, command-id=01f0aff2-6568-1416-83b9-51fb483b0892) - Closing
[0m11:26:47.040777 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:26:47.041793 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-655f-118c-8236-5505061d7ece) - Closing
[0m11:26:47.116670 [info ] [Thread-1 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.58s]
[0m11:26:47.117669 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:26:47.118673 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:26:47.118673 [info ] [Thread-1 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m11:26:47.119179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:26:47.119179 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:26:47.120183 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:26:47.124772 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:26:47.125784 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:26:47.130352 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:26:47.131367 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:26:47.131367 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:26:47.132519 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:26:47.306185 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-65b3-1137-b070-54ed6cd692a5) - Created
[0m11:26:47.593581 [debug] [Thread-1 (]: SQL status: OK in 0.460 seconds
[0m11:26:47.595630 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-65b3-1137-b070-54ed6cd692a5, command-id=01f0aff2-65bc-1926-a44a-3ea63c65f69b) - Closing
[0m11:26:47.596629 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:26:47.596629 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-65b3-1137-b070-54ed6cd692a5) - Closing
[0m11:26:47.668354 [info ] [Thread-1 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.55s]
[0m11:26:47.668354 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:26:47.668354 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:26:47.669856 [info ] [Thread-1 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m11:26:47.669856 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:26:47.671190 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:26:47.671190 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:26:47.677246 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:26:47.678750 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:26:47.680802 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:26:47.680802 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:26:47.682011 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:26:47.682011 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:26:47.862807 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-6605-1e5a-98bb-1b9f46052aa3) - Created
[0m11:26:48.175367 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m11:26:48.177367 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-6605-1e5a-98bb-1b9f46052aa3, command-id=01f0aff2-6613-11e2-ab49-581ddd1dd634) - Closing
[0m11:26:48.177367 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:26:48.177367 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-6605-1e5a-98bb-1b9f46052aa3) - Closing
[0m11:26:48.249905 [info ] [Thread-1 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.58s]
[0m11:26:48.250905 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:26:48.251906 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:26:48.251906 [info ] [Thread-1 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m11:26:48.252907 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:26:48.252907 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m11:26:48.252907 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:26:48.256906 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:26:48.258412 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:26:48.261427 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:26:48.262427 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:26:48.262427 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:26:48.262427 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:26:48.428338 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-665f-16f1-831b-830257185c8f) - Created
[0m11:26:48.620461 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m11:26:48.621460 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-665f-16f1-831b-830257185c8f, command-id=01f0aff2-6668-1173-9b98-8b46fa2360f1) - Closing
[0m11:26:48.622900 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:26:48.622900 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-665f-16f1-831b-830257185c8f) - Closing
[0m11:26:48.712332 [info ] [Thread-1 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.46s]
[0m11:26:48.713332 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:26:48.714332 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:26:48.715394 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:26:48.715394 [info ] [MainThread]: 
[0m11:26:48.715394 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 4.44 seconds (4.44s).
[0m11:26:48.716745 [debug] [MainThread]: Command end result
[0m11:26:48.866893 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:26:48.869813 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:26:48.876527 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m11:26:48.877971 [info ] [MainThread]: 
[0m11:26:48.878478 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:26:48.878478 [info ] [MainThread]: 
[0m11:26:48.878478 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m11:26:48.879627 [debug] [MainThread]: Command `dbt test` succeeded at 11:26:48.879627 after 6.80 seconds
[0m11:26:48.879627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDCEFB890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCDCEF9A30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC814C7800>]}
[0m11:26:48.880739 [debug] [MainThread]: Flushing usage events
[0m11:26:49.548384 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:27:41.731362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F19344A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F199C6750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F199C6660>]}


============================== 11:27:41.735365 | 7edb7a9d-8120-4321-9667-47f35862dff3 ==============================
[0m11:27:41.735365 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:27:41.735365 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'printer_width': '80', 'use_colors': 'True', 'log_format': 'default', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m11:27:42.526451 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:27:42.527451 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:27:42.527451 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:27:43.177005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F3CFB29C0>]}
[0m11:27:43.233486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F1995FF80>]}
[0m11:27:43.234485 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:27:43.522616 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:27:43.669599 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:27:43.669599 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:27:43.676177 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m11:27:43.713378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F3D173AD0>]}
[0m11:27:43.792893 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:27:43.795087 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:27:43.812932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F3D6F6810>]}
[0m11:27:43.812932 [info ] [MainThread]: Found 6 models, 6 data tests, 6 sources, 700 macros
[0m11:27:43.812932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F3D378890>]}
[0m11:27:43.815256 [info ] [MainThread]: 
[0m11:27:43.816292 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:27:43.816292 [info ] [MainThread]: 
[0m11:27:43.817304 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:27:43.817304 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:27:43.823216 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m11:27:43.824218 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m11:27:43.836707 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m11:27:43.837734 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m11:27:43.837734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:27:44.061649 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-8787-1eb9-858d-3476e6a9297e) - Created
[0m11:27:44.569507 [debug] [ThreadPool]: SQL status: OK in 0.730 seconds
[0m11:27:44.574068 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0aff2-8787-1eb9-858d-3476e6a9297e, command-id=01f0aff2-8791-1303-a0f1-1664a4f5a659) - Closing
[0m11:27:44.574068 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m11:27:44.575069 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff2-8787-1eb9-858d-3476e6a9297e) - Closing
[0m11:27:44.680741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7edb7a9d-8120-4321-9667-47f35862dff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F16FC8230>]}
[0m11:27:44.683881 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:27:44.685061 [info ] [Thread-1 (]: 1 of 6 START test accepted_values_bronze_store_country__USA__Canada ............ [RUN]
[0m11:27:44.685061 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7) - Creating connection
[0m11:27:44.686061 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7'
[0m11:27:44.686061 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:27:44.703029 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:27:44.704029 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:27:44.720633 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:27:44.721634 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:27:44.722634 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        country as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by country

)

select *
from all_values
where value_field not in (
    'USA','Canada'
)



  
  
      
    ) dbt_internal_test
[0m11:27:44.722634 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:44.891707 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8806-1ff9-b65c-1840034972ce) - Created
[0m11:27:45.383977 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m11:27:45.386142 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-8806-1ff9-b65c-1840034972ce, command-id=01f0aff2-880f-191b-b814-ac231567bcac) - Closing
[0m11:27:45.389277 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: Close
[0m11:27:45.389277 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8806-1ff9-b65c-1840034972ce) - Closing
[0m11:27:45.462483 [info ] [Thread-1 (]: 1 of 6 PASS accepted_values_bronze_store_country__USA__Canada .................. [[32mPASS[0m in 0.78s]
[0m11:27:45.463482 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:27:45.463482 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:27:45.464481 [info ] [Thread-1 (]: 2 of 6 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:27:45.464481 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m11:27:45.465512 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m11:27:45.465512 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:27:45.472642 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:27:45.473643 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:27:45.475642 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:27:45.475642 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:27:45.476644 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:27:45.476644 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:45.661837 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8879-1e99-a46e-bba6bea8d18a) - Created
[0m11:27:45.856066 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m11:27:45.858065 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-8879-1e99-a46e-bba6bea8d18a, command-id=01f0aff2-8885-10ec-be5d-474396234485) - Closing
[0m11:27:45.859569 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m11:27:45.859569 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8879-1e99-a46e-bba6bea8d18a) - Closing
[0m11:27:45.929308 [info ] [Thread-1 (]: 2 of 6 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.46s]
[0m11:27:45.930388 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:27:45.931405 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:27:45.931405 [info ] [Thread-1 (]: 3 of 6 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m11:27:45.932405 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:27:45.932405 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:27:45.932405 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:27:45.940006 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:27:45.940006 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:27:45.944007 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:27:45.945007 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:27:45.945007 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:27:45.946009 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:46.113868 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-88c1-10ee-bb34-c2a4cbd061a2) - Created
[0m11:27:46.382875 [debug] [Thread-1 (]: SQL status: OK in 0.440 seconds
[0m11:27:46.384872 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-88c1-10ee-bb34-c2a4cbd061a2, command-id=01f0aff2-88c9-16da-9751-af5578b6786d) - Closing
[0m11:27:46.384872 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:27:46.384872 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-88c1-10ee-bb34-c2a4cbd061a2) - Closing
[0m11:27:46.465777 [info ] [Thread-1 (]: 3 of 6 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.53s]
[0m11:27:46.466776 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:27:46.466776 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:27:46.467780 [info ] [Thread-1 (]: 4 of 6 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m11:27:46.467780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:27:46.467780 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:27:46.469284 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:27:46.473540 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:27:46.474635 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:27:46.476727 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:27:46.476727 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:27:46.477772 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:27:46.477772 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:46.657151 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8913-117b-b87e-bea594538f86) - Created
[0m11:27:46.845504 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m11:27:46.847012 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-8913-117b-b87e-bea594538f86, command-id=01f0aff2-891c-1c21-8712-c6780fedb941) - Closing
[0m11:27:46.848023 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:27:46.848023 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8913-117b-b87e-bea594538f86) - Closing
[0m11:27:46.926634 [info ] [Thread-1 (]: 4 of 6 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.46s]
[0m11:27:46.927681 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:27:46.927681 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:27:46.928680 [info ] [Thread-1 (]: 5 of 6 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m11:27:46.928680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:27:46.929681 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:27:46.929681 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:27:46.935937 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:27:46.937092 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:27:46.939626 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:27:46.939626 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:27:46.939626 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:27:46.940695 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:47.118080 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8959-1072-8657-5ecb56e0fbd5) - Created
[0m11:27:47.419610 [debug] [Thread-1 (]: SQL status: OK in 0.480 seconds
[0m11:27:47.421615 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-8959-1072-8657-5ecb56e0fbd5, command-id=01f0aff2-8962-1fa6-924d-583faf272526) - Closing
[0m11:27:47.422631 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:27:47.422631 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-8959-1072-8657-5ecb56e0fbd5) - Closing
[0m11:27:47.495134 [info ] [Thread-1 (]: 5 of 6 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.57s]
[0m11:27:47.496234 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:27:47.496234 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:27:47.497336 [info ] [Thread-1 (]: 6 of 6 START test unique_bronze_store_store_sk ................................. [RUN]
[0m11:27:47.497336 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:27:47.497336 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m11:27:47.498336 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:27:47.502212 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:27:47.503241 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:27:47.505276 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:27:47.506306 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:27:47.506306 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:27:47.506306 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:27:47.685157 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-89ae-1e2f-8266-78f93d7f425b) - Created
[0m11:27:47.901784 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m11:27:47.903776 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff2-89ae-1e2f-8266-78f93d7f425b, command-id=01f0aff2-89ba-1e1a-a005-df17f70b666a) - Closing
[0m11:27:47.904777 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:27:47.904777 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff2-89ae-1e2f-8266-78f93d7f425b) - Closing
[0m11:27:47.977440 [info ] [Thread-1 (]: 6 of 6 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.48s]
[0m11:27:47.978438 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:27:47.979439 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:27:47.979949 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:27:47.979949 [info ] [MainThread]: 
[0m11:27:47.979949 [info ] [MainThread]: Finished running 6 data tests in 0 hours 0 minutes and 4.16 seconds (4.16s).
[0m11:27:47.981949 [debug] [MainThread]: Command end result
[0m11:27:48.114188 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:27:48.116188 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:27:48.122811 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m11:27:48.122811 [info ] [MainThread]: 
[0m11:27:48.123808 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:27:48.123808 [info ] [MainThread]: 
[0m11:27:48.123808 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m11:27:48.125140 [debug] [MainThread]: Command `dbt test` succeeded at 11:27:48.125140 after 6.50 seconds
[0m11:27:48.126168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F19500E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F198EB9B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F3D58CE60>]}
[0m11:27:48.126168 [debug] [MainThread]: Flushing usage events
[0m11:27:48.772520 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:41:56.255494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB784DC560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7B0B7E60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7B0B7C50>]}


============================== 11:41:56.259582 | 5fcfa846-4e15-45e0-a555-cde38df5d421 ==============================
[0m11:41:56.259582 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:41:56.259582 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'use_colors': 'True', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'no_print': 'None', 'cache_selected_only': 'False', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt test', 'printer_width': '80', 'write_json': 'True'}
[0m11:41:57.038019 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:41:57.038019 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:41:57.038019 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:41:57.826525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7E66CEC0>]}
[0m11:41:57.881498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB1E748590>]}
[0m11:41:57.882502 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m11:41:58.180996 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:41:58.331934 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:41:58.332934 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:41:58.339448 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m11:41:58.380950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB1E2A4890>]}
[0m11:41:58.470469 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:41:58.473102 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:41:58.490812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB1EEA4A10>]}
[0m11:41:58.490812 [info ] [MainThread]: Found 6 models, 7 data tests, 6 sources, 700 macros
[0m11:41:58.492168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7AEA7320>]}
[0m11:41:58.494190 [info ] [MainThread]: 
[0m11:41:58.494190 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:41:58.494190 [info ] [MainThread]: 
[0m11:41:58.495694 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:41:58.495694 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:41:58.501702 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m11:41:58.501702 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m11:41:58.515741 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m11:41:58.515741 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m11:41:58.516746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:41:58.754143 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff4-84f4-10ca-823b-889e7c61c787) - Created
[0m11:41:59.209668 [debug] [ThreadPool]: SQL status: OK in 0.690 seconds
[0m11:41:59.215062 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0aff4-84f4-10ca-823b-889e7c61c787, command-id=01f0aff4-84ff-1e93-89be-b5ebfb32329d) - Closing
[0m11:41:59.215566 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m11:41:59.215566 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0aff4-84f4-10ca-823b-889e7c61c787) - Closing
[0m11:41:59.290958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fcfa846-4e15-45e0-a555-cde38df5d421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB1EB2E6F0>]}
[0m11:41:59.294958 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:41:59.294958 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_bronze_store_country__USA__Canada ............ [RUN]
[0m11:41:59.295771 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7) - Creating connection
[0m11:41:59.295771 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7'
[0m11:41:59.296776 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:41:59.310791 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:41:59.311793 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:41:59.334228 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:41:59.334228 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m11:41:59.335660 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        country as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by country

)

select *
from all_values
where value_field not in (
    'USA','Canada'
)



  
  
      
    ) dbt_internal_test
[0m11:41:59.335660 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:41:59.503708 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8569-1bcf-808c-5587ff8aa3d7) - Created
[0m11:41:59.738854 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m11:41:59.740854 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-8569-1bcf-808c-5587ff8aa3d7, command-id=01f0aff4-8575-134b-81cc-ca59da0b4b27) - Closing
[0m11:41:59.743854 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: Close
[0m11:41:59.743854 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8569-1bcf-808c-5587ff8aa3d7) - Closing
[0m11:41:59.819719 [info ] [Thread-1 (]: 1 of 7 PASS accepted_values_bronze_store_country__USA__Canada .................. [[32mPASS[0m in 0.52s]
[0m11:41:59.820718 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m11:41:59.820718 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:41:59.821718 [info ] [Thread-1 (]: 2 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:41:59.821718 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m11:41:59.822718 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m11:41:59.822718 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:41:59.830039 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:41:59.831040 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:41:59.833040 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:41:59.834041 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:41:59.834041 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:41:59.834041 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:00.027255 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-85b6-15a7-80f8-0b0b79999802) - Created
[0m11:42:00.261930 [debug] [Thread-1 (]: SQL status: OK in 0.430 seconds
[0m11:42:00.262929 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-85b6-15a7-80f8-0b0b79999802, command-id=01f0aff4-85c2-1342-a904-100920bc3260) - Closing
[0m11:42:00.263931 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m11:42:00.263931 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-85b6-15a7-80f8-0b0b79999802) - Closing
[0m11:42:00.338095 [info ] [Thread-1 (]: 2 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.52s]
[0m11:42:00.339092 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:42:00.339092 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.non_negative_test
[0m11:42:00.340093 [info ] [Thread-1 (]: 3 of 7 START test non_negative_test ............................................ [RUN]
[0m11:42:00.340093 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.non_negative_test) - Creating connection
[0m11:42:00.341093 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.non_negative_test'
[0m11:42:00.341093 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.non_negative_test
[0m11:42:00.344093 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.non_negative_test"
[0m11:42:00.404321 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.non_negative_test
[0m11:42:00.408685 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.non_negative_test"
[0m11:42:00.409686 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.non_negative_test"
[0m11:42:00.409686 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.non_negative_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM 
    `dbt_tutorial_dev`.`bronze`.`bronze_sales`
WHERE 
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m11:42:00.409686 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:00.649682 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8615-159f-a7e8-af0ddd8ac485) - Created
[0m11:42:01.342306 [debug] [Thread-1 (]: SQL status: OK in 0.930 seconds
[0m11:42:01.345813 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-8615-159f-a7e8-af0ddd8ac485, command-id=01f0aff4-8628-189d-b713-0364fb9e4444) - Closing
[0m11:42:01.347247 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: Close
[0m11:42:01.347247 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8615-159f-a7e8-af0ddd8ac485) - Closing
[0m11:42:01.439071 [info ] [Thread-1 (]: 3 of 7 PASS non_negative_test .................................................. [[32mPASS[0m in 1.10s]
[0m11:42:01.439071 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.non_negative_test
[0m11:42:01.440071 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:42:01.440071 [info ] [Thread-1 (]: 4 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m11:42:01.441072 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:42:01.441072 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:42:01.441072 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:42:01.448581 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:42:01.449582 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:42:01.451627 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:42:01.452663 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:42:01.453664 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:42:01.453664 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:01.716444 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-86b9-1d73-b50b-aefe76b20f91) - Created
[0m11:42:01.923142 [debug] [Thread-1 (]: SQL status: OK in 0.470 seconds
[0m11:42:01.924142 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-86b9-1d73-b50b-aefe76b20f91, command-id=01f0aff4-86c4-12f6-b88b-82671e117cd5) - Closing
[0m11:42:01.925646 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:42:01.925646 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-86b9-1d73-b50b-aefe76b20f91) - Closing
[0m11:42:02.008088 [info ] [Thread-1 (]: 4 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.57s]
[0m11:42:02.008088 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:42:02.009088 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:42:02.009088 [info ] [Thread-1 (]: 5 of 7 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m11:42:02.010088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:42:02.010088 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:42:02.010088 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:42:02.014088 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:42:02.015592 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:42:02.017597 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:42:02.018641 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:42:02.018641 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:42:02.018641 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:02.402222 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8722-1922-89d3-95a29c5f3388) - Created
[0m11:42:02.609828 [debug] [Thread-1 (]: SQL status: OK in 0.590 seconds
[0m11:42:02.611828 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-8722-1922-89d3-95a29c5f3388, command-id=01f0aff4-872c-1bc9-be85-56672e4e2ee4) - Closing
[0m11:42:02.612829 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:42:02.612829 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-8722-1922-89d3-95a29c5f3388) - Closing
[0m11:42:02.692805 [info ] [Thread-1 (]: 5 of 7 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.68s]
[0m11:42:02.693805 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m11:42:02.693805 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:42:02.693805 [info ] [Thread-1 (]: 6 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m11:42:02.694804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:42:02.694804 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:42:02.695805 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:42:02.701313 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:42:02.701313 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:42:02.704315 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:42:02.704315 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:42:02.704315 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:42:02.705697 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:03.013969 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-877f-12a4-9d91-8a24f7fdfc8a) - Created
[0m11:42:03.442310 [debug] [Thread-1 (]: SQL status: OK in 0.740 seconds
[0m11:42:03.444310 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-877f-12a4-9d91-8a24f7fdfc8a, command-id=01f0aff4-878c-1e7a-a57b-3834e9f63fe3) - Closing
[0m11:42:03.444310 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:42:03.444310 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-877f-12a4-9d91-8a24f7fdfc8a) - Closing
[0m11:42:03.560241 [info ] [Thread-1 (]: 6 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.87s]
[0m11:42:03.561240 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m11:42:03.561240 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:42:03.562247 [info ] [Thread-1 (]: 7 of 7 START test unique_bronze_store_store_sk ................................. [RUN]
[0m11:42:03.562247 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:42:03.563240 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m11:42:03.563240 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:42:03.566749 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:42:03.567750 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:42:03.574129 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:42:03.574129 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m11:42:03.575645 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:42:03.575645 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:42:04.053348 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-881c-1a3f-af7b-202eacf2ce5b) - Created
[0m11:42:04.264233 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m11:42:04.266742 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0aff4-881c-1a3f-af7b-202eacf2ce5b, command-id=01f0aff4-8828-163f-9376-89571926ccdc) - Closing
[0m11:42:04.267742 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:42:04.267742 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0aff4-881c-1a3f-af7b-202eacf2ce5b) - Closing
[0m11:42:04.347349 [info ] [Thread-1 (]: 7 of 7 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.79s]
[0m11:42:04.348348 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m11:42:04.349347 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:42:04.350348 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:42:04.350348 [info ] [MainThread]: 
[0m11:42:04.350348 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 5.86 seconds (5.86s).
[0m11:42:04.352348 [debug] [MainThread]: Command end result
[0m11:42:04.378383 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m11:42:04.381845 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m11:42:04.387658 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m11:42:04.389075 [info ] [MainThread]: 
[0m11:42:04.389075 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:42:04.390121 [info ] [MainThread]: 
[0m11:42:04.390121 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m11:42:04.391135 [debug] [MainThread]: Command `dbt test` succeeded at 11:42:04.391135 after 8.24 seconds
[0m11:42:04.391135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7A9B6990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7B599A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB7B599A60>]}
[0m11:42:04.392134 [debug] [MainThread]: Flushing usage events
[0m11:42:05.079131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:46:10.873026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021768330260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002176A884EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002176A886DB0>]}


============================== 13:46:10.876842 | 11e31fe1-879e-4a1e-bca5-ab27cb7183cb ==============================
[0m13:46:10.876842 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:46:10.877858 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'target_path': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'write_json': 'True'}
[0m13:46:11.658991 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:46:11.659990 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:46:11.659990 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:46:12.650331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002176AECCEF0>]}
[0m13:46:12.705785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170E61C290>]}
[0m13:46:12.706783 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m13:46:13.010316 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:46:13.163284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:46:13.163284 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:46:13.170471 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.gold
- models.octy_dbt_learn.silver
[0m13:46:13.213172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002177FC2D790>]}
[0m13:46:13.300999 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m13:46:13.303014 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m13:46:13.321874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170EC840B0>]}
[0m13:46:13.321874 [info ] [MainThread]: Found 6 models, 8 data tests, 6 sources, 701 macros
[0m13:46:13.323381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170ECC9580>]}
[0m13:46:13.324522 [info ] [MainThread]: 
[0m13:46:13.325533 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:46:13.325533 [info ] [MainThread]: 
[0m13:46:13.326535 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:46:13.326535 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:46:13.333041 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m13:46:13.333041 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m13:46:13.345248 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m13:46:13.346303 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m13:46:13.346303 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:46:13.921383 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b005-e06b-135d-ab85-3cc22d0cbad1) - Created
[0m13:46:27.898610 [debug] [ThreadPool]: SQL status: OK in 14.550 seconds
[0m13:46:27.904670 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b005-e06b-135d-ab85-3cc22d0cbad1, command-id=01f0b005-e098-167a-bd95-75217b449fb7) - Closing
[0m13:46:28.103875 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m13:46:28.103875 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b005-e06b-135d-ab85-3cc22d0cbad1) - Closing
[0m13:46:28.174104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11e31fe1-879e-4a1e-bca5-ab27cb7183cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170E0D46B0>]}
[0m13:46:28.178649 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m13:46:28.178649 [info ] [Thread-1 (]: 1 of 8 START test accepted_values_bronze_store_country__USA__Canada ............ [RUN]
[0m13:46:28.179649 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7) - Creating connection
[0m13:46:28.179649 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7'
[0m13:46:28.180694 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m13:46:28.198500 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m13:46:28.200561 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m13:46:28.221854 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m13:46:28.221854 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m13:46:28.221854 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        country as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by country

)

select *
from all_values
where value_field not in (
    'USA','Canada'
)



  
  
      
    ) dbt_internal_test
[0m13:46:28.223460 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:28.457455 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-e934-1a92-88b0-6b906b9e7f3a) - Created
[0m13:46:35.206037 [debug] [Thread-1 (]: SQL status: OK in 6.980 seconds
[0m13:46:35.209517 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-e934-1a92-88b0-6b906b9e7f3a, command-id=01f0b005-e940-1216-8819-4217387dd3e3) - Closing
[0m13:46:35.303259 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: Close
[0m13:46:35.304344 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-e934-1a92-88b0-6b906b9e7f3a) - Closing
[0m13:46:35.378877 [info ] [Thread-1 (]: 1 of 8 PASS accepted_values_bronze_store_country__USA__Canada .................. [[32mPASS[0m in 7.20s]
[0m13:46:35.379876 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m13:46:35.379876 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:46:35.380876 [info ] [Thread-1 (]: 2 of 8 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m13:46:35.381924 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m13:46:35.381924 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m13:46:35.381924 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:46:35.389442 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:46:35.390823 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:46:35.393866 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:46:35.394883 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:46:35.394883 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m13:46:35.396093 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:35.619779 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-ed78-1498-b0b8-4b83ace79803) - Created
[0m13:46:36.750121 [debug] [Thread-1 (]: SQL status: OK in 1.350 seconds
[0m13:46:36.752126 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-ed78-1498-b0b8-4b83ace79803, command-id=01f0b005-ed84-17d1-a08c-ccc5ff542941) - Closing
[0m13:46:36.752126 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m13:46:36.753126 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-ed78-1498-b0b8-4b83ace79803) - Closing
[0m13:46:36.825485 [info ] [Thread-1 (]: 2 of 8 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.44s]
[0m13:46:36.826989 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:46:36.826989 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:46:36.828161 [info ] [Thread-1 (]: 3 of 8 START test generic_non_negative_bronze_sales_gross_amount ............... [RUN]
[0m13:46:36.829158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m13:46:36.829158 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m13:46:36.829158 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:46:36.838955 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:46:36.840210 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:46:36.843495 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:46:36.845847 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m13:46:36.845847 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

    SELECT
        *
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
    WHERE 
        gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m13:46:36.845847 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:37.051126 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-ee53-194b-9818-eb9849529dc6) - Created
[0m13:46:39.556739 [debug] [Thread-1 (]: SQL status: OK in 2.710 seconds
[0m13:46:39.558738 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-ee53-194b-9818-eb9849529dc6, command-id=01f0b005-ee5f-190e-a93b-17175044e373) - Closing
[0m13:46:39.559739 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m13:46:39.560738 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-ee53-194b-9818-eb9849529dc6) - Closing
[0m13:46:39.638364 [info ] [Thread-1 (]: 3 of 8 PASS generic_non_negative_bronze_sales_gross_amount ..................... [[32mPASS[0m in 2.81s]
[0m13:46:39.639363 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m13:46:39.639363 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.non_negative_test
[0m13:46:39.640363 [info ] [Thread-1 (]: 4 of 8 START test non_negative_test ............................................ [RUN]
[0m13:46:39.640363 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.non_negative_test) - Creating connection
[0m13:46:39.641363 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.non_negative_test'
[0m13:46:39.641363 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.non_negative_test
[0m13:46:39.644363 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.non_negative_test"
[0m13:46:39.645363 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.non_negative_test
[0m13:46:39.647364 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.non_negative_test"
[0m13:46:39.648362 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.non_negative_test"
[0m13:46:39.649625 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.non_negative_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM 
    `dbt_tutorial_dev`.`bronze`.`bronze_sales`
WHERE 
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m13:46:39.649625 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:39.822764 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-effe-10b6-8ecc-7047a745bea7) - Created
[0m13:46:40.679164 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m13:46:40.681165 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-effe-10b6-8ecc-7047a745bea7, command-id=01f0b005-f006-161f-8e8b-d3bebaa73d68) - Closing
[0m13:46:40.682165 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: Close
[0m13:46:40.682165 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-effe-10b6-8ecc-7047a745bea7) - Closing
[0m13:46:40.751725 [info ] [Thread-1 (]: 4 of 8 PASS non_negative_test .................................................. [[32mPASS[0m in 1.11s]
[0m13:46:40.752724 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.non_negative_test
[0m13:46:40.752724 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:46:40.753725 [info ] [Thread-1 (]: 5 of 8 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m13:46:40.753725 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m13:46:40.754724 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m13:46:40.754724 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:46:40.760724 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:46:40.761724 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:46:40.764489 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:46:40.765528 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:46:40.765528 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m13:46:40.766531 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:40.990406 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f0ab-1e56-9d80-b086fa1b4904) - Created
[0m13:46:41.874984 [debug] [Thread-1 (]: SQL status: OK in 1.110 seconds
[0m13:46:41.878201 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-f0ab-1e56-9d80-b086fa1b4904, command-id=01f0b005-f0ba-1755-b5f3-52653b69f111) - Closing
[0m13:46:41.879200 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m13:46:41.879200 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f0ab-1e56-9d80-b086fa1b4904) - Closing
[0m13:46:41.960826 [info ] [Thread-1 (]: 5 of 8 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.21s]
[0m13:46:41.961827 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:46:41.962827 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m13:46:41.962827 [info ] [Thread-1 (]: 6 of 8 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m13:46:41.963826 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m13:46:41.963826 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m13:46:41.964825 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m13:46:41.968825 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:46:41.968825 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m13:46:41.972219 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:46:41.973233 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:46:41.973233 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m13:46:41.974630 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:42.152275 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f160-1e21-bc8c-c7b296c932e9) - Created
[0m13:46:42.718794 [debug] [Thread-1 (]: SQL status: OK in 0.740 seconds
[0m13:46:42.721797 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-f160-1e21-bc8c-c7b296c932e9, command-id=01f0b005-f16a-1054-86ef-ddfa0ef71787) - Closing
[0m13:46:42.722797 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m13:46:42.722797 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f160-1e21-bc8c-c7b296c932e9) - Closing
[0m13:46:42.793613 [info ] [Thread-1 (]: 6 of 8 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.83s]
[0m13:46:42.793613 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m13:46:42.794612 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m13:46:42.795613 [info ] [Thread-1 (]: 7 of 8 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m13:46:42.795613 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m13:46:42.796612 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m13:46:42.796612 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m13:46:42.810613 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:46:42.811622 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m13:46:42.932231 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:46:42.933736 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:46:42.933736 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:46:42.934741 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:43.114118 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f1f3-1bcb-bf2e-319513addd7a) - Created
[0m13:46:43.642949 [debug] [Thread-1 (]: SQL status: OK in 0.710 seconds
[0m13:46:43.645951 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-f1f3-1bcb-bf2e-319513addd7a, command-id=01f0b005-f1fd-16f4-97ec-ee525dac96a4) - Closing
[0m13:46:43.646950 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m13:46:43.646950 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f1f3-1bcb-bf2e-319513addd7a) - Closing
[0m13:46:43.729065 [info ] [Thread-1 (]: 7 of 8 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.93s]
[0m13:46:43.730070 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m13:46:43.730070 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m13:46:43.731069 [info ] [Thread-1 (]: 8 of 8 START test unique_bronze_store_store_sk ................................. [RUN]
[0m13:46:43.731069 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m13:46:43.732069 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m13:46:43.732069 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m13:46:43.736582 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m13:46:43.737582 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m13:46:43.740621 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m13:46:43.740621 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m13:46:43.741636 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:46:43.741636 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:46:43.927803 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f26f-1510-b134-8e12ccb2acb8) - Created
[0m13:46:44.524120 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m13:46:44.526121 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b005-f26f-1510-b134-8e12ccb2acb8, command-id=01f0b005-f27a-1ea5-8892-afef5fb0a6e4) - Closing
[0m13:46:44.527121 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m13:46:44.527121 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b005-f26f-1510-b134-8e12ccb2acb8) - Closing
[0m13:46:44.611354 [info ] [Thread-1 (]: 8 of 8 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.88s]
[0m13:46:44.612355 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m13:46:44.613355 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:46:44.613355 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:46:44.614356 [info ] [MainThread]: 
[0m13:46:44.614356 [info ] [MainThread]: Finished running 8 data tests in 0 hours 0 minutes and 31.29 seconds (31.29s).
[0m13:46:44.616354 [debug] [MainThread]: Command end result
[0m13:46:44.654746 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m13:46:44.657117 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m13:46:44.665560 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m13:46:44.665560 [info ] [MainThread]: 
[0m13:46:44.665560 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:46:44.666563 [info ] [MainThread]: 
[0m13:46:44.666563 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=8
[0m13:46:44.668560 [debug] [MainThread]: Command `dbt test` succeeded at 13:46:44.667561 after 33.91 seconds
[0m13:46:44.668560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002176AAF5EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002176AAF5EB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021768CB3260>]}
[0m13:46:44.668560 [debug] [MainThread]: Flushing usage events
[0m13:46:45.381883 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:55:30.755574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9B6F7D700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BA69F170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BAC87860>]}


============================== 13:55:30.762399 | 1b31c28c-d7bc-4777-b7a0-ae984b772d96 ==============================
[0m13:55:30.762399 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:55:30.763744 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'invocation_command': 'dbt seed', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'write_json': 'True', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m13:55:31.668885 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:55:31.668885 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:55:31.670034 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:55:32.344141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BDA1C050>]}
[0m13:55:32.402626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9DDBE7470>]}
[0m13:55:32.402626 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m13:55:32.697446 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:55:32.862612 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:55:32.862612 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:55:32.869891 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.octy_dbt_learn.silver
- models.octy_dbt_learn.gold
[0m13:55:32.918067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9DE4F59A0>]}
[0m13:55:33.010805 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m13:55:33.012808 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m13:55:33.055486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9DE6D2DB0>]}
[0m13:55:33.055486 [info ] [MainThread]: Found 6 models, 8 data tests, 1 seed, 6 sources, 701 macros
[0m13:55:33.055486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9DE309880>]}
[0m13:55:33.057683 [info ] [MainThread]: 
[0m13:55:33.057683 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:55:33.058779 [info ] [MainThread]: 
[0m13:55:33.058779 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:55:33.058779 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:55:33.059817 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m13:55:33.059817 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m13:55:33.070108 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m13:55:33.071110 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m13:55:33.071110 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:55:33.275866 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b007-2df1-1898-9df2-05910f911539) - Created
[0m13:55:33.792387 [debug] [ThreadPool]: SQL status: OK in 0.720 seconds
[0m13:55:33.795476 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b007-2df1-1898-9df2-05910f911539, command-id=01f0b007-2dfb-1c53-8041-2110509a1adc) - Closing
[0m13:55:33.796756 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m13:55:33.796756 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b007-2df1-1898-9df2-05910f911539) - Closing
[0m13:55:33.884772 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m13:55:33.884772 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m13:55:33.892432 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m13:55:33.893487 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m13:55:33.893487 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:55:34.083050 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b007-2e6a-1898-a735-848c3b08ce6c) - Created
[0m13:55:34.680524 [debug] [ThreadPool]: SQL status: OK in 0.790 seconds
[0m13:55:34.682870 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b007-2e6a-1898-a735-848c3b08ce6c, command-id=01f0b007-2e76-1f11-9c9f-a14693fce006) - Closing
[0m13:55:34.682870 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m13:55:34.683867 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b007-2e6a-1898-a735-848c3b08ce6c) - Closing
[0m13:55:34.756549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BACC6420>]}
[0m13:55:34.760551 [debug] [Thread-1 (]: Began running node seed.octy_dbt_learn.lookup
[0m13:55:34.760551 [info ] [Thread-1 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m13:55:34.761551 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.octy_dbt_learn.lookup) - Creating connection
[0m13:55:34.761551 [debug] [Thread-1 (]: Acquiring new databricks connection 'seed.octy_dbt_learn.lookup'
[0m13:55:34.762550 [debug] [Thread-1 (]: Began compiling node seed.octy_dbt_learn.lookup
[0m13:55:34.762550 [debug] [Thread-1 (]: Began executing node seed.octy_dbt_learn.lookup
[0m13:55:34.766590 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m13:55:34.767591 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9DE9D8E60>]}
[0m13:55:34.815668 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m13:55:34.816179 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "seed.octy_dbt_learn.lookup"} */

    create  table `dbt_tutorial_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m13:55:34.816179 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:55:34.988278 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b007-2ef8-11fe-8d99-eff46e9b2c84) - Created
[0m13:55:38.349118 [debug] [Thread-1 (]: SQL status: OK in 3.530 seconds
[0m13:55:38.350148 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b007-2ef8-11fe-8d99-eff46e9b2c84, command-id=01f0b007-2f00-190c-95bf-33d091c12c02) - Closing
[0m13:55:38.362655 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m13:55:38.362655 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: 
          insert overwrite `dbt_tutorial_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m13:55:42.163479 [debug] [Thread-1 (]: SQL status: OK in 3.800 seconds
[0m13:55:42.163479 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b007-2ef8-11fe-8d99-eff46e9b2c84, command-id=01f0b007-3103-1e62-93b8-dd9ba1568eaa) - Closing
[0m13:55:42.170016 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.octy_dbt_learn.lookup"
[0m13:55:42.188920 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: Close
[0m13:55:42.188920 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b007-2ef8-11fe-8d99-eff46e9b2c84) - Closing
[0m13:55:42.330033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b31c28c-d7bc-4777-b7a0-ae984b772d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9B81F8500>]}
[0m13:55:42.331485 [info ] [Thread-1 (]: 1 of 1 OK loaded seed file bronze.lookup ....................................... [[32mINSERT 3[0m in 7.50s]
[0m13:55:42.331485 [debug] [Thread-1 (]: Finished running node seed.octy_dbt_learn.lookup
[0m13:55:42.332932 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:55:42.334146 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:55:42.334146 [info ] [MainThread]: 
[0m13:55:42.334146 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 9.28 seconds (9.28s).
[0m13:55:42.335205 [debug] [MainThread]: Command end result
[0m13:55:42.378465 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m13:55:42.381481 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m13:55:42.388129 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m13:55:42.389162 [info ] [MainThread]: 
[0m13:55:42.389162 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:55:42.389162 [info ] [MainThread]: 
[0m13:55:42.390470 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m13:55:42.391484 [debug] [MainThread]: Command `dbt seed` succeeded at 13:55:42.390470 after 11.85 seconds
[0m13:55:42.391484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BAD98EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BB0AC950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9BDEC5EB0>]}
[0m13:55:42.391484 [debug] [MainThread]: Flushing usage events
[0m13:55:43.098862 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:49:00.383978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37106AF00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37099E150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37099F3B0>]}


============================== 15:49:00.388046 | ffb97b01-467d-4ebc-a57b-b7b2902cddb3 ==============================
[0m15:49:00.388046 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:49:00.389061 [debug] [MainThread]: running dbt with arguments {'profiles_dir': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'no_print': 'None', 'printer_width': '80', 'write_json': 'True', 'invocation_command': 'dbt ', 'warn_error': 'None', 'log_path': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m15:49:00.502995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffb97b01-467d-4ebc-a57b-b7b2902cddb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37106B770>]}
[0m15:49:00.520847 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:49:00.521851 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:49:00.522851 [debug] [MainThread]: Command `cli deps` succeeded at 15:49:00.522851 after 0.25 seconds
[0m15:49:00.522851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B3716D0AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B3716D3FB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B371520320>]}
[0m15:49:00.522851 [debug] [MainThread]: Flushing usage events
[0m15:49:01.178352 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:49:45.671940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F53EB4650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F5634E7E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F563FDD60>]}


============================== 15:49:45.675942 | bf2a86f5-a265-4ba3-a155-7f1691604543 ==============================
[0m15:49:45.675942 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:49:45.675942 [debug] [MainThread]: running dbt with arguments {'profiles_dir': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'printer_width': '80', 'no_print': 'None', 'write_json': 'True', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'log_path': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt ', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m15:49:45.793089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf2a86f5-a265-4ba3-a155-7f1691604543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F56FB6240>]}
[0m15:49:45.810169 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:49:45.811170 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:49:45.812170 [debug] [MainThread]: Command `cli deps` succeeded at 15:49:45.812170 after 0.25 seconds
[0m15:49:45.812170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F562F6F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F571A9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F583686E0>]}
[0m15:49:45.813170 [debug] [MainThread]: Flushing usage events
[0m15:49:46.485458 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:50:32.555237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DF384560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E248A5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E25809E0>]}


============================== 15:50:32.559256 | 6dc164be-715b-4626-ab86-be0b464bd6cf ==============================
[0m15:50:32.559256 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:50:32.559256 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'profiles_dir': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'no_print': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': 'd:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt ', 'printer_width': '80', 'write_json': 'True'}
[0m15:50:32.677258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6dc164be-715b-4626-ab86-be0b464bd6cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E35A6450>]}
[0m15:50:32.694366 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:50:32.696599 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:50:32.696599 [debug] [MainThread]: Command `cli deps` succeeded at 15:50:32.696599 after 0.26 seconds
[0m15:50:32.696599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E20D42F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E377B500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173E372E810>]}
[0m15:50:32.698104 [debug] [MainThread]: Flushing usage events
[0m15:50:33.371270 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:27:35.883794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026904C4F530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269022B6D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026904CF01A0>]}


============================== 16:27:35.887809 | 06d68493-9446-4bb3-bccc-90689bd6ca60 ==============================
[0m16:27:35.887809 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:27:35.888810 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'write_json': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'warn_error': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m16:27:36.688515 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:27:36.689515 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:27:36.689515 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:27:37.344222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002692825FFE0>]}
[0m16:27:37.400957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026927DA7FB0>]}
[0m16:27:37.400957 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m16:27:37.701101 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:27:37.879747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:27:37.880747 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:27:37.887787 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.octy_dbt_learn.gold
[0m16:27:37.948036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026907F64DA0>]}
[0m16:27:38.056966 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m16:27:38.059967 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m16:27:38.074549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928B401D0>]}
[0m16:27:38.075556 [info ] [MainThread]: Found 7 models, 4 analyses, 8 data tests, 1 seed, 6 sources, 702 macros
[0m16:27:38.075556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269042AA6C0>]}
[0m16:27:38.077697 [info ] [MainThread]: 
[0m16:27:38.078697 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:27:38.078697 [info ] [MainThread]: 
[0m16:27:38.079978 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:27:38.079978 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:27:38.086821 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m16:27:38.086821 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m16:27:38.099913 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m16:27:38.100953 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m16:27:38.100953 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:38.308180 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6cd2-1c48-a3e3-4626a666f4dd) - Created
[0m16:27:38.775543 [debug] [ThreadPool]: SQL status: OK in 0.670 seconds
[0m16:27:38.781689 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b01c-6cd2-1c48-a3e3-4626a666f4dd, command-id=01f0b01c-6cde-1bb0-af8e-cbc0d383c6b3) - Closing
[0m16:27:38.781689 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m16:27:38.782703 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6cd2-1c48-a3e3-4626a666f4dd) - Closing
[0m16:27:38.856066 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m16:27:38.857063 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m16:27:38.860061 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m16:27:38.861061 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m16:27:38.861061 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:39.051008 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6d45-1d7b-8a89-df9a2e0d6ae6) - Created
[0m16:27:39.340308 [debug] [ThreadPool]: SQL status: OK in 0.480 seconds
[0m16:27:39.342821 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b01c-6d45-1d7b-8a89-df9a2e0d6ae6, command-id=01f0b01c-6d4f-1f40-9682-a3bfcd834daa) - Closing
[0m16:27:39.342821 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m16:27:39.343897 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6d45-1d7b-8a89-df9a2e0d6ae6) - Closing
[0m16:27:39.415197 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_dev_silver) - Creating connection
[0m16:27:39.416200 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_dev_silver'
[0m16:27:39.416200 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_dev"
schema: "silver"
"
[0m16:27:39.422937 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_dev_silver"
[0m16:27:39.422937 [debug] [ThreadPool]: On create_dbt_tutorial_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "create_dbt_tutorial_dev_silver"} */
create schema if not exists `dbt_tutorial_dev`.`silver`
  
[0m16:27:39.423993 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:39.602734 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6d9a-1774-9bc7-46d4835ed159) - Created
[0m16:27:40.211472 [debug] [ThreadPool]: SQL status: OK in 0.790 seconds
[0m16:27:40.212457 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b01c-6d9a-1774-9bc7-46d4835ed159, command-id=01f0b01c-6da4-1925-af87-498ec8dd5441) - Closing
[0m16:27:40.212457 [debug] [ThreadPool]: On create_dbt_tutorial_dev_silver: Close
[0m16:27:40.213518 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6d9a-1774-9bc7-46d4835ed159) - Closing
[0m16:27:40.290516 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m16:27:40.291985 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m16:27:40.301000 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m16:27:40.301000 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m16:27:40.301000 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:40.494000 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6e22-1d61-8401-cd85ad82eafc) - Created
[0m16:27:41.399323 [debug] [ThreadPool]: SQL status: OK in 1.100 seconds
[0m16:27:41.402315 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b01c-6e22-1d61-8401-cd85ad82eafc, command-id=01f0b01c-6e2c-1922-9846-bacf5106eb3e) - Closing
[0m16:27:41.402820 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m16:27:41.402820 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6e22-1d61-8401-cd85ad82eafc) - Closing
[0m16:27:41.476889 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_silver) - Creating connection
[0m16:27:41.478939 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_silver'
[0m16:27:41.480939 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_silver"
[0m16:27:41.481957 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'silver'

  
[0m16:27:41.481957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:41.662681 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6ed4-1de1-a127-b95c4a55e3e4) - Created
[0m16:27:42.061944 [debug] [ThreadPool]: SQL status: OK in 0.580 seconds
[0m16:27:42.062957 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b01c-6ed4-1de1-a127-b95c4a55e3e4, command-id=01f0b01c-6ede-1aca-86be-c444f5a393c7) - Closing
[0m16:27:42.064490 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: Close
[0m16:27:42.064490 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b01c-6ed4-1de1-a127-b95c4a55e3e4) - Closing
[0m16:27:42.143120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269285E56A0>]}
[0m16:27:42.147131 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m16:27:42.147131 [info ] [Thread-1 (]: 1 of 7 START sql table model bronze.bronze_customer ............................ [RUN]
[0m16:27:42.148532 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m16:27:42.149548 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m16:27:42.149548 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m16:27:42.156659 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m16:27:42.156659 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m16:27:42.173437 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m16:27:42.174448 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:27:42.174448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928FD8470>]}
[0m16:27:42.220166 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m16:27:42.222673 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m16:27:42.222673 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m16:27:42.223213 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:42.396021 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-6f46-18cb-88e1-adb0dd98e44b) - Created
[0m16:27:47.191170 [debug] [Thread-1 (]: SQL status: OK in 4.970 seconds
[0m16:27:47.192690 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-6f46-18cb-88e1-adb0dd98e44b, command-id=01f0b01c-6f4e-1fd2-a31b-dd8e35159155) - Closing
[0m16:27:47.208997 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:47.223362 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m16:27:47.223362 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-6f46-18cb-88e1-adb0dd98e44b) - Closing
[0m16:27:47.301522 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026904800380>]}
[0m16:27:47.303028 [info ] [Thread-1 (]: 1 of 7 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 5.15s]
[0m16:27:47.304034 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m16:27:47.304034 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m16:27:47.305034 [info ] [Thread-1 (]: 2 of 7 START sql view model bronze.bronze_date ................................. [RUN]
[0m16:27:47.306035 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m16:27:47.306035 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m16:27:47.307035 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m16:27:47.310034 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m16:27:47.311036 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m16:27:47.323974 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m16:27:47.335146 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m16:27:47.336313 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m16:27:47.337726 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m16:27:47.337726 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m16:27:47.337726 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:47.546118 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-7255-1745-8388-fdb29fd5ca5a) - Created
[0m16:27:48.731366 [debug] [Thread-1 (]: SQL status: OK in 1.390 seconds
[0m16:27:48.732413 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-7255-1745-8388-fdb29fd5ca5a, command-id=01f0b01c-7260-1557-8e54-5a4fc13d6d81) - Closing
[0m16:27:48.732929 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:48.733459 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m16:27:48.733980 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-7255-1745-8388-fdb29fd5ca5a) - Closing
[0m16:27:48.835855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928FC13A0>]}
[0m16:27:48.836968 [info ] [Thread-1 (]: 2 of 7 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.53s]
[0m16:27:48.836968 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m16:27:48.838194 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m16:27:48.838194 [info ] [Thread-1 (]: 3 of 7 START sql view model bronze.bronze_product .............................. [RUN]
[0m16:27:48.839243 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m16:27:48.839243 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m16:27:48.840433 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m16:27:48.842958 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m16:27:48.844488 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m16:27:48.847523 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m16:27:48.848523 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m16:27:48.849523 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m16:27:48.851518 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m16:27:48.851518 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m16:27:48.851518 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:49.034733 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-733a-10d2-ab4d-fae033398bc5) - Created
[0m16:27:49.757905 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m16:27:49.759904 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-733a-10d2-ab4d-fae033398bc5, command-id=01f0b01c-7345-18bb-9b17-3ce0140d1ecb) - Closing
[0m16:27:49.759904 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:49.761352 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m16:27:49.761352 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-733a-10d2-ab4d-fae033398bc5) - Closing
[0m16:27:49.841489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002692902B440>]}
[0m16:27:49.843002 [info ] [Thread-1 (]: 3 of 7 OK created sql view model bronze.bronze_product ......................... [[32mOK[0m in 1.00s]
[0m16:27:49.843002 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m16:27:49.843002 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m16:27:49.844570 [info ] [Thread-1 (]: 4 of 7 START sql table model bronze.bronze_returns ............................. [RUN]
[0m16:27:49.845719 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m16:27:49.845719 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m16:27:49.846752 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m16:27:49.850787 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m16:27:49.851802 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m16:27:49.853819 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m16:27:49.855819 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m16:27:49.855819 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m16:27:49.856851 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m16:27:49.856851 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:50.032752 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-73d2-1cb1-968a-c1a3a35f7a27) - Created
[0m16:27:53.481106 [debug] [Thread-1 (]: SQL status: OK in 3.620 seconds
[0m16:27:53.482106 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-73d2-1cb1-968a-c1a3a35f7a27, command-id=01f0b01c-73de-1fec-8396-c1a8f51d059b) - Closing
[0m16:27:53.483106 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:53.484216 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m16:27:53.484216 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-73d2-1cb1-968a-c1a3a35f7a27) - Closing
[0m16:27:53.557261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928FB8B60>]}
[0m16:27:53.558261 [info ] [Thread-1 (]: 4 of 7 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 3.71s]
[0m16:27:53.559262 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m16:27:53.560262 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m16:27:53.560262 [info ] [Thread-1 (]: 5 of 7 START sql view model bronze.bronze_sales ................................ [RUN]
[0m16:27:53.561266 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m16:27:53.561266 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m16:27:53.562779 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m16:27:53.570793 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m16:27:53.573859 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m16:27:53.576858 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m16:27:53.577861 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m16:27:53.577861 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m16:27:53.578861 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m16:27:53.579860 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m16:27:53.579860 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:53.761453 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-760c-193d-b781-01c596554a4a) - Created
[0m16:27:54.389102 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m16:27:54.390101 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-760c-193d-b781-01c596554a4a, command-id=01f0b01c-7614-1cf9-b148-b6671ee59523) - Closing
[0m16:27:54.391099 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:54.392114 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m16:27:54.392114 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-760c-193d-b781-01c596554a4a) - Closing
[0m16:27:54.472824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928FB8770>]}
[0m16:27:54.472824 [info ] [Thread-1 (]: 5 of 7 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 0.91s]
[0m16:27:54.473831 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m16:27:54.473831 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m16:27:54.475284 [info ] [Thread-1 (]: 6 of 7 START sql table model bronze.bronze_store ............................... [RUN]
[0m16:27:54.475284 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m16:27:54.476286 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m16:27:54.476286 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m16:27:54.480057 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m16:27:54.480057 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m16:27:54.482800 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m16:27:54.483853 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m16:27:54.485271 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m16:27:54.485271 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m16:27:54.486693 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:54.655261 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-7694-1348-b3c1-3147ae428b9f) - Created
[0m16:27:57.876898 [debug] [Thread-1 (]: SQL status: OK in 3.390 seconds
[0m16:27:57.877914 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-7694-1348-b3c1-3147ae428b9f, command-id=01f0b01c-769e-1760-923d-214a9354463f) - Closing
[0m16:27:57.878942 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:27:57.879955 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m16:27:57.879955 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-7694-1348-b3c1-3147ae428b9f) - Closing
[0m16:27:57.958013 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928FE42C0>]}
[0m16:27:57.959024 [info ] [Thread-1 (]: 6 of 7 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 3.48s]
[0m16:27:57.960024 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m16:27:57.960024 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.silver_sales_info
[0m16:27:57.961039 [info ] [Thread-1 (]: 7 of 7 START sql table model silver.silver_sales_info .......................... [RUN]
[0m16:27:57.962879 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.silver_sales_info) - Creating connection
[0m16:27:57.962879 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.silver_sales_info'
[0m16:27:57.962879 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.silver_sales_info
[0m16:27:57.969707 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.silver_sales_info"
[0m16:27:57.971705 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.silver_sales_info
[0m16:27:57.974768 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m16:27:57.975770 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.silver_sales_info"
[0m16:27:57.976909 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.silver_sales_info"
[0m16:27:57.977972 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.silver_sales_info"} */

  
    
        create or replace table `dbt_tutorial_dev`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS (
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        unit_price * quantity AS calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
),

products AS (
    SELECT
        product_sk,
        category
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_product`
),

customer AS (
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_customer`
),

joined_query AS (
    SELECT
        s.sales_id,
        s.gross_amount,
        s.payment_method,
        p.category,
        c.gender
    FROM
        sales s
    JOIN
        products p ON s.product_sk = p.product_sk
    JOIN
        customer c ON s.customer_sk = c.customer_sk
)

SELECT
    category,
    gender,
    sum(gross_amount) AS total_sales
FROM joined_query
GROUP BY
    1,
    2
ORDER BY  
    total_sales DESC
  
[0m16:27:57.977972 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:27:58.176103 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-78ad-1861-8a3b-75cc439ca8f1) - Created
[0m16:28:02.978234 [debug] [Thread-1 (]: SQL status: OK in 5.000 seconds
[0m16:28:02.979260 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b01c-78ad-1861-8a3b-75cc439ca8f1, command-id=01f0b01c-78b7-17c0-8ac2-3aa50daecb8c) - Closing
[0m16:28:02.980257 [debug] [Thread-1 (]: Applying tags to relation None
[0m16:28:02.981534 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: Close
[0m16:28:02.981534 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b01c-78ad-1861-8a3b-75cc439ca8f1) - Closing
[0m16:28:03.092996 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06d68493-9446-4bb3-bccc-90689bd6ca60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026928C39790>]}
[0m16:28:03.092996 [info ] [Thread-1 (]: 7 of 7 OK created sql table model silver.silver_sales_info ..................... [[32mOK[0m in 5.13s]
[0m16:28:03.095576 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.silver_sales_info
[0m16:28:03.096575 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:28:03.096575 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:28:03.097632 [info ] [MainThread]: 
[0m16:28:03.098632 [info ] [MainThread]: Finished running 4 table models, 3 view models in 0 hours 0 minutes and 25.02 seconds (25.02s).
[0m16:28:03.099782 [debug] [MainThread]: Command end result
[0m16:28:03.261588 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m16:28:03.265099 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m16:28:03.270492 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m16:28:03.270492 [info ] [MainThread]: 
[0m16:28:03.270492 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:28:03.271962 [info ] [MainThread]: 
[0m16:28:03.271962 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m16:28:03.273142 [debug] [MainThread]: Command `dbt run` succeeded at 16:28:03.273142 after 27.52 seconds
[0m16:28:03.273142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269280B0E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026904CF01A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026907F7A060>]}
[0m16:28:03.273142 [debug] [MainThread]: Flushing usage events
[0m16:28:04.016457 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:03:08.796951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B4A94EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B4010860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B4011C40>]}


============================== 17:03:08.800950 | ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d ==============================
[0m17:03:08.800950 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:03:08.801972 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'write_json': 'True', 'use_colors': 'True', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'printer_width': '80', 'target_path': 'None'}
[0m17:03:09.629392 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:03:09.630588 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:03:09.631792 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:03:10.329904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D5980F80>]}
[0m17:03:10.388135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D7C98830>]}
[0m17:03:10.389135 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m17:03:10.698290 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:03:10.893870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:03:10.894894 [debug] [MainThread]: Partial parsing: updated file: octy_dbt_learn://snapshots\gold_items.yml
[0m17:03:11.226572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D858B710>]}
[0m17:03:11.457846 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:03:11.459893 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:03:11.487137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D814DDC0>]}
[0m17:03:11.488137 [info ] [MainThread]: Found 4 analyses, 1 seed, 8 models, 8 data tests, 1 snapshot, 7 sources, 702 macros
[0m17:03:11.488137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D8580470>]}
[0m17:03:11.490236 [info ] [MainThread]: 
[0m17:03:11.490236 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:03:11.490236 [info ] [MainThread]: 
[0m17:03:11.491235 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:03:11.491235 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:03:11.492235 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:03:11.493264 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:03:11.502359 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:03:11.502359 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:03:11.502359 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:11.752428 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6472-1641-8151-05b6962b137d) - Created
[0m17:03:12.078133 [debug] [ThreadPool]: SQL status: OK in 0.580 seconds
[0m17:03:12.084648 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-6472-1641-8151-05b6962b137d, command-id=01f0b021-647f-1035-a470-628d1fc1d253) - Closing
[0m17:03:12.085652 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:03:12.085652 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6472-1641-8151-05b6962b137d) - Closing
[0m17:03:12.167153 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_dev_gold) - Creating connection
[0m17:03:12.168206 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_dev_gold'
[0m17:03:12.168206 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_dev"
schema: "gold"
"
[0m17:03:12.172735 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_dev_gold"
[0m17:03:12.174243 [debug] [ThreadPool]: On create_dbt_tutorial_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "create_dbt_tutorial_dev_gold"} */
create schema if not exists `dbt_tutorial_dev`.`gold`
  
[0m17:03:12.174243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:12.351167 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-64cf-1537-83ab-3fcc80236729) - Created
[0m17:03:12.964292 [debug] [ThreadPool]: SQL status: OK in 0.790 seconds
[0m17:03:12.965842 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-64cf-1537-83ab-3fcc80236729, command-id=01f0b021-64da-1803-a92b-1adfe16fc0f7) - Closing
[0m17:03:12.965842 [debug] [ThreadPool]: On create_dbt_tutorial_dev_gold: Close
[0m17:03:12.966859 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-64cf-1537-83ab-3fcc80236729) - Closing
[0m17:03:13.066285 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_gold) - Creating connection
[0m17:03:13.066285 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_gold'
[0m17:03:13.072233 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_gold"
[0m17:03:13.073766 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'gold'

  
[0m17:03:13.074273 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:13.254930 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6559-1096-be35-a723f5df5205) - Created
[0m17:03:14.075211 [debug] [ThreadPool]: SQL status: OK in 1.000 seconds
[0m17:03:14.077211 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-6559-1096-be35-a723f5df5205, command-id=01f0b021-6562-1275-b44f-03fb1894b865) - Closing
[0m17:03:14.078210 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: Close
[0m17:03:14.078210 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6559-1096-be35-a723f5df5205) - Closing
[0m17:03:14.157132 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_silver) - Creating connection
[0m17:03:14.158433 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_silver'
[0m17:03:14.162455 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_silver"
[0m17:03:14.162455 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'silver'

  
[0m17:03:14.162455 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:14.346922 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-65fe-1c7b-af10-7cf7981d72c1) - Created
[0m17:03:14.940302 [debug] [ThreadPool]: SQL status: OK in 0.780 seconds
[0m17:03:14.942303 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-65fe-1c7b-af10-7cf7981d72c1, command-id=01f0b021-660f-13a7-a463-f4a113f1d75b) - Closing
[0m17:03:14.943303 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: Close
[0m17:03:14.943303 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-65fe-1c7b-af10-7cf7981d72c1) - Closing
[0m17:03:15.019340 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m17:03:15.020358 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m17:03:15.023905 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m17:03:15.024910 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m17:03:15.024910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:15.214726 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6682-1eb9-9d24-dd46fabff548) - Created
[0m17:03:15.643949 [debug] [ThreadPool]: SQL status: OK in 0.620 seconds
[0m17:03:15.646020 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-6682-1eb9-9d24-dd46fabff548, command-id=01f0b021-668d-1be5-a196-c7bd6bf5c1e0) - Closing
[0m17:03:15.648020 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m17:03:15.648020 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-6682-1eb9-9d24-dd46fabff548) - Closing
[0m17:03:15.721417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2D81C9280>]}
[0m17:03:15.725258 [debug] [Thread-1 (]: Began running node snapshot.octy_dbt_learn.gold_items
[0m17:03:15.726634 [info ] [Thread-1 (]: 1 of 1 START snapshot gold.gold_items .......................................... [RUN]
[0m17:03:15.727634 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.octy_dbt_learn.gold_items) - Creating connection
[0m17:03:15.727634 [debug] [Thread-1 (]: Acquiring new databricks connection 'snapshot.octy_dbt_learn.gold_items'
[0m17:03:15.727634 [debug] [Thread-1 (]: Began compiling node snapshot.octy_dbt_learn.gold_items
[0m17:03:15.737161 [debug] [Thread-1 (]: Began executing node snapshot.octy_dbt_learn.gold_items
[0m17:03:15.824107 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:03:15.824107 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m17:03:15.824107 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:03:16.021846 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-66fe-1d2a-aecc-e3e148dfd82a) - Created
[0m17:03:16.271011 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b021-6708-1b23-8461-2c6a43b3a30b
[0m17:03:16.272011 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: Close
[0m17:03:16.272011 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-66fe-1d2a-aecc-e3e148dfd82a) - Closing
[0m17:03:16.568161 [debug] [Thread-1 (]: Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22
[0m17:03:16.570182 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce88ffe5-1ed6-4768-8dbf-3da60ed9cb2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B3F512E0>]}
[0m17:03:16.571182 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting gold.gold_items ...................................... [[31mERROR[0m in 0.84s]
[0m17:03:16.572181 [debug] [Thread-1 (]: Finished running node snapshot.octy_dbt_learn.gold_items
[0m17:03:16.572181 [debug] [Thread-4 (]: Marking all children of 'snapshot.octy_dbt_learn.gold_items' to be skipped because of status 'error'.  Reason: Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22.
[0m17:03:16.574182 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:03:16.574688 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:03:16.574688 [info ] [MainThread]: 
[0m17:03:16.575690 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 5.08 seconds (5.08s).
[0m17:03:16.576691 [debug] [MainThread]: Command end result
[0m17:03:16.607254 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:03:16.609249 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:03:16.615350 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m17:03:16.615350 [info ] [MainThread]: 
[0m17:03:16.615350 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:03:16.616824 [info ] [MainThread]: 
[0m17:03:16.616824 [error] [MainThread]: [31mFailure in snapshot gold_items (snapshots\gold_items.yml)[0m
[0m17:03:16.617823 [error] [MainThread]:   Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_dev`.`gold`.`source_gold_items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 22
[0m17:03:16.617823 [info ] [MainThread]: 
[0m17:03:16.617823 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m17:03:16.618823 [debug] [MainThread]: Command `dbt snapshot` failed at 17:03:16.618823 after 7.98 seconds
[0m17:03:16.619824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B41906B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B41D7EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B49EC860>]}
[0m17:03:16.619824 [debug] [MainThread]: Flushing usage events
[0m17:03:17.261429 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:04:41.756781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8974FD700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89AB75E80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89AB759D0>]}


============================== 17:04:41.761425 | 1caae1f4-8fa3-430d-ba4c-f767dac1d2a9 ==============================
[0m17:04:41.761425 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:04:41.762439 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'write_json': 'True', 'printer_width': '80', 'invocation_command': 'dbt build', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'warn_error': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m17:04:42.560690 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:04:42.561690 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:04:42.561690 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:04:43.221457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BE667FE0>]}
[0m17:04:43.277306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BC94EB70>]}
[0m17:04:43.278308 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m17:04:43.592159 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:04:43.800255 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:04:43.800255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:04:43.874245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BEAC0740>]}
[0m17:04:43.995786 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:04:43.997300 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:04:44.112730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BEFA46E0>]}
[0m17:04:44.113750 [info ] [MainThread]: Found 4 analyses, 1 seed, 8 models, 8 data tests, 1 snapshot, 7 sources, 702 macros
[0m17:04:44.115749 [info ] [MainThread]: 
[0m17:04:44.116775 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:04:44.116775 [info ] [MainThread]: 
[0m17:04:44.116775 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:04:44.118279 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:04:44.124604 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:04:44.124604 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:04:44.135337 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:04:44.136340 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:04:44.136340 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:44.355121 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9ba5-14ec-8c0b-337e96858151) - Created
[0m17:04:44.743129 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m17:04:44.748132 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9ba5-14ec-8c0b-337e96858151, command-id=01f0b021-9bae-1f98-8bda-883fde0e9abc) - Closing
[0m17:04:44.749213 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:04:44.749213 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9ba5-14ec-8c0b-337e96858151) - Closing
[0m17:04:44.818168 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:04:44.819212 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:04:44.822698 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:04:44.822698 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:04:44.822698 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:45.041052 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9c0e-1384-9df8-1f9d37f937e4) - Created
[0m17:04:45.446534 [debug] [ThreadPool]: SQL status: OK in 0.620 seconds
[0m17:04:45.448039 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9c0e-1384-9df8-1f9d37f937e4, command-id=01f0b021-9c17-1730-b87c-e6fd41e13911) - Closing
[0m17:04:45.449082 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:04:45.449082 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9c0e-1384-9df8-1f9d37f937e4) - Closing
[0m17:04:45.528325 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:04:45.528325 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:04:45.530893 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:04:45.531911 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:04:45.531911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:45.734833 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9c77-1342-81d6-4c15750dc857) - Created
[0m17:04:45.986057 [debug] [ThreadPool]: SQL status: OK in 0.450 seconds
[0m17:04:45.988583 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9c77-1342-81d6-4c15750dc857, command-id=01f0b021-9c81-17d9-b82b-25f33e834c5b) - Closing
[0m17:04:45.988583 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:04:45.989603 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9c77-1342-81d6-4c15750dc857) - Closing
[0m17:04:46.073991 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_gold) - Creating connection
[0m17:04:46.073991 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_gold'
[0m17:04:46.084142 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_gold"
[0m17:04:46.085155 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'gold'

  
[0m17:04:46.085155 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:46.258266 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9cc8-11be-a343-bdac85577d2a) - Created
[0m17:04:46.650806 [debug] [ThreadPool]: SQL status: OK in 0.560 seconds
[0m17:04:46.652834 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9cc8-11be-a343-bdac85577d2a, command-id=01f0b021-9cd1-170d-bc0c-58de068d1df5) - Closing
[0m17:04:46.652834 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: Close
[0m17:04:46.653896 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9cc8-11be-a343-bdac85577d2a) - Closing
[0m17:04:46.726260 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_silver) - Creating connection
[0m17:04:46.727258 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_silver'
[0m17:04:46.730044 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_silver"
[0m17:04:46.730044 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'silver'

  
[0m17:04:46.730044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:46.936988 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9d2e-1d49-8b17-e2e1beaba336) - Created
[0m17:04:47.325452 [debug] [ThreadPool]: SQL status: OK in 0.600 seconds
[0m17:04:47.328442 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9d2e-1d49-8b17-e2e1beaba336, command-id=01f0b021-9d38-16ba-aa2e-dafe97ecd1b3) - Closing
[0m17:04:47.328949 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: Close
[0m17:04:47.328949 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9d2e-1d49-8b17-e2e1beaba336) - Closing
[0m17:04:47.404807 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m17:04:47.405824 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m17:04:47.409351 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m17:04:47.409351 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m17:04:47.410336 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:47.606103 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9d93-1886-a391-87c9abf09ca5) - Created
[0m17:04:48.008378 [debug] [ThreadPool]: SQL status: OK in 0.600 seconds
[0m17:04:48.011838 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b021-9d93-1886-a391-87c9abf09ca5, command-id=01f0b021-9d9e-1e04-81ed-0bde78947557) - Closing
[0m17:04:48.011838 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m17:04:48.012851 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b021-9d93-1886-a391-87c9abf09ca5) - Closing
[0m17:04:48.087344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89DF7B920>]}
[0m17:04:48.092303 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m17:04:48.093297 [info ] [Thread-1 (]: 1 of 18 START sql table model bronze.bronze_customer ........................... [RUN]
[0m17:04:48.094298 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m17:04:48.094298 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m17:04:48.095297 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m17:04:48.104271 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m17:04:48.104271 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m17:04:48.121821 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:04:48.121821 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m17:04:48.122819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF4C45F0>]}
[0m17:04:48.162526 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m17:04:48.163526 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m17:04:48.164527 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m17:04:48.164527 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:48.336640 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-9e05-1e84-8da0-bab2233cdde4) - Created
[0m17:04:51.967266 [debug] [Thread-1 (]: SQL status: OK in 3.800 seconds
[0m17:04:51.968771 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-9e05-1e84-8da0-bab2233cdde4, command-id=01f0b021-9e0e-1f41-b708-7f8e310dbc20) - Closing
[0m17:04:51.983393 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:04:51.999423 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m17:04:51.999423 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-9e05-1e84-8da0-bab2233cdde4) - Closing
[0m17:04:52.078156 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF46D850>]}
[0m17:04:52.079170 [info ] [Thread-1 (]: 1 of 18 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 3.98s]
[0m17:04:52.080170 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m17:04:52.081353 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m17:04:52.081353 [info ] [Thread-1 (]: 2 of 18 START sql view model bronze.bronze_date ................................ [RUN]
[0m17:04:52.082388 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m17:04:52.083406 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m17:04:52.083406 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m17:04:52.089918 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m17:04:52.090918 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m17:04:52.216869 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:04:52.228946 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m17:04:52.228946 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m17:04:52.229961 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m17:04:52.229961 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m17:04:52.230960 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:52.416932 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a074-13af-adba-aeb7117fac53) - Created
[0m17:04:53.408325 [debug] [Thread-1 (]: SQL status: OK in 1.180 seconds
[0m17:04:53.409344 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a074-13af-adba-aeb7117fac53, command-id=01f0b021-a07c-1cab-9f85-a2c0402aea30) - Closing
[0m17:04:53.411285 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:04:53.411285 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m17:04:53.412293 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a074-13af-adba-aeb7117fac53) - Closing
[0m17:04:53.485335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89E3A4B60>]}
[0m17:04:53.486336 [info ] [Thread-1 (]: 2 of 18 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.40s]
[0m17:04:53.487336 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m17:04:53.488337 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m17:04:53.488848 [info ] [Thread-1 (]: 3 of 18 START sql view model bronze.bronze_product ............................. [RUN]
[0m17:04:53.489851 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m17:04:53.489851 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m17:04:53.490852 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m17:04:53.493851 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m17:04:53.494852 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m17:04:53.496851 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:04:53.498358 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m17:04:53.499366 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m17:04:53.500372 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m17:04:53.500372 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m17:04:53.500372 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:53.680158 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a133-199d-b8a7-09dcd58c542c) - Created
[0m17:04:54.634293 [debug] [Thread-1 (]: SQL status: OK in 1.130 seconds
[0m17:04:54.635296 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a133-199d-b8a7-09dcd58c542c, command-id=01f0b021-a13d-13e5-8b39-decef9da6e0d) - Closing
[0m17:04:54.636295 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:04:54.637296 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m17:04:54.637296 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a133-199d-b8a7-09dcd58c542c) - Closing
[0m17:04:54.715971 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BEA40230>]}
[0m17:04:54.716969 [info ] [Thread-1 (]: 3 of 18 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 1.23s]
[0m17:04:54.718528 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m17:04:54.718528 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m17:04:54.719600 [info ] [Thread-1 (]: 4 of 18 START sql table model bronze.bronze_returns ............................ [RUN]
[0m17:04:54.720599 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m17:04:54.720599 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m17:04:54.720599 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m17:04:54.725970 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m17:04:54.726969 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m17:04:54.728475 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:04:54.730482 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m17:04:54.730482 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m17:04:54.731484 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m17:04:54.731484 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:54.899557 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a1ef-19a5-b0dc-cea93c9c9b78) - Created
[0m17:04:57.830269 [debug] [Thread-1 (]: SQL status: OK in 3.100 seconds
[0m17:04:57.831277 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a1ef-19a5-b0dc-cea93c9c9b78, command-id=01f0b021-a1f7-1bbe-9a6f-9fb825903b5a) - Closing
[0m17:04:57.832278 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:04:57.833277 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m17:04:57.833277 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a1ef-19a5-b0dc-cea93c9c9b78) - Closing
[0m17:04:57.907484 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF46BC80>]}
[0m17:04:57.907484 [info ] [Thread-1 (]: 4 of 18 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 3.19s]
[0m17:04:57.908483 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m17:04:57.909600 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m17:04:57.910593 [info ] [Thread-1 (]: 5 of 18 START sql view model bronze.bronze_sales ............................... [RUN]
[0m17:04:57.910593 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m17:04:57.911594 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m17:04:57.911594 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m17:04:57.916597 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m17:04:57.918600 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m17:04:57.923787 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:04:57.924787 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m17:04:57.925788 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m17:04:57.925788 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m17:04:57.926789 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m17:04:57.926789 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:58.128700 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a3d8-1b97-913a-177063d5a694) - Created
[0m17:04:58.790693 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m17:04:58.792727 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a3d8-1b97-913a-177063d5a694, command-id=01f0b021-a3e4-170c-b20d-79a974c87f26) - Closing
[0m17:04:58.793749 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:04:58.793749 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m17:04:58.794769 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a3d8-1b97-913a-177063d5a694) - Closing
[0m17:04:58.872074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF0DDCA0>]}
[0m17:04:58.872074 [info ] [Thread-1 (]: 5 of 18 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 0.96s]
[0m17:04:58.873089 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m17:04:58.874127 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m17:04:58.875172 [info ] [Thread-1 (]: 6 of 18 START sql table model bronze.bronze_store .............................. [RUN]
[0m17:04:58.876607 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m17:04:58.876607 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m17:04:58.876607 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m17:04:58.880285 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m17:04:58.881308 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m17:04:58.884338 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:04:58.886336 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m17:04:58.887832 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m17:04:58.888339 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m17:04:58.888339 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:04:59.062518 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a46a-130a-8b8c-77d3925d30fd) - Created
[0m17:05:01.688750 [debug] [Thread-1 (]: SQL status: OK in 2.800 seconds
[0m17:05:01.690296 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a46a-130a-8b8c-77d3925d30fd, command-id=01f0b021-a474-124f-b686-fb7d685fe510) - Closing
[0m17:05:01.691311 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:05:01.692330 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m17:05:01.693452 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a46a-130a-8b8c-77d3925d30fd) - Closing
[0m17:05:01.771364 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF0E6330>]}
[0m17:05:01.772364 [info ] [Thread-1 (]: 6 of 18 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 2.90s]
[0m17:05:01.772364 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m17:05:01.773365 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.source_gold_items
[0m17:05:01.774370 [info ] [Thread-1 (]: 7 of 18 START sql table model gold.source_gold_items ........................... [RUN]
[0m17:05:01.775372 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.source_gold_items) - Creating connection
[0m17:05:01.775372 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.source_gold_items'
[0m17:05:01.776369 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.source_gold_items
[0m17:05:01.781435 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.source_gold_items"
[0m17:05:01.784431 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.source_gold_items
[0m17:05:01.786574 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:05:01.788593 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.source_gold_items"
[0m17:05:01.788593 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.source_gold_items"
[0m17:05:01.789770 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.source_gold_items"} */

  
    
        create or replace table `dbt_tutorial_dev`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH dedup_query AS (
    SELECT
        *,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY updateDate DESC) AS deduplication_id
    FROM 
        `dbt_tutorial_dev`.`source`.`items`
)

SELECT
    id,
    name,
    category,
    updateDate
FROM
    dedup_query
WHERE
    deduplication_id = 1
  
[0m17:05:01.789770 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:01.982944 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a627-1dec-9def-06592db95220) - Created
[0m17:05:05.622053 [debug] [Thread-1 (]: SQL status: OK in 3.830 seconds
[0m17:05:05.623073 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a627-1dec-9def-06592db95220, command-id=01f0b021-a632-1783-9fd9-f90b48b6ef30) - Closing
[0m17:05:05.624070 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:05:05.625071 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: Close
[0m17:05:05.625071 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a627-1dec-9def-06592db95220) - Closing
[0m17:05:05.699807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF0E6AE0>]}
[0m17:05:05.700910 [info ] [Thread-1 (]: 7 of 18 OK created sql table model gold.source_gold_items ...................... [[32mOK[0m in 3.93s]
[0m17:05:05.700910 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.source_gold_items
[0m17:05:05.700910 [debug] [Thread-1 (]: Began running node seed.octy_dbt_learn.lookup
[0m17:05:05.702369 [info ] [Thread-1 (]: 8 of 18 START seed file bronze.lookup .......................................... [RUN]
[0m17:05:05.702369 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.octy_dbt_learn.lookup) - Creating connection
[0m17:05:05.703497 [debug] [Thread-1 (]: Acquiring new databricks connection 'seed.octy_dbt_learn.lookup'
[0m17:05:05.703497 [debug] [Thread-1 (]: Began compiling node seed.octy_dbt_learn.lookup
[0m17:05:05.703497 [debug] [Thread-1 (]: Began executing node seed.octy_dbt_learn.lookup
[0m17:05:05.738709 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:05:05.738709 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "seed.octy_dbt_learn.lookup"} */

    create or replace table `dbt_tutorial_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m17:05:05.739847 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:05.960502 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a887-1374-906d-f0ed1eff5281) - Created
[0m17:05:07.176223 [debug] [Thread-1 (]: SQL status: OK in 1.440 seconds
[0m17:05:07.177202 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a887-1374-906d-f0ed1eff5281, command-id=01f0b021-a88f-1d6e-a823-ae393e776a7e) - Closing
[0m17:05:07.195581 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:05:07.195581 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: 
          insert overwrite `dbt_tutorial_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m17:05:08.907909 [debug] [Thread-1 (]: SQL status: OK in 1.710 seconds
[0m17:05:08.908912 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-a887-1374-906d-f0ed1eff5281, command-id=01f0b021-a94c-1c61-a0ed-87d8810654e4) - Closing
[0m17:05:08.915960 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.octy_dbt_learn.lookup"
[0m17:05:08.917969 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: Close
[0m17:05:08.918970 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-a887-1374-906d-f0ed1eff5281) - Closing
[0m17:05:08.990343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF4AF200>]}
[0m17:05:08.990847 [info ] [Thread-1 (]: 8 of 18 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.29s]
[0m17:05:08.991858 [debug] [Thread-1 (]: Finished running node seed.octy_dbt_learn.lookup
[0m17:05:08.992858 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:05:08.992858 [info ] [Thread-1 (]: 9 of 18 START test generic_non_negative_bronze_sales_gross_amount .............. [RUN]
[0m17:05:08.993936 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m17:05:08.993936 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m17:05:08.994934 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:05:09.004456 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:05:09.005455 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:05:09.023016 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:05:09.024017 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:05:09.025017 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

    SELECT
        *
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
    WHERE 
        gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m17:05:09.025017 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:09.209727 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aa76-14a7-a29c-d7bc7097fabf) - Created
[0m17:05:09.862050 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m17:05:09.863217 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-aa76-14a7-a29c-d7bc7097fabf, command-id=01f0b021-aa83-1651-93bc-e9c576548a04) - Closing
[0m17:05:09.865245 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m17:05:09.866262 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aa76-14a7-a29c-d7bc7097fabf) - Closing
[0m17:05:09.951562 [info ] [Thread-1 (]: 9 of 18 PASS generic_non_negative_bronze_sales_gross_amount .................... [[32mPASS[0m in 0.96s]
[0m17:05:09.952553 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:05:09.952553 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.non_negative_test
[0m17:05:09.953549 [info ] [Thread-1 (]: 10 of 18 START test non_negative_test .......................................... [RUN]
[0m17:05:09.954552 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.non_negative_test) - Creating connection
[0m17:05:09.955553 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.non_negative_test'
[0m17:05:09.955553 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.non_negative_test
[0m17:05:09.960158 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.non_negative_test"
[0m17:05:09.961182 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.non_negative_test
[0m17:05:09.964233 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.non_negative_test"
[0m17:05:09.965251 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.non_negative_test"
[0m17:05:09.965251 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.non_negative_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM 
    `dbt_tutorial_dev`.`bronze`.`bronze_sales`
WHERE 
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m17:05:09.965251 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:10.154368 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ab06-14fc-ba22-39f8cec30ce7) - Created
[0m17:05:10.896267 [debug] [Thread-1 (]: SQL status: OK in 0.930 seconds
[0m17:05:10.898773 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-ab06-14fc-ba22-39f8cec30ce7, command-id=01f0b021-ab10-1358-9afd-d1dc2d739398) - Closing
[0m17:05:10.899783 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: Close
[0m17:05:10.899783 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ab06-14fc-ba22-39f8cec30ce7) - Closing
[0m17:05:10.974859 [info ] [Thread-1 (]: 10 of 18 PASS non_negative_test ................................................ [[32mPASS[0m in 1.02s]
[0m17:05:10.976858 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.non_negative_test
[0m17:05:10.976858 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:10.977858 [info ] [Thread-1 (]: 11 of 18 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m17:05:10.978872 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m17:05:10.978872 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m17:05:10.978872 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:10.988918 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:10.989925 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:10.991937 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:10.991937 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:05:10.992970 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m17:05:10.992970 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:11.200976 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aba6-16d1-be59-28e424ab6edb) - Created
[0m17:05:11.681833 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m17:05:11.684996 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-aba6-16d1-be59-28e424ab6edb, command-id=01f0b021-abae-1d6d-afb8-681193603f87) - Closing
[0m17:05:11.686057 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m17:05:11.686057 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aba6-16d1-be59-28e424ab6edb) - Closing
[0m17:05:11.757206 [info ] [Thread-1 (]: 11 of 18 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 0.78s]
[0m17:05:11.757206 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:05:11.758715 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:11.759726 [info ] [Thread-1 (]: 12 of 18 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m17:05:11.759726 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m17:05:11.760729 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m17:05:11.760729 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:11.775651 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:11.776659 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:11.781177 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:11.782177 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:05:11.782177 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:05:11.783176 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:11.953244 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ac19-172a-a105-57034dddb984) - Created
[0m17:05:12.469960 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m17:05:12.471965 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-ac19-172a-a105-57034dddb984, command-id=01f0b021-ac21-1e41-93f1-caff33ce6654) - Closing
[0m17:05:12.471965 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m17:05:12.473026 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ac19-172a-a105-57034dddb984) - Closing
[0m17:05:12.540797 [info ] [Thread-1 (]: 12 of 18 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.78s]
[0m17:05:12.541816 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:05:12.541816 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:05:12.542838 [info ] [Thread-1 (]: 13 of 18 START test accepted_values_bronze_store_country__USA__Canada .......... [RUN]
[0m17:05:12.544860 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7) - Creating connection
[0m17:05:12.544860 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7'
[0m17:05:12.545860 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:05:12.556152 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:05:12.557203 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:05:12.560782 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:05:12.561832 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:05:12.561832 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        country as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by country

)

select *
from all_values
where value_field not in (
    'USA','Canada'
)



  
  
      
    ) dbt_internal_test
[0m17:05:12.561832 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:12.735237 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ac90-19fd-85b6-9210bcadc822) - Created
[0m17:05:13.637000 [debug] [Thread-1 (]: SQL status: OK in 1.080 seconds
[0m17:05:13.640088 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-ac90-19fd-85b6-9210bcadc822, command-id=01f0b021-ac99-1129-b6f7-5ee06c80b266) - Closing
[0m17:05:13.640088 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: Close
[0m17:05:13.641109 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ac90-19fd-85b6-9210bcadc822) - Closing
[0m17:05:13.712908 [info ] [Thread-1 (]: 13 of 18 PASS accepted_values_bronze_store_country__USA__Canada ................ [[32mPASS[0m in 1.17s]
[0m17:05:13.714048 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:05:13.714048 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:05:13.715046 [info ] [Thread-1 (]: 14 of 18 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m17:05:13.716047 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m17:05:13.716047 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m17:05:13.717046 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:05:13.727389 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:05:13.727389 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:05:13.730901 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:05:13.731901 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:05:13.731901 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m17:05:13.731901 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:13.906097 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ad43-182c-9620-855f235137e1) - Created
[0m17:05:14.411178 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m17:05:14.413390 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-ad43-182c-9620-855f235137e1, command-id=01f0b021-ad4c-13cf-a1fa-b3bcd3547128) - Closing
[0m17:05:14.413390 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m17:05:14.414391 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ad43-182c-9620-855f235137e1) - Closing
[0m17:05:14.484273 [info ] [Thread-1 (]: 14 of 18 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.77s]
[0m17:05:14.485508 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:05:14.485508 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:05:14.486553 [info ] [Thread-1 (]: 15 of 18 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m17:05:14.486553 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m17:05:14.487550 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m17:05:14.487550 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:05:14.494111 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:05:14.495124 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:05:14.497161 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:05:14.497161 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:05:14.498665 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m17:05:14.498665 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:14.678688 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-adb8-1d67-853a-2d99e277cebe) - Created
[0m17:05:15.314436 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m17:05:15.316990 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-adb8-1d67-853a-2d99e277cebe, command-id=01f0b021-adc2-10cb-8cae-a3aa72111e19) - Closing
[0m17:05:15.318039 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m17:05:15.318039 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-adb8-1d67-853a-2d99e277cebe) - Closing
[0m17:05:15.391368 [info ] [Thread-1 (]: 15 of 18 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 0.90s]
[0m17:05:15.392370 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:05:15.393415 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:05:15.393415 [info ] [Thread-1 (]: 16 of 18 START test unique_bronze_store_store_sk ............................... [RUN]
[0m17:05:15.394414 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m17:05:15.394414 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m17:05:15.394414 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:05:15.401427 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:05:15.402528 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:05:15.405748 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:05:15.406998 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:05:15.406998 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:05:15.406998 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:15.599983 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ae44-1396-9d09-e400bcd17335) - Created
[0m17:05:16.055960 [debug] [Thread-1 (]: SQL status: OK in 0.650 seconds
[0m17:05:16.057961 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-ae44-1396-9d09-e400bcd17335, command-id=01f0b021-ae4e-1507-a201-1a62715966d3) - Closing
[0m17:05:16.058961 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m17:05:16.059467 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-ae44-1396-9d09-e400bcd17335) - Closing
[0m17:05:16.142246 [info ] [Thread-1 (]: 16 of 18 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.75s]
[0m17:05:16.143244 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:05:16.144241 [debug] [Thread-1 (]: Began running node snapshot.octy_dbt_learn.gold_items
[0m17:05:16.145294 [info ] [Thread-1 (]: 17 of 18 START snapshot gold.gold_items ........................................ [RUN]
[0m17:05:16.145294 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.octy_dbt_learn.gold_items) - Creating connection
[0m17:05:16.146295 [debug] [Thread-1 (]: Acquiring new databricks connection 'snapshot.octy_dbt_learn.gold_items'
[0m17:05:16.146295 [debug] [Thread-1 (]: Began compiling node snapshot.octy_dbt_learn.gold_items
[0m17:05:16.153506 [debug] [Thread-1 (]: Began executing node snapshot.octy_dbt_learn.gold_items
[0m17:05:16.208684 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:05:16.209811 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m17:05:16.209811 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:16.397469 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aebe-1545-a047-c1a14541df3e) - Created
[0m17:05:16.923785 [debug] [Thread-1 (]: SQL status: OK in 0.710 seconds
[0m17:05:16.928856 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:05:16.928856 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m17:05:16.928856 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-aebe-1545-a047-c1a14541df3e, command-id=01f0b021-aec8-1767-a8ce-437233e26fe6) - Closing
[0m17:05:17.085116 [debug] [Thread-1 (]: SQL status: OK in 0.160 seconds
[0m17:05:17.085116 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.octy_dbt_learn.gold_items"
[0m17:05:17.088701 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:05:17.089764 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

      
  
    
        create or replace table `dbt_tutorial_dev`.`gold`.`gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id,
        updateDate as dbt_updated_at,
        updateDate as dbt_valid_from,
        
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`
    ) sbq



  
  
[0m17:05:17.089764 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-aebe-1545-a047-c1a14541df3e, command-id=01f0b021-af19-13b7-991a-18b68c2a6ffc) - Closing
[0m17:05:20.488778 [debug] [Thread-1 (]: SQL status: OK in 3.400 seconds
[0m17:05:20.490252 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-aebe-1545-a047-c1a14541df3e, command-id=01f0b021-af32-11b2-a01a-5513452f8253) - Closing
[0m17:05:20.495536 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: Close
[0m17:05:20.495536 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-aebe-1545-a047-c1a14541df3e) - Closing
[0m17:05:20.575061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BF495A30>]}
[0m17:05:20.576070 [info ] [Thread-1 (]: 17 of 18 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 4.43s]
[0m17:05:20.577312 [debug] [Thread-1 (]: Finished running node snapshot.octy_dbt_learn.gold_items
[0m17:05:20.577312 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.silver_sales_info
[0m17:05:20.578819 [info ] [Thread-1 (]: 18 of 18 START sql table model silver.silver_sales_info ........................ [RUN]
[0m17:05:20.579855 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.silver_sales_info) - Creating connection
[0m17:05:20.579855 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.silver_sales_info'
[0m17:05:20.580901 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.silver_sales_info
[0m17:05:20.584901 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.silver_sales_info"
[0m17:05:20.586325 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.silver_sales_info
[0m17:05:20.588827 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:05:20.589862 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.silver_sales_info"
[0m17:05:20.590873 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.silver_sales_info"
[0m17:05:20.590873 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.silver_sales_info"} */

  
    
        create or replace table `dbt_tutorial_dev`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS (
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        unit_price * quantity AS calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
),

products AS (
    SELECT
        product_sk,
        category
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_product`
),

customer AS (
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_customer`
),

joined_query AS (
    SELECT
        s.sales_id,
        s.gross_amount,
        s.payment_method,
        p.category,
        c.gender
    FROM
        sales s
    JOIN
        products p ON s.product_sk = p.product_sk
    JOIN
        customer c ON s.customer_sk = c.customer_sk
)

SELECT
    category,
    gender,
    sum(gross_amount) AS total_sales
FROM joined_query
GROUP BY
    1,
    2
ORDER BY  
    total_sales DESC
  
[0m17:05:20.590873 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:05:20.774850 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-b15b-1e3a-9aa6-5b2501907dad) - Created
[0m17:05:24.747607 [debug] [Thread-1 (]: SQL status: OK in 4.160 seconds
[0m17:05:24.747607 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b021-b15b-1e3a-9aa6-5b2501907dad, command-id=01f0b021-b164-1690-9c29-0ac75bb728ed) - Closing
[0m17:05:24.749112 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:05:24.750118 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: Close
[0m17:05:24.750118 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b021-b15b-1e3a-9aa6-5b2501907dad) - Closing
[0m17:05:24.839062 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caae1f4-8fa3-430d-ba4c-f767dac1d2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8BE9E6AE0>]}
[0m17:05:24.840329 [info ] [Thread-1 (]: 18 of 18 OK created sql table model silver.silver_sales_info ................... [[32mOK[0m in 4.26s]
[0m17:05:24.841329 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.silver_sales_info
[0m17:05:24.842333 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:05:24.842333 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:05:24.843765 [info ] [MainThread]: 
[0m17:05:24.843765 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 8 data tests, 3 view models in 0 hours 0 minutes and 40.73 seconds (40.73s).
[0m17:05:24.847792 [debug] [MainThread]: Command end result
[0m17:05:24.898981 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:05:24.903195 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:05:24.910039 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m17:05:24.911044 [info ] [MainThread]: 
[0m17:05:24.911044 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:05:24.912187 [info ] [MainThread]: 
[0m17:05:24.912187 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=18
[0m17:05:24.914668 [debug] [MainThread]: Command `dbt build` succeeded at 17:05:24.913609 after 43.32 seconds
[0m17:05:24.914668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89B254830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89B257F80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E89B256750>]}
[0m17:05:24.915857 [debug] [MainThread]: Flushing usage events
[0m17:05:25.854351 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:18:05.937555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CEF705700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF374BFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF18C5D00>]}


============================== 17:18:05.939933 | 354484ff-bbf1-4588-901c-0bba6e967070 ==============================
[0m17:18:05.939933 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:18:05.941430 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'invocation_command': 'dbt build', 'log_format': 'default', 'target_path': 'None', 'no_print': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m17:18:06.735444 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:18:06.735444 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:18:06.736445 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:18:07.398204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97166CC0>]}
[0m17:18:07.455365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CFF5BDA90>]}
[0m17:18:07.456378 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m17:18:07.757173 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:18:07.954041 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:18:07.955057 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:18:08.030938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C9726C410>]}
[0m17:18:08.154893 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:18:08.157004 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:18:08.186012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C9726D0A0>]}
[0m17:18:08.187012 [info ] [MainThread]: Found 4 analyses, 1 seed, 8 models, 8 data tests, 1 snapshot, 7 sources, 702 macros
[0m17:18:08.190123 [info ] [MainThread]: 
[0m17:18:08.191151 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:18:08.191151 [info ] [MainThread]: 
[0m17:18:08.192146 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:18:08.192146 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:18:08.201050 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:18:08.201050 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:18:08.212334 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:18:08.213339 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:18:08.213339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:08.479340 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7aec-152e-9e8e-7a9c54caa8c3) - Created
[0m17:18:08.739918 [debug] [ThreadPool]: SQL status: OK in 0.530 seconds
[0m17:18:08.745447 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7aec-152e-9e8e-7a9c54caa8c3, command-id=01f0b023-7af9-1996-82eb-d26ee6288ca9) - Closing
[0m17:18:08.745447 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:18:08.746447 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7aec-152e-9e8e-7a9c54caa8c3) - Closing
[0m17:18:08.823867 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:18:08.825000 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:18:08.827052 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:18:08.827052 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:18:08.828053 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:09.019814 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7b3f-1a0d-993d-aa36ea6af208) - Created
[0m17:18:09.277749 [debug] [ThreadPool]: SQL status: OK in 0.450 seconds
[0m17:18:09.279824 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7b3f-1a0d-993d-aa36ea6af208, command-id=01f0b023-7b4b-1509-81e2-bec20c502467) - Closing
[0m17:18:09.280823 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:18:09.280823 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7b3f-1a0d-993d-aa36ea6af208) - Closing
[0m17:18:09.353834 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev) - Creating connection
[0m17:18:09.353834 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev'
[0m17:18:09.355856 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev"
[0m17:18:09.356851 [debug] [ThreadPool]: On list_dbt_tutorial_dev: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev"} */

    show databases
  
[0m17:18:09.356851 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:09.527373 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7b90-121e-a614-292cf566d7c3) - Created
[0m17:18:09.806543 [debug] [ThreadPool]: SQL status: OK in 0.450 seconds
[0m17:18:09.808079 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7b90-121e-a614-292cf566d7c3, command-id=01f0b023-7b9b-1a54-8668-b84ff723cc22) - Closing
[0m17:18:09.809094 [debug] [ThreadPool]: On list_dbt_tutorial_dev: Close
[0m17:18:09.809094 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7b90-121e-a614-292cf566d7c3) - Closing
[0m17:18:09.881148 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_silver) - Creating connection
[0m17:18:09.881148 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_silver'
[0m17:18:09.892512 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_silver"
[0m17:18:09.893517 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'silver'

  
[0m17:18:09.893517 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:10.117073 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7be7-11e0-b2df-77e227b92596) - Created
[0m17:18:10.661276 [debug] [ThreadPool]: SQL status: OK in 0.770 seconds
[0m17:18:10.663801 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7be7-11e0-b2df-77e227b92596, command-id=01f0b023-7bf2-1b16-b504-7fae47e5dfa2) - Closing
[0m17:18:10.664800 [debug] [ThreadPool]: On list_dbt_tutorial_dev_silver: Close
[0m17:18:10.664800 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7be7-11e0-b2df-77e227b92596) - Closing
[0m17:18:10.746745 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_bronze) - Creating connection
[0m17:18:10.747792 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_bronze'
[0m17:18:10.750454 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_bronze"
[0m17:18:10.751474 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'bronze'

  
[0m17:18:10.751474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:10.960772 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7c68-11e8-b5eb-50ae06f722d0) - Created
[0m17:18:11.307081 [debug] [ThreadPool]: SQL status: OK in 0.560 seconds
[0m17:18:11.309104 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7c68-11e8-b5eb-50ae06f722d0, command-id=01f0b023-7c73-1e28-9f86-32ef5924a275) - Closing
[0m17:18:11.309104 [debug] [ThreadPool]: On list_dbt_tutorial_dev_bronze: Close
[0m17:18:11.310145 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7c68-11e8-b5eb-50ae06f722d0) - Closing
[0m17:18:11.381648 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_dev_gold) - Creating connection
[0m17:18:11.382648 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_dev_gold'
[0m17:18:11.386441 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_dev_gold"
[0m17:18:11.386441 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "connection_name": "list_dbt_tutorial_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_dev' 
  AND table_schema = 'gold'

  
[0m17:18:11.387441 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:18:11.568848 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7cc4-1ba7-9370-db6245d77166) - Created
[0m17:18:12.019915 [debug] [ThreadPool]: SQL status: OK in 0.630 seconds
[0m17:18:12.020918 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b023-7cc4-1ba7-9370-db6245d77166, command-id=01f0b023-7cd0-1562-b34d-d189f9048971) - Closing
[0m17:18:12.022427 [debug] [ThreadPool]: On list_dbt_tutorial_dev_gold: Close
[0m17:18:12.022427 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b023-7cc4-1ba7-9370-db6245d77166) - Closing
[0m17:18:12.090977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF0FD8320>]}
[0m17:18:12.095371 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m17:18:12.095371 [info ] [Thread-1 (]: 1 of 18 START sql table model bronze.bronze_customer ........................... [RUN]
[0m17:18:12.096391 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m17:18:12.096391 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m17:18:12.097406 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m17:18:12.105908 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m17:18:12.107412 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m17:18:12.123276 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:18:12.124295 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m17:18:12.124295 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97C70410>]}
[0m17:18:12.170632 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m17:18:12.170632 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m17:18:12.171632 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_customer`
  
[0m17:18:12.171632 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:12.340745 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7d3d-1175-9ad2-22546b606c4e) - Created
[0m17:18:14.451758 [debug] [Thread-1 (]: SQL status: OK in 2.280 seconds
[0m17:18:14.452264 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-7d3d-1175-9ad2-22546b606c4e, command-id=01f0b023-7d46-1055-b70c-9076ed48e753) - Closing
[0m17:18:14.464646 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:14.481423 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m17:18:14.481423 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7d3d-1175-9ad2-22546b606c4e) - Closing
[0m17:18:14.555185 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF0F085C0>]}
[0m17:18:14.556221 [info ] [Thread-1 (]: 1 of 18 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 2.46s]
[0m17:18:14.557242 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m17:18:14.558261 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m17:18:14.559281 [info ] [Thread-1 (]: 2 of 18 START sql view model bronze.bronze_date ................................ [RUN]
[0m17:18:14.559281 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m17:18:14.560614 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m17:18:14.560614 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m17:18:14.566178 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m17:18:14.567664 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m17:18:14.693311 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:18:14.704388 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_date`
[0m17:18:14.705386 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m17:18:14.705386 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m17:18:14.706387 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_date`
  )

[0m17:18:14.706387 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:14.904536 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7ec4-1f99-86dc-76e418e8f7ed) - Created
[0m17:18:15.597752 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m17:18:15.599758 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-7ec4-1f99-86dc-76e418e8f7ed, command-id=01f0b023-7ecd-16a4-b473-8eb738840cb0) - Closing
[0m17:18:15.601754 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:15.602754 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m17:18:15.603262 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7ec4-1f99-86dc-76e418e8f7ed) - Closing
[0m17:18:15.678744 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97C582C0>]}
[0m17:18:15.679762 [info ] [Thread-1 (]: 2 of 18 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.12s]
[0m17:18:15.680780 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m17:18:15.680780 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m17:18:15.681950 [info ] [Thread-1 (]: 3 of 18 START sql view model bronze.bronze_product ............................. [RUN]
[0m17:18:15.682457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m17:18:15.683544 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m17:18:15.683544 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m17:18:15.686652 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m17:18:15.687688 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m17:18:15.690742 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:18:15.690742 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_product`
[0m17:18:15.692617 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m17:18:15.692617 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m17:18:15.692617 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_product`
  )

[0m17:18:15.694038 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:15.860757 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7f57-128d-96f1-e21de19749be) - Created
[0m17:18:16.482548 [debug] [Thread-1 (]: SQL status: OK in 0.790 seconds
[0m17:18:16.483824 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-7f57-128d-96f1-e21de19749be, command-id=01f0b023-7f5f-12bf-896f-052bd1ee9687) - Closing
[0m17:18:16.484822 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:16.484822 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m17:18:16.485821 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7f57-128d-96f1-e21de19749be) - Closing
[0m17:18:16.578138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97C2EEA0>]}
[0m17:18:16.578656 [info ] [Thread-1 (]: 3 of 18 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 0.90s]
[0m17:18:16.579695 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m17:18:16.579695 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m17:18:16.580221 [info ] [Thread-1 (]: 4 of 18 START sql table model bronze.bronze_returns ............................ [RUN]
[0m17:18:16.580740 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m17:18:16.581268 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m17:18:16.581783 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m17:18:16.585897 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m17:18:16.586459 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m17:18:16.588524 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:18:16.589523 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m17:18:16.590523 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m17:18:16.590523 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_returns`
  
[0m17:18:16.590523 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:16.760517 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7fdf-17d7-af0f-50d2e409809e) - Created
[0m17:18:19.093418 [debug] [Thread-1 (]: SQL status: OK in 2.500 seconds
[0m17:18:19.094438 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-7fdf-17d7-af0f-50d2e409809e, command-id=01f0b023-7fe8-1742-a005-80923efcfa6d) - Closing
[0m17:18:19.095480 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:19.096495 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m17:18:19.096495 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-7fdf-17d7-af0f-50d2e409809e) - Closing
[0m17:18:19.169176 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF4006750>]}
[0m17:18:19.169176 [info ] [Thread-1 (]: 4 of 18 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 2.59s]
[0m17:18:19.170225 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m17:18:19.171239 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m17:18:19.171239 [info ] [Thread-1 (]: 5 of 18 START sql view model bronze.bronze_sales ............................... [RUN]
[0m17:18:19.172758 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m17:18:19.172758 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m17:18:19.173803 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m17:18:19.179031 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m17:18:19.180048 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m17:18:19.185592 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:18:19.186588 [debug] [Thread-1 (]: Creating view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
[0m17:18:19.186588 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m17:18:19.187593 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m17:18:19.187593 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_dev`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`fact_sales`
  )

[0m17:18:19.188588 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:19.403221 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8173-185a-a240-b4c061770685) - Created
[0m17:18:20.230709 [debug] [Thread-1 (]: SQL status: OK in 1.040 seconds
[0m17:18:20.231925 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-8173-185a-a240-b4c061770685, command-id=01f0b023-817c-1085-8adc-1650e126ae5e) - Closing
[0m17:18:20.232429 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:20.235548 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m17:18:20.235548 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8173-185a-a240-b4c061770685) - Closing
[0m17:18:20.309051 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C971B4A70>]}
[0m17:18:20.310049 [info ] [Thread-1 (]: 5 of 18 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.14s]
[0m17:18:20.311318 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m17:18:20.311318 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m17:18:20.312902 [info ] [Thread-1 (]: 6 of 18 START sql table model bronze.bronze_store .............................. [RUN]
[0m17:18:20.313913 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m17:18:20.313913 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m17:18:20.313913 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m17:18:20.317920 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m17:18:20.318922 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m17:18:20.320921 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:18:20.323437 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m17:18:20.323437 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m17:18:20.324436 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_dev`.`source`.`dim_store`
  
[0m17:18:20.324436 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:20.492468 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8219-1b7d-b3b9-4c5e7340cf14) - Created
[0m17:18:22.551012 [debug] [Thread-1 (]: SQL status: OK in 2.230 seconds
[0m17:18:22.552517 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-8219-1b7d-b3b9-4c5e7340cf14, command-id=01f0b023-8222-125d-8437-b3432bdcc185) - Closing
[0m17:18:22.553523 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:22.554525 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m17:18:22.554525 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8219-1b7d-b3b9-4c5e7340cf14) - Closing
[0m17:18:22.622608 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97894E90>]}
[0m17:18:22.624180 [info ] [Thread-1 (]: 6 of 18 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 2.31s]
[0m17:18:22.625190 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m17:18:22.626190 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.source_gold_items
[0m17:18:22.626190 [info ] [Thread-1 (]: 7 of 18 START sql table model gold.source_gold_items ........................... [RUN]
[0m17:18:22.627591 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.source_gold_items) - Creating connection
[0m17:18:22.628626 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.source_gold_items'
[0m17:18:22.628626 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.source_gold_items
[0m17:18:22.633138 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.source_gold_items"
[0m17:18:22.634146 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.source_gold_items
[0m17:18:22.637141 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:18:22.638143 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.source_gold_items"
[0m17:18:22.639143 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.source_gold_items"
[0m17:18:22.639143 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.source_gold_items"} */

  
    
        create or replace table `dbt_tutorial_dev`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH dedup_query AS (
    SELECT
        *,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY updateDate DESC) AS deduplication_id
    FROM 
        `dbt_tutorial_dev`.`source`.`items`
)

SELECT
    id,
    name,
    category,
    updateDate
FROM
    dedup_query
WHERE
    deduplication_id = 1
  
[0m17:18:22.639143 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:22.834599 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-837e-10fe-a5fd-cbd9344c7995) - Created
[0m17:18:24.795841 [debug] [Thread-1 (]: SQL status: OK in 2.160 seconds
[0m17:18:24.796842 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-837e-10fe-a5fd-cbd9344c7995, command-id=01f0b023-8387-1b25-aef6-b8c3f270a095) - Closing
[0m17:18:24.797841 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:24.798841 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: Close
[0m17:18:24.799844 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-837e-10fe-a5fd-cbd9344c7995) - Closing
[0m17:18:24.875988 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97C2EF90>]}
[0m17:18:24.875988 [info ] [Thread-1 (]: 7 of 18 OK created sql table model gold.source_gold_items ...................... [[32mOK[0m in 2.25s]
[0m17:18:24.877992 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.source_gold_items
[0m17:18:24.877992 [debug] [Thread-1 (]: Began running node seed.octy_dbt_learn.lookup
[0m17:18:24.878986 [info ] [Thread-1 (]: 8 of 18 START seed file bronze.lookup .......................................... [RUN]
[0m17:18:24.879986 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.octy_dbt_learn.lookup) - Creating connection
[0m17:18:24.879986 [debug] [Thread-1 (]: Acquiring new databricks connection 'seed.octy_dbt_learn.lookup'
[0m17:18:24.879986 [debug] [Thread-1 (]: Began compiling node seed.octy_dbt_learn.lookup
[0m17:18:24.880984 [debug] [Thread-1 (]: Began executing node seed.octy_dbt_learn.lookup
[0m17:18:24.914565 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:18:24.915072 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "seed.octy_dbt_learn.lookup"} */

    create or replace table `dbt_tutorial_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m17:18:24.915072 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:25.128968 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-84d8-18f1-a002-d82e1d17925c) - Created
[0m17:18:26.532927 [debug] [Thread-1 (]: SQL status: OK in 1.620 seconds
[0m17:18:26.534390 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-84d8-18f1-a002-d82e1d17925c, command-id=01f0b023-84e5-1b07-9213-f80bba19bd4e) - Closing
[0m17:18:26.550371 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:18:26.550876 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: 
          insert overwrite `dbt_tutorial_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m17:18:28.057003 [debug] [Thread-1 (]: SQL status: OK in 1.510 seconds
[0m17:18:28.058076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-84d8-18f1-a002-d82e1d17925c, command-id=01f0b023-85be-1919-a612-1289a667a5b8) - Closing
[0m17:18:28.064664 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.octy_dbt_learn.lookup"
[0m17:18:28.067217 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: Close
[0m17:18:28.068276 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-84d8-18f1-a002-d82e1d17925c) - Closing
[0m17:18:28.143547 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C97C3BB90>]}
[0m17:18:28.144560 [info ] [Thread-1 (]: 8 of 18 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.26s]
[0m17:18:28.144560 [debug] [Thread-1 (]: Finished running node seed.octy_dbt_learn.lookup
[0m17:18:28.145561 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:18:28.146602 [info ] [Thread-1 (]: 9 of 18 START test generic_non_negative_bronze_sales_gross_amount .............. [RUN]
[0m17:18:28.147106 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1) - Creating connection
[0m17:18:28.148137 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1'
[0m17:18:28.148137 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:18:28.157045 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:18:28.158066 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:18:28.177091 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:18:28.178109 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"
[0m17:18:28.178109 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

    SELECT
        *
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
    WHERE 
        gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m17:18:28.178109 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:28.358996 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-86c8-1fe0-9c4d-ac5c4fc51d9f) - Created
[0m17:18:28.553679 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m17:18:28.555965 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-86c8-1fe0-9c4d-ac5c4fc51d9f, command-id=01f0b023-86d2-1729-99a8-559addddbf43) - Closing
[0m17:18:28.558964 [debug] [Thread-1 (]: On test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1: Close
[0m17:18:28.559964 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-86c8-1fe0-9c4d-ac5c4fc51d9f) - Closing
[0m17:18:28.630929 [info ] [Thread-1 (]: 9 of 18 PASS generic_non_negative_bronze_sales_gross_amount .................... [[32mPASS[0m in 0.48s]
[0m17:18:28.631943 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:18:28.631943 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.non_negative_test
[0m17:18:28.632943 [info ] [Thread-1 (]: 10 of 18 START test non_negative_test .......................................... [RUN]
[0m17:18:28.634389 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.non_negative_test) - Creating connection
[0m17:18:28.634389 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.non_negative_test'
[0m17:18:28.635440 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.non_negative_test
[0m17:18:28.639955 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.non_negative_test"
[0m17:18:28.640992 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.non_negative_test
[0m17:18:28.643686 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.non_negative_test"
[0m17:18:28.645721 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.non_negative_test"
[0m17:18:28.645721 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.non_negative_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT
    *
FROM 
    `dbt_tutorial_dev`.`bronze`.`bronze_sales`
WHERE 
    gross_amount < 0 AND net_amount < 0
  
  
      
    ) dbt_internal_test
[0m17:18:28.645721 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:28.818666 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-870e-1bbd-9d72-0179a5b42024) - Created
[0m17:18:29.004488 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m17:18:29.007495 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-870e-1bbd-9d72-0179a5b42024, command-id=01f0b023-8718-19fd-be5d-55846b6228a7) - Closing
[0m17:18:29.007495 [debug] [Thread-1 (]: On test.octy_dbt_learn.non_negative_test: Close
[0m17:18:29.008495 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-870e-1bbd-9d72-0179a5b42024) - Closing
[0m17:18:29.080687 [info ] [Thread-1 (]: 10 of 18 PASS non_negative_test ................................................ [[32mPASS[0m in 0.45s]
[0m17:18:29.081687 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.non_negative_test
[0m17:18:29.081687 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:18:29.082687 [info ] [Thread-1 (]: 11 of 18 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m17:18:29.083194 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m17:18:29.083194 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m17:18:29.084196 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:18:29.091196 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:18:29.092699 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:18:29.095704 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:18:29.095704 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m17:18:29.096703 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m17:18:29.096703 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:29.266622 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8753-19e3-903e-7fd0d7fe4c33) - Created
[0m17:18:29.473233 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m17:18:29.475413 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-8753-19e3-903e-7fd0d7fe4c33, command-id=01f0b023-875d-1189-9b8b-b35aa1b06c75) - Closing
[0m17:18:29.476452 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m17:18:29.477527 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8753-19e3-903e-7fd0d7fe4c33) - Closing
[0m17:18:29.549332 [info ] [Thread-1 (]: 11 of 18 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 0.47s]
[0m17:18:29.550613 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:18:29.550613 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:18:29.550613 [info ] [Thread-1 (]: 12 of 18 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m17:18:29.552000 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m17:18:29.552000 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d'
[0m17:18:29.553016 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:18:29.560593 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:18:29.561593 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:18:29.564108 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:18:29.564821 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"
[0m17:18:29.564821 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:18:29.565345 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:29.742689 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-879c-14d1-b09e-f130a976ceca) - Created
[0m17:18:29.938269 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m17:18:29.940561 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-879c-14d1-b09e-f130a976ceca, command-id=01f0b023-87a6-17f7-a3c9-3cdc74dc150d) - Closing
[0m17:18:29.941586 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m17:18:29.941586 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-879c-14d1-b09e-f130a976ceca) - Closing
[0m17:18:30.020073 [info ] [Thread-1 (]: 12 of 18 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.47s]
[0m17:18:30.021114 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:18:30.021114 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:18:30.022136 [info ] [Thread-1 (]: 13 of 18 START test accepted_values_bronze_store_country__USA__Canada .......... [RUN]
[0m17:18:30.022644 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7) - Creating connection
[0m17:18:30.023755 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7'
[0m17:18:30.023755 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:18:30.035502 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:18:30.036517 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:18:30.038515 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:18:30.039527 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"
[0m17:18:30.039527 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        country as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by country

)

select *
from all_values
where value_field not in (
    'USA','Canada'
)



  
  
      
    ) dbt_internal_test
[0m17:18:30.039527 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:30.226451 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-87e6-1b59-a7a0-4e03a5b79197) - Created
[0m17:18:30.823195 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m17:18:30.825608 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-87e6-1b59-a7a0-4e03a5b79197, command-id=01f0b023-87ef-1114-a6c9-93067623570a) - Closing
[0m17:18:30.826628 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7: Close
[0m17:18:30.826628 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-87e6-1b59-a7a0-4e03a5b79197) - Closing
[0m17:18:30.901885 [info ] [Thread-1 (]: 13 of 18 PASS accepted_values_bronze_store_country__USA__Canada ................ [[32mPASS[0m in 0.88s]
[0m17:18:30.902898 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:18:30.902898 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:18:30.902898 [info ] [Thread-1 (]: 14 of 18 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m17:18:30.903904 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m17:18:30.903904 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m17:18:30.904909 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:18:30.912710 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:18:30.913715 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:18:30.915722 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:18:30.916723 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m17:18:30.916723 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_tutorial_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m17:18:30.916723 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:31.097640 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-886b-1618-965c-2a895fc62793) - Created
[0m17:18:31.498348 [debug] [Thread-1 (]: SQL status: OK in 0.580 seconds
[0m17:18:31.501592 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-886b-1618-965c-2a895fc62793, command-id=01f0b023-8873-1edd-ad44-4d441bd535bb) - Closing
[0m17:18:31.502593 [debug] [Thread-1 (]: On test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m17:18:31.503098 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-886b-1618-965c-2a895fc62793) - Closing
[0m17:18:31.579254 [info ] [Thread-1 (]: 14 of 18 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.67s]
[0m17:18:31.580253 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:18:31.580253 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:18:31.581251 [info ] [Thread-1 (]: 15 of 18 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m17:18:31.581251 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m17:18:31.582756 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a'
[0m17:18:31.582756 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:18:31.588824 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:18:31.589819 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:18:31.591820 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:18:31.592836 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"
[0m17:18:31.593843 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m17:18:31.593843 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:31.775687 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-88d1-1c64-8e44-6b3dcb5b2f08) - Created
[0m17:18:32.157059 [debug] [Thread-1 (]: SQL status: OK in 0.560 seconds
[0m17:18:32.159071 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-88d1-1c64-8e44-6b3dcb5b2f08, command-id=01f0b023-88dc-1ffe-9849-f39e8db9e863) - Closing
[0m17:18:32.160065 [debug] [Thread-1 (]: On test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m17:18:32.161065 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-88d1-1c64-8e44-6b3dcb5b2f08) - Closing
[0m17:18:32.237909 [info ] [Thread-1 (]: 15 of 18 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 0.66s]
[0m17:18:32.238920 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:18:32.238920 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:18:32.238920 [info ] [Thread-1 (]: 16 of 18 START test unique_bronze_store_store_sk ............................... [RUN]
[0m17:18:32.239937 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m17:18:32.240948 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63'
[0m17:18:32.240948 [debug] [Thread-1 (]: Began compiling node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:18:32.247759 [debug] [Thread-1 (]: Writing injected SQL for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:18:32.248771 [debug] [Thread-1 (]: Began executing node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:18:32.250931 [debug] [Thread-1 (]: Writing runtime sql for node "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:18:32.250931 [debug] [Thread-1 (]: Using databricks connection "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"
[0m17:18:32.251950 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_tutorial_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:18:32.251950 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:32.425270 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8936-10d8-8b1b-b14a73a0f188) - Created
[0m17:18:32.830556 [debug] [Thread-1 (]: SQL status: OK in 0.580 seconds
[0m17:18:32.833063 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-8936-10d8-8b1b-b14a73a0f188, command-id=01f0b023-893e-1f0a-952e-26d8925b9c1b) - Closing
[0m17:18:32.834073 [debug] [Thread-1 (]: On test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63: Close
[0m17:18:32.834073 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8936-10d8-8b1b-b14a73a0f188) - Closing
[0m17:18:32.904098 [info ] [Thread-1 (]: 16 of 18 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.66s]
[0m17:18:32.905097 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:18:32.905097 [debug] [Thread-1 (]: Began running node snapshot.octy_dbt_learn.gold_items
[0m17:18:32.906099 [info ] [Thread-1 (]: 17 of 18 START snapshot gold.gold_items ........................................ [RUN]
[0m17:18:32.907096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.octy_dbt_learn.gold_items) - Creating connection
[0m17:18:32.908099 [debug] [Thread-1 (]: Acquiring new databricks connection 'snapshot.octy_dbt_learn.gold_items'
[0m17:18:32.908099 [debug] [Thread-1 (]: Began compiling node snapshot.octy_dbt_learn.gold_items
[0m17:18:32.913606 [debug] [Thread-1 (]: Began executing node snapshot.octy_dbt_learn.gold_items
[0m17:18:32.949710 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:33.120056 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-89a0-1b24-98f7-7170de481922) - Created
[0m17:18:33.125716 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:33.126741 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_tutorial_dev`.`gold`.`gold_items` AS JSON

  
[0m17:18:33.395871 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m17:18:33.396868 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-89a9-1af2-9a57-a2a95f9b9485) - Closing
[0m17:18:33.440459 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:33.441459 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

        
  
    create or replace temporary view `gold_items__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_tutorial_dev`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            updateDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updateDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updateDate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m17:18:33.826484 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m17:18:33.827772 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-89d9-19ee-94c7-80760bd5c705) - Closing
[0m17:18:33.829827 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:33.830850 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:18:33.978797 [debug] [Thread-1 (]: SQL status: OK in 0.150 seconds
[0m17:18:33.981280 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a15-15c6-b94c-0cb60b19b9fd) - Closing
[0m17:18:33.984976 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:33.985975 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_tutorial_dev`.`gold`.`gold_items` AS JSON

  
[0m17:18:34.169306 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m17:18:34.171370 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a2c-1f84-aa32-4b818c3c0ec5) - Closing
[0m17:18:34.174486 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:34.174486 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:18:34.336627 [debug] [Thread-1 (]: SQL status: OK in 0.160 seconds
[0m17:18:34.338653 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a49-1896-8411-7f01d7de7d87) - Closing
[0m17:18:34.341650 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:34.341650 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt_tutorial_dev`.`gold`.`gold_items` AS JSON

  
[0m17:18:34.525321 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m17:18:34.527360 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a63-12c6-a61d-01b8b6c3acfc) - Closing
[0m17:18:34.534992 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:34.536006 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:18:34.697599 [debug] [Thread-1 (]: SQL status: OK in 0.160 seconds
[0m17:18:34.699601 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a81-19b9-9b7b-f4750eaf6e38) - Closing
[0m17:18:34.714633 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:34.715640 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt_tutorial_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_tutorial_dev`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            
  
  coalesce(nullif(updateDate, updateDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updateDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updateDate as dbt_updated_at,
            updateDate as dbt_valid_from,
            updateDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updateDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updateDate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m17:18:35.083149 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m17:18:35.089224 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:35.089224 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m17:18:35.090240 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8a9c-1810-aa4e-dce38a93f8ef) - Closing
[0m17:18:35.260431 [debug] [Thread-1 (]: SQL status: OK in 0.170 seconds
[0m17:18:35.261434 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.octy_dbt_learn.gold_items"
[0m17:18:35.261434 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:35.262943 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */

      merge into `dbt_tutorial_dev`.`gold`.`gold_items` as DBT_INTERNAL_DEST
    
      using `gold_items__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m17:18:35.262943 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8ad5-1e11-badf-3e74ead59c13) - Closing
[0m17:18:42.732913 [debug] [Thread-1 (]: SQL status: OK in 7.470 seconds
[0m17:18:42.734463 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8aef-1a3f-903a-44b2dd195c1e) - Closing
[0m17:18:42.848697 [debug] [Thread-1 (]: Applying DROP to: `gold_items__dbt_tmp`
[0m17:18:42.853358 [debug] [Thread-1 (]: Using databricks connection "snapshot.octy_dbt_learn.gold_items"
[0m17:18:42.853358 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "snapshot.octy_dbt_learn.gold_items"} */
DROP VIEW IF EXISTS `gold_items__dbt_tmp`
[0m17:18:43.056568 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m17:18:43.057616 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-89a0-1b24-98f7-7170de481922, command-id=01f0b023-8f77-1d64-a291-0e45ab5edf42) - Closing
[0m17:18:43.058674 [debug] [Thread-1 (]: On snapshot.octy_dbt_learn.gold_items: Close
[0m17:18:43.058674 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-89a0-1b24-98f7-7170de481922) - Closing
[0m17:18:43.135169 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017C971B76B0>]}
[0m17:18:43.136245 [info ] [Thread-1 (]: 17 of 18 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 10.23s]
[0m17:18:43.136245 [debug] [Thread-1 (]: Finished running node snapshot.octy_dbt_learn.gold_items
[0m17:18:43.137712 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.silver_sales_info
[0m17:18:43.137712 [info ] [Thread-1 (]: 18 of 18 START sql table model silver.silver_sales_info ........................ [RUN]
[0m17:18:43.138728 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.silver_sales_info) - Creating connection
[0m17:18:43.139728 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.silver_sales_info'
[0m17:18:43.139728 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.silver_sales_info
[0m17:18:43.145406 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.silver_sales_info"
[0m17:18:43.146428 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.silver_sales_info
[0m17:18:43.148426 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:18:43.149438 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.silver_sales_info"
[0m17:18:43.150854 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.silver_sales_info"
[0m17:18:43.150854 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "dev", "node_id": "model.octy_dbt_learn.silver_sales_info"} */

  
    
        create or replace table `dbt_tutorial_dev`.`silver`.`silver_sales_info`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH sales AS (
    SELECT
        sales_id,
        product_sk,
        customer_sk,
        unit_price * quantity AS calculated_gross_amount,
        gross_amount,
        payment_method
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_sales`
),

products AS (
    SELECT
        product_sk,
        category
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_product`
),

customer AS (
    SELECT
        customer_sk,
        gender
    FROM
        `dbt_tutorial_dev`.`bronze`.`bronze_customer`
),

joined_query AS (
    SELECT
        s.sales_id,
        s.gross_amount,
        s.payment_method,
        p.category,
        c.gender
    FROM
        sales s
    JOIN
        products p ON s.product_sk = p.product_sk
    JOIN
        customer c ON s.customer_sk = c.customer_sk
)

SELECT
    category,
    gender,
    sum(gross_amount) AS total_sales
FROM joined_query
GROUP BY
    1,
    2
ORDER BY  
    total_sales DESC
  
[0m17:18:43.150854 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:18:43.362254 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8fb8-113f-88c5-8649a8d93c94) - Created
[0m17:18:46.204116 [debug] [Thread-1 (]: SQL status: OK in 3.050 seconds
[0m17:18:46.205141 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b023-8fb8-113f-88c5-8649a8d93c94, command-id=01f0b023-8fc3-1a5d-8707-92db8cba7461) - Closing
[0m17:18:46.205141 [debug] [Thread-1 (]: Applying tags to relation None
[0m17:18:46.207155 [debug] [Thread-1 (]: On model.octy_dbt_learn.silver_sales_info: Close
[0m17:18:46.207155 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b023-8fb8-113f-88c5-8649a8d93c94) - Closing
[0m17:18:46.284433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '354484ff-bbf1-4588-901c-0bba6e967070', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF40382C0>]}
[0m17:18:46.285432 [info ] [Thread-1 (]: 18 of 18 OK created sql table model silver.silver_sales_info ................... [[32mOK[0m in 3.15s]
[0m17:18:46.286431 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.silver_sales_info
[0m17:18:46.288432 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:18:46.288432 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:18:46.289431 [info ] [MainThread]: 
[0m17:18:46.289431 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 8 data tests, 3 view models in 0 hours 0 minutes and 38.10 seconds (38.10s).
[0m17:18:46.293432 [debug] [MainThread]: Command end result
[0m17:18:46.325324 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:18:46.328325 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:18:46.336096 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m17:18:46.336096 [info ] [MainThread]: 
[0m17:18:46.337093 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:18:46.337093 [info ] [MainThread]: 
[0m17:18:46.337093 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=18
[0m17:18:46.338093 [debug] [MainThread]: Command `dbt build` succeeded at 17:18:46.338093 after 40.56 seconds
[0m17:18:46.338093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF3CC4F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF2EF12E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017CF2EF3FB0>]}
[0m17:18:46.339296 [debug] [MainThread]: Flushing usage events
[0m17:18:47.096503 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:44:21.133213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB8DD5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB7C77920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB6079760>]}


============================== 17:44:21.137684 | 972b4757-f840-462d-b0c7-d576298d4bf4 ==============================
[0m17:44:21.137684 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:44:21.137684 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'invocation_command': 'dbt build --target prod', 'target_path': 'None', 'no_print': 'None', 'warn_error': 'None', 'log_path': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn\\logs', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'D:\\Projects\\DBT_TUTORIAL\\octy_dbt_learn', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m17:44:21.947972 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:44:21.948972 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:44:21.948972 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:44:22.824583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDBC27F20>]}
[0m17:44:22.881274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDB232990>]}
[0m17:44:22.882800 [info ] [MainThread]: Registered adapter: databricks=1.10.14
[0m17:44:23.187343 [debug] [MainThread]: checksum: fd5f499d60404c73e369f2149bd6aa6c74754a4e78aa98476ca57564d99f7088, vars: {}, profile: , target: prod, version: 1.10.13
[0m17:44:23.319445 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:44:23.319445 [debug] [MainThread]: previous checksum: fd5f499d60404c73e369f2149bd6aa6c74754a4e78aa98476ca57564d99f7088, current checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe
[0m17:44:23.320950 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m17:44:23.320950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDC3012B0>]}
[0m17:44:25.517212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDDA807A0>]}
[0m17:44:25.628804 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:44:25.631319 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:44:25.653848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDD9281D0>]}
[0m17:44:25.654848 [info ] [MainThread]: Found 8 models, 5 analyses, 8 data tests, 1 seed, 1 snapshot, 7 sources, 702 macros
[0m17:44:25.657847 [info ] [MainThread]: 
[0m17:44:25.657847 [info ] [MainThread]: Concurrency: 1 threads (target='prod')
[0m17:44:25.657847 [info ] [MainThread]: 
[0m17:44:25.658885 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:44:25.658885 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:44:25.665486 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod) - Creating connection
[0m17:44:25.666486 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod'
[0m17:44:25.675138 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod"
[0m17:44:25.675138 [debug] [ThreadPool]: On list_dbt_tutorial_prod: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod"} */

    show databases
  
[0m17:44:25.676149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:25.954039 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-272a-1a79-b33b-3c4a0ddb025b) - Created
[0m17:44:26.880989 [debug] [ThreadPool]: SQL status: OK in 1.200 seconds
[0m17:44:26.885094 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-272a-1a79-b33b-3c4a0ddb025b, command-id=01f0b027-2736-156a-84e8-48b484e1b189) - Closing
[0m17:44:26.885094 [debug] [ThreadPool]: On list_dbt_tutorial_prod: Close
[0m17:44:26.886095 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-272a-1a79-b33b-3c4a0ddb025b) - Closing
[0m17:44:26.978472 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod) - Creating connection
[0m17:44:26.979594 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod'
[0m17:44:26.982171 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod"
[0m17:44:26.983196 [debug] [ThreadPool]: On list_dbt_tutorial_prod: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod"} */

    show databases
  
[0m17:44:26.983196 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:27.190383 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-27e6-1d9e-9e4d-ce22b7b69b47) - Created
[0m17:44:27.497776 [debug] [ThreadPool]: SQL status: OK in 0.510 seconds
[0m17:44:27.499789 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-27e6-1d9e-9e4d-ce22b7b69b47, command-id=01f0b027-27f2-15d0-959a-cbb46e242e5c) - Closing
[0m17:44:27.499789 [debug] [ThreadPool]: On list_dbt_tutorial_prod: Close
[0m17:44:27.501307 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-27e6-1d9e-9e4d-ce22b7b69b47) - Closing
[0m17:44:27.580161 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod) - Creating connection
[0m17:44:27.581161 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod'
[0m17:44:27.584682 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod"
[0m17:44:27.585683 [debug] [ThreadPool]: On list_dbt_tutorial_prod: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod"} */

    show databases
  
[0m17:44:27.585683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:27.805639 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2843-1c6a-bb6c-1fc102adf4d8) - Created
[0m17:44:28.105169 [debug] [ThreadPool]: SQL status: OK in 0.520 seconds
[0m17:44:28.107691 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-2843-1c6a-bb6c-1fc102adf4d8, command-id=01f0b027-2855-1d5e-b5a3-e1d87316179c) - Closing
[0m17:44:28.108687 [debug] [ThreadPool]: On list_dbt_tutorial_prod: Close
[0m17:44:28.108687 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2843-1c6a-bb6c-1fc102adf4d8) - Closing
[0m17:44:28.203048 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_prod_bronze) - Creating connection
[0m17:44:28.204073 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_prod_bronze'
[0m17:44:28.204073 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_prod"
schema: "bronze"
"
[0m17:44:28.212571 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_prod_bronze"
[0m17:44:28.213589 [debug] [ThreadPool]: On create_dbt_tutorial_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "create_dbt_tutorial_prod_bronze"} */
create schema if not exists `dbt_tutorial_prod`.`bronze`
  
[0m17:44:28.213589 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:28.439448 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-28a4-1c64-b77d-ade0c6bdd1c6) - Created
[0m17:44:29.272362 [debug] [ThreadPool]: SQL status: OK in 1.060 seconds
[0m17:44:29.274414 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-28a4-1c64-b77d-ade0c6bdd1c6, command-id=01f0b027-28b1-1edd-8b58-ee775e8fcace) - Closing
[0m17:44:29.274414 [debug] [ThreadPool]: On create_dbt_tutorial_prod_bronze: Close
[0m17:44:29.274414 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-28a4-1c64-b77d-ade0c6bdd1c6) - Closing
[0m17:44:29.348965 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_prod_gold) - Creating connection
[0m17:44:29.349964 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_prod_gold'
[0m17:44:29.349964 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_prod"
schema: "gold"
"
[0m17:44:29.352723 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_prod_gold"
[0m17:44:29.353788 [debug] [ThreadPool]: On create_dbt_tutorial_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "create_dbt_tutorial_prod_gold"} */
create schema if not exists `dbt_tutorial_prod`.`gold`
  
[0m17:44:29.353788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:29.539133 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-294e-1360-8bae-c774a114c8af) - Created
[0m17:44:29.939885 [debug] [ThreadPool]: SQL status: OK in 0.590 seconds
[0m17:44:29.941391 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-294e-1360-8bae-c774a114c8af, command-id=01f0b027-295a-11ad-98ee-a95b41ddc85b) - Closing
[0m17:44:29.941391 [debug] [ThreadPool]: On create_dbt_tutorial_prod_gold: Close
[0m17:44:29.941391 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-294e-1360-8bae-c774a114c8af) - Closing
[0m17:44:30.045550 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_tutorial_prod_silver) - Creating connection
[0m17:44:30.045550 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_tutorial_prod_silver'
[0m17:44:30.046550 [debug] [ThreadPool]: Creating schema "database: "dbt_tutorial_prod"
schema: "silver"
"
[0m17:44:30.050606 [debug] [ThreadPool]: Using databricks connection "create_dbt_tutorial_prod_silver"
[0m17:44:30.050606 [debug] [ThreadPool]: On create_dbt_tutorial_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "create_dbt_tutorial_prod_silver"} */
create schema if not exists `dbt_tutorial_prod`.`silver`
  
[0m17:44:30.051112 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:30.286350 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-29bf-1945-9a96-4a16cf19a049) - Created
[0m17:44:30.721228 [debug] [ThreadPool]: SQL status: OK in 0.670 seconds
[0m17:44:30.722257 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-29bf-1945-9a96-4a16cf19a049, command-id=01f0b027-29cb-1a38-a5ee-94698a45afd1) - Closing
[0m17:44:30.722257 [debug] [ThreadPool]: On create_dbt_tutorial_prod_silver: Close
[0m17:44:30.723256 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-29bf-1945-9a96-4a16cf19a049) - Closing
[0m17:44:30.801221 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod_bronze) - Creating connection
[0m17:44:30.801221 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod_bronze'
[0m17:44:30.811942 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod_bronze"
[0m17:44:30.811942 [debug] [ThreadPool]: On list_dbt_tutorial_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_prod' 
  AND table_schema = 'bronze'

  
[0m17:44:30.811942 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:31.000444 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2a2f-177d-9417-3e4342ed5883) - Created
[0m17:44:31.888073 [debug] [ThreadPool]: SQL status: OK in 1.080 seconds
[0m17:44:31.891073 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-2a2f-177d-9417-3e4342ed5883, command-id=01f0b027-2a38-19e7-9f59-0e67f1e2c65c) - Closing
[0m17:44:31.891582 [debug] [ThreadPool]: On list_dbt_tutorial_prod_bronze: Close
[0m17:44:31.891582 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2a2f-177d-9417-3e4342ed5883) - Closing
[0m17:44:31.979640 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod_gold) - Creating connection
[0m17:44:31.979640 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod_gold'
[0m17:44:31.984165 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod_gold"
[0m17:44:31.985166 [debug] [ThreadPool]: On list_dbt_tutorial_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_prod' 
  AND table_schema = 'gold'

  
[0m17:44:31.985166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:32.163970 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2ae0-1a2c-bdce-9ccd8a009ea2) - Created
[0m17:44:32.575932 [debug] [ThreadPool]: SQL status: OK in 0.590 seconds
[0m17:44:32.577932 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-2ae0-1a2c-bdce-9ccd8a009ea2, command-id=01f0b027-2ae9-17aa-8670-0156d460fe49) - Closing
[0m17:44:32.577932 [debug] [ThreadPool]: On list_dbt_tutorial_prod_gold: Close
[0m17:44:32.578935 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2ae0-1a2c-bdce-9ccd8a009ea2) - Closing
[0m17:44:32.676424 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_tutorial_prod_silver) - Creating connection
[0m17:44:32.676424 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_tutorial_prod_silver'
[0m17:44:32.680423 [debug] [ThreadPool]: Using databricks connection "list_dbt_tutorial_prod_silver"
[0m17:44:32.681424 [debug] [ThreadPool]: On list_dbt_tutorial_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "connection_name": "list_dbt_tutorial_prod_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_tutorial_prod' 
  AND table_schema = 'silver'

  
[0m17:44:32.681932 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:44:32.879625 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2b4e-11d7-bfc8-1bc2777ab0e9) - Created
[0m17:44:33.297596 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m17:44:33.299624 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0b027-2b4e-11d7-bfc8-1bc2777ab0e9, command-id=01f0b027-2b59-105e-9d9b-6a806a678948) - Closing
[0m17:44:33.299624 [debug] [ThreadPool]: On list_dbt_tutorial_prod_silver: Close
[0m17:44:33.299624 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0b027-2b4e-11d7-bfc8-1bc2777ab0e9) - Closing
[0m17:44:33.372145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDD5B6C90>]}
[0m17:44:33.376327 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_customer
[0m17:44:33.377347 [info ] [Thread-1 (]: 1 of 18 START sql table model bronze.bronze_customer ........................... [RUN]
[0m17:44:33.378328 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_customer) - Creating connection
[0m17:44:33.378328 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_customer'
[0m17:44:33.379326 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_customer
[0m17:44:33.388358 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_customer"
[0m17:44:33.389360 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_customer
[0m17:44:33.408334 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:44:33.409867 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m17:44:33.409867 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDE0A20C0>]}
[0m17:44:33.450464 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_customer"
[0m17:44:33.451971 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_customer"
[0m17:44:33.451971 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_customer`
  
[0m17:44:33.451971 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:33.631639 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2bc1-10e1-bd4c-68500f272bf8) - Created
[0m17:44:34.133492 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_customer"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_customer`
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2bc9-1a81-99a2-535bbc3561b6
[0m17:44:34.134506 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_customer: Close
[0m17:44:34.134506 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2bc1-10e1-bd4c-68500f272bf8) - Closing
[0m17:44:34.222399 [debug] [Thread-1 (]: Database Error in model bronze_customer (models\bronze\bronze_customer.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_customer.sql
[0m17:44:34.224398 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB80ECBF0>]}
[0m17:44:34.225456 [error] [Thread-1 (]: 1 of 18 ERROR creating sql table model bronze.bronze_customer .................. [[31mERROR[0m in 0.85s]
[0m17:44:34.226479 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_customer
[0m17:44:34.226479 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_date
[0m17:44:34.226479 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_customer' to be skipped because of status 'error'.  Reason: Database Error in model bronze_customer (models\bronze\bronze_customer.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_customer.sql.
[0m17:44:34.227771 [info ] [Thread-1 (]: 2 of 18 START sql view model bronze.bronze_date ................................ [RUN]
[0m17:44:34.228956 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_date) - Creating connection
[0m17:44:34.228956 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_date'
[0m17:44:34.228956 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_date
[0m17:44:34.232475 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_date"
[0m17:44:34.233476 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_date
[0m17:44:34.247018 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:44:34.258557 [debug] [Thread-1 (]: Creating view `dbt_tutorial_prod`.`bronze`.`bronze_date`
[0m17:44:34.259570 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_date"
[0m17:44:34.259570 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_date"
[0m17:44:34.260632 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_date`
  )

[0m17:44:34.260632 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:34.450361 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2c3d-11c4-8e63-8e8cc36072a5) - Created
[0m17:44:34.742236 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_date"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_date`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_date`
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2c47-13f2-9554-f3a7c5139ae7
[0m17:44:34.744406 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_date: Close
[0m17:44:34.744406 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2c3d-11c4-8e63-8e8cc36072a5) - Closing
[0m17:44:34.820332 [debug] [Thread-1 (]: Database Error in model bronze_date (models\bronze\bronze_date.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_date.sql
[0m17:44:34.821334 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDDA554C0>]}
[0m17:44:34.821334 [error] [Thread-1 (]: 2 of 18 ERROR creating sql view model bronze.bronze_date ....................... [[31mERROR[0m in 0.59s]
[0m17:44:34.822797 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_date
[0m17:44:34.823794 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_product
[0m17:44:34.823794 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_date' to be skipped because of status 'error'.  Reason: Database Error in model bronze_date (models\bronze\bronze_date.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_date.sql.
[0m17:44:34.824797 [info ] [Thread-1 (]: 3 of 18 START sql view model bronze.bronze_product ............................. [RUN]
[0m17:44:34.825823 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_product) - Creating connection
[0m17:44:34.825823 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_product'
[0m17:44:34.826865 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_product
[0m17:44:34.829923 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_product"
[0m17:44:34.831428 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_product
[0m17:44:34.833497 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:44:34.834550 [debug] [Thread-1 (]: Creating view `dbt_tutorial_prod`.`bronze`.`bronze_product`
[0m17:44:34.835573 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_product"
[0m17:44:34.836576 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_product"
[0m17:44:34.837574 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_product`
  )

[0m17:44:34.837574 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:35.043637 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2c95-1497-a734-f3376bc0f3af) - Created
[0m17:44:35.317817 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_product"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_product`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_product`
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2ca1-1222-aa31-ac43a7be1f71
[0m17:44:35.318816 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_product: Close
[0m17:44:35.318816 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2c95-1497-a734-f3376bc0f3af) - Closing
[0m17:44:35.398879 [debug] [Thread-1 (]: Database Error in model bronze_product (models\bronze\bronze_product.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_product.sql
[0m17:44:35.399899 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDDA2CB60>]}
[0m17:44:35.399899 [error] [Thread-1 (]: 3 of 18 ERROR creating sql view model bronze.bronze_product .................... [[31mERROR[0m in 0.58s]
[0m17:44:35.401404 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_product
[0m17:44:35.402570 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_returns
[0m17:44:35.402570 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_product' to be skipped because of status 'error'.  Reason: Database Error in model bronze_product (models\bronze\bronze_product.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_product.sql.
[0m17:44:35.403593 [info ] [Thread-1 (]: 4 of 18 START sql table model bronze.bronze_returns ............................ [RUN]
[0m17:44:35.404593 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_returns) - Creating connection
[0m17:44:35.405592 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_returns'
[0m17:44:35.405592 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_returns
[0m17:44:35.408724 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_returns"
[0m17:44:35.409744 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_returns
[0m17:44:35.412833 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:44:35.418260 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_returns"
[0m17:44:35.419470 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_returns"
[0m17:44:35.419470 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`fact_returns`
  
[0m17:44:35.419470 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:35.585393 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2cea-1a4e-b63d-278ca1a4cab3) - Created
[0m17:44:35.991929 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_returns"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`fact_returns`
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2cf3-1c30-9266-962ceaeb17ee
[0m17:44:35.992945 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_returns: Close
[0m17:44:35.992945 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2cea-1a4e-b63d-278ca1a4cab3) - Closing
[0m17:44:36.069090 [debug] [Thread-1 (]: Database Error in model bronze_returns (models\bronze\bronze_returns.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_returns.sql
[0m17:44:36.070109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDE13F980>]}
[0m17:44:36.071622 [error] [Thread-1 (]: 4 of 18 ERROR creating sql table model bronze.bronze_returns ................... [[31mERROR[0m in 0.67s]
[0m17:44:36.072708 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_returns
[0m17:44:36.073736 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_sales
[0m17:44:36.073736 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_returns' to be skipped because of status 'error'.  Reason: Database Error in model bronze_returns (models\bronze\bronze_returns.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_returns.sql.
[0m17:44:36.074740 [info ] [Thread-1 (]: 5 of 18 START sql view model bronze.bronze_sales ............................... [RUN]
[0m17:44:36.075735 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_sales) - Creating connection
[0m17:44:36.075735 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_sales'
[0m17:44:36.076733 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_sales
[0m17:44:36.079838 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_sales"
[0m17:44:36.083381 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_sales
[0m17:44:36.085736 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m17:44:36.087253 [debug] [Thread-1 (]: Creating view `dbt_tutorial_prod`.`bronze`.`bronze_sales`
[0m17:44:36.087253 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_sales"
[0m17:44:36.088633 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_sales"
[0m17:44:36.088633 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`fact_sales`
  )

[0m17:44:36.088633 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:36.271730 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2d53-1d50-828f-303d6958d7ae) - Created
[0m17:44:36.548989 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_sales"} */

  
  
  create or replace view `dbt_tutorial_prod`.`bronze`.`bronze_sales`
  
  as (
    SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`fact_sales`
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2d5e-1663-9938-b878ab55b2a5
[0m17:44:36.550503 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_sales: Close
[0m17:44:36.550503 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2d53-1d50-828f-303d6958d7ae) - Closing
[0m17:44:36.641452 [debug] [Thread-1 (]: Database Error in model bronze_sales (models\bronze\bronze_sales.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_sales.sql
[0m17:44:36.642466 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDDCAC1D0>]}
[0m17:44:36.643467 [error] [Thread-1 (]: 5 of 18 ERROR creating sql view model bronze.bronze_sales ...................... [[31mERROR[0m in 0.57s]
[0m17:44:36.644462 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_sales
[0m17:44:36.644462 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.bronze_store
[0m17:44:36.645463 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_sales' to be skipped because of status 'error'.  Reason: Database Error in model bronze_sales (models\bronze\bronze_sales.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_sales.sql.
[0m17:44:36.645463 [info ] [Thread-1 (]: 6 of 18 START sql table model bronze.bronze_store .............................. [RUN]
[0m17:44:36.646467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.bronze_store) - Creating connection
[0m17:44:36.647789 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.bronze_store'
[0m17:44:36.647789 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.bronze_store
[0m17:44:36.651294 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.bronze_store"
[0m17:44:36.652304 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.bronze_store
[0m17:44:36.655308 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:44:36.656309 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.bronze_store"
[0m17:44:36.656309 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.bronze_store"
[0m17:44:36.657309 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_store`
  
[0m17:44:36.657309 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:36.880104 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2dac-1bb2-aae3-e1fec533cb3b) - Created
[0m17:44:37.292724 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.bronze_store"} */

  
    
        create or replace table `dbt_tutorial_prod`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
    *
FROM 
    `dbt_tutorial_prod}`.`source`.`dim_store`
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2dbc-1446-9c42-ecad5696b5fe
[0m17:44:37.293742 [debug] [Thread-1 (]: On model.octy_dbt_learn.bronze_store: Close
[0m17:44:37.293742 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2dac-1bb2-aae3-e1fec533cb3b) - Closing
[0m17:44:37.374638 [debug] [Thread-1 (]: Database Error in model bronze_store (models\bronze\bronze_store.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_store.sql
[0m17:44:37.375638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDE17C4A0>]}
[0m17:44:37.376638 [error] [Thread-1 (]: 6 of 18 ERROR creating sql table model bronze.bronze_store ..................... [[31mERROR[0m in 0.73s]
[0m17:44:37.377638 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.bronze_store
[0m17:44:37.377638 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.source_gold_items
[0m17:44:37.378636 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.bronze_store' to be skipped because of status 'error'.  Reason: Database Error in model bronze_store (models\bronze\bronze_store.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_store.sql.
[0m17:44:37.378636 [info ] [Thread-1 (]: 7 of 18 START sql table model gold.source_gold_items ........................... [RUN]
[0m17:44:37.379651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.octy_dbt_learn.source_gold_items) - Creating connection
[0m17:44:37.379651 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.octy_dbt_learn.source_gold_items'
[0m17:44:37.381164 [debug] [Thread-1 (]: Began compiling node model.octy_dbt_learn.source_gold_items
[0m17:44:37.385179 [debug] [Thread-1 (]: Writing injected SQL for node "model.octy_dbt_learn.source_gold_items"
[0m17:44:37.385179 [debug] [Thread-1 (]: Began executing node model.octy_dbt_learn.source_gold_items
[0m17:44:37.388176 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m17:44:37.389176 [debug] [Thread-1 (]: Writing runtime sql for node "model.octy_dbt_learn.source_gold_items"
[0m17:44:37.390177 [debug] [Thread-1 (]: Using databricks connection "model.octy_dbt_learn.source_gold_items"
[0m17:44:37.390177 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.source_gold_items"} */

  
    
        create or replace table `dbt_tutorial_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH dedup_query AS (
    SELECT
        *,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY updateDate DESC) AS deduplication_id
    FROM 
        `dbt_tutorial_prod}`.`source`.`items`
)

SELECT
    id,
    name,
    category,
    updateDate
FROM
    dedup_query
WHERE
    deduplication_id = 1
  
[0m17:44:37.390177 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:37.576634 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2e1a-15c9-96f3-6c9afbdaa6fc) - Created
[0m17:44:38.024688 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "model.octy_dbt_learn.source_gold_items"} */

  
    
        create or replace table `dbt_tutorial_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      WITH dedup_query AS (
    SELECT
        *,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY updateDate DESC) AS deduplication_id
    FROM 
        `dbt_tutorial_prod}`.`source`.`items`
)

SELECT
    id,
    name,
    category,
    updateDate
FROM
    dedup_query
WHERE
    deduplication_id = 1
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1040)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:778)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:835)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:569)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:546)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:532)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:96)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1001)
	... 53 more
, operation-id=01f0b027-2e26-1e93-9e35-9b3e49b3e1db
[0m17:44:38.025732 [debug] [Thread-1 (]: On model.octy_dbt_learn.source_gold_items: Close
[0m17:44:38.026732 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2e1a-15c9-96f3-6c9afbdaa6fc) - Closing
[0m17:44:38.108980 [debug] [Thread-1 (]: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
  compiled code at target\run\octy_dbt_learn\models\gold\source_gold_items.sql
[0m17:44:38.108980 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BDE1A0080>]}
[0m17:44:38.110487 [error] [Thread-1 (]: 7 of 18 ERROR creating sql table model gold.source_gold_items .................. [[31mERROR[0m in 0.73s]
[0m17:44:38.110487 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.source_gold_items
[0m17:44:38.111492 [debug] [Thread-1 (]: Began running node seed.octy_dbt_learn.lookup
[0m17:44:38.111492 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.source_gold_items' to be skipped because of status 'error'.  Reason: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
  compiled code at target\run\octy_dbt_learn\models\gold\source_gold_items.sql.
[0m17:44:38.113028 [info ] [Thread-1 (]: 8 of 18 START seed file bronze.lookup .......................................... [RUN]
[0m17:44:38.114045 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.octy_dbt_learn.lookup) - Creating connection
[0m17:44:38.114045 [debug] [Thread-1 (]: Acquiring new databricks connection 'seed.octy_dbt_learn.lookup'
[0m17:44:38.114045 [debug] [Thread-1 (]: Began compiling node seed.octy_dbt_learn.lookup
[0m17:44:38.115092 [debug] [Thread-1 (]: Began executing node seed.octy_dbt_learn.lookup
[0m17:44:38.148902 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:44:38.149902 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: /* {"app": "dbt", "dbt_version": "1.10.13", "dbt_databricks_version": "1.10.14", "databricks_sql_connector_version": "4.0.5", "profile_name": "octy_dbt_learn", "target_name": "prod", "node_id": "seed.octy_dbt_learn.lookup"} */

    create  table `dbt_tutorial_prod`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m17:44:38.149902 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:44:38.339771 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2e8d-126e-87aa-50f8cf7195a0) - Created
[0m17:44:41.158004 [debug] [Thread-1 (]: SQL status: OK in 3.010 seconds
[0m17:44:41.159005 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b027-2e8d-126e-87aa-50f8cf7195a0, command-id=01f0b027-2e98-16e6-90cd-0b9d15bab3ea) - Closing
[0m17:44:41.173584 [debug] [Thread-1 (]: Using databricks connection "seed.octy_dbt_learn.lookup"
[0m17:44:41.174584 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: 
          insert overwrite `dbt_tutorial_prod`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m17:44:45.181694 [debug] [Thread-1 (]: SQL status: OK in 4.010 seconds
[0m17:44:45.181694 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0b027-2e8d-126e-87aa-50f8cf7195a0, command-id=01f0b027-3049-1c6c-942d-fec12d635d15) - Closing
[0m17:44:45.189093 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.octy_dbt_learn.lookup"
[0m17:44:45.202734 [debug] [Thread-1 (]: On seed.octy_dbt_learn.lookup: Close
[0m17:44:45.202734 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0b027-2e8d-126e-87aa-50f8cf7195a0) - Closing
[0m17:44:45.279536 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '972b4757-f840-462d-b0c7-d576298d4bf4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB5CD43E0>]}
[0m17:44:45.279536 [info ] [Thread-1 (]: 8 of 18 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 7.17s]
[0m17:44:45.280537 [debug] [Thread-1 (]: Finished running node seed.octy_dbt_learn.lookup
[0m17:44:45.281536 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:44:45.282042 [info ] [Thread-1 (]: 9 of 18 SKIP test generic_non_negative_bronze_sales_gross_amount ............... [[33mSKIP[0m]
[0m17:44:45.283047 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1
[0m17:44:45.283047 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.non_negative_test
[0m17:44:45.284051 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.generic_non_negative_bronze_sales_gross_amount.770bebc5b1' to be skipped because of status 'skipped'. 
[0m17:44:45.284051 [info ] [Thread-1 (]: 10 of 18 SKIP test non_negative_test ........................................... [[33mSKIP[0m]
[0m17:44:45.285097 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.non_negative_test
[0m17:44:45.285097 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:44:45.286144 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.non_negative_test' to be skipped because of status 'skipped'. 
[0m17:44:45.286144 [info ] [Thread-1 (]: 11 of 18 SKIP test not_null_bronze_sales_sales_id .............................. [[33mSKIP[0m]
[0m17:44:45.287166 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb
[0m17:44:45.287166 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:44:45.288166 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.not_null_bronze_sales_sales_id.e4b1b997fb' to be skipped because of status 'skipped'. 
[0m17:44:45.288166 [info ] [Thread-1 (]: 12 of 18 SKIP test unique_bronze_sales_sales_id ................................ [[33mSKIP[0m]
[0m17:44:45.288166 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d
[0m17:44:45.289538 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:44:45.289538 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.unique_bronze_sales_sales_id.3c35aa753d' to be skipped because of status 'skipped'. 
[0m17:44:45.290537 [info ] [Thread-1 (]: 13 of 18 SKIP test accepted_values_bronze_store_country__USA__Canada ........... [[33mSKIP[0m]
[0m17:44:45.291537 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7
[0m17:44:45.291537 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:44:45.292044 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.accepted_values_bronze_store_country__USA__Canada.bdac5920b7' to be skipped because of status 'skipped'. 
[0m17:44:45.292044 [info ] [Thread-1 (]: 14 of 18 SKIP test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mSKIP[0m]
[0m17:44:45.293058 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m17:44:45.294056 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:44:45.294056 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159' to be skipped because of status 'skipped'. 
[0m17:44:45.294056 [info ] [Thread-1 (]: 15 of 18 SKIP test not_null_bronze_store_store_sk .............................. [[33mSKIP[0m]
[0m17:44:45.295051 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a
[0m17:44:45.295051 [debug] [Thread-1 (]: Began running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:44:45.295051 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.not_null_bronze_store_store_sk.ffdb44062a' to be skipped because of status 'skipped'. 
[0m17:44:45.296173 [info ] [Thread-1 (]: 16 of 18 SKIP test unique_bronze_store_store_sk ................................ [[33mSKIP[0m]
[0m17:44:45.296173 [debug] [Thread-1 (]: Finished running node test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63
[0m17:44:45.297175 [debug] [Thread-1 (]: Began running node snapshot.octy_dbt_learn.gold_items
[0m17:44:45.297175 [debug] [Thread-4 (]: Marking all children of 'test.octy_dbt_learn.unique_bronze_store_store_sk.cd37333b63' to be skipped because of status 'skipped'. 
[0m17:44:45.297175 [info ] [Thread-1 (]: 17 of 18 SKIP relation gold.gold_items ......................................... [[33mSKIP[0m]
[0m17:44:45.298174 [debug] [Thread-1 (]: Finished running node snapshot.octy_dbt_learn.gold_items
[0m17:44:45.298174 [debug] [Thread-1 (]: Began running node model.octy_dbt_learn.silver_sales_info
[0m17:44:45.298174 [debug] [Thread-4 (]: Marking all children of 'snapshot.octy_dbt_learn.gold_items' to be skipped because of status 'skipped'. 
[0m17:44:45.299173 [info ] [Thread-1 (]: 18 of 18 SKIP relation silver.silver_sales_info ................................ [[33mSKIP[0m]
[0m17:44:45.299173 [debug] [Thread-1 (]: Finished running node model.octy_dbt_learn.silver_sales_info
[0m17:44:45.300187 [debug] [Thread-4 (]: Marking all children of 'model.octy_dbt_learn.silver_sales_info' to be skipped because of status 'skipped'. 
[0m17:44:45.301700 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:44:45.301700 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:44:45.301700 [info ] [MainThread]: 
[0m17:44:45.302732 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 8 data tests, 3 view models in 0 hours 0 minutes and 19.64 seconds (19.64s).
[0m17:44:45.303731 [debug] [MainThread]: Command end result
[0m17:44:45.468090 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\manifest.json
[0m17:44:45.470091 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\semantic_manifest.json
[0m17:44:45.476715 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Projects\DBT_TUTORIAL\octy_dbt_learn\target\run_results.json
[0m17:44:45.476715 [info ] [MainThread]: 
[0m17:44:45.476715 [info ] [MainThread]: [31mCompleted with 7 errors, 0 partial successes, and 0 warnings:[0m
[0m17:44:45.477753 [info ] [MainThread]: 
[0m17:44:45.477753 [error] [MainThread]: [31mFailure in model bronze_customer (models\bronze\bronze_customer.sql)[0m
[0m17:44:45.478752 [error] [MainThread]:   Database Error in model bronze_customer (models\bronze\bronze_customer.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_customer.sql
[0m17:44:45.478752 [info ] [MainThread]: 
[0m17:44:45.478752 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_customer.sql
[0m17:44:45.479755 [info ] [MainThread]: 
[0m17:44:45.479755 [error] [MainThread]: [31mFailure in model bronze_date (models\bronze\bronze_date.sql)[0m
[0m17:44:45.479755 [error] [MainThread]:   Database Error in model bronze_date (models\bronze\bronze_date.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_date` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_date.sql
[0m17:44:45.481111 [info ] [MainThread]: 
[0m17:44:45.481614 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_date.sql
[0m17:44:45.481614 [info ] [MainThread]: 
[0m17:44:45.481614 [error] [MainThread]: [31mFailure in model bronze_product (models\bronze\bronze_product.sql)[0m
[0m17:44:45.482646 [error] [MainThread]:   Database Error in model bronze_product (models\bronze\bronze_product.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_product` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_product.sql
[0m17:44:45.482646 [info ] [MainThread]: 
[0m17:44:45.483649 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_product.sql
[0m17:44:45.483649 [info ] [MainThread]: 
[0m17:44:45.484683 [error] [MainThread]: [31mFailure in model bronze_returns (models\bronze\bronze_returns.sql)[0m
[0m17:44:45.484683 [error] [MainThread]:   Database Error in model bronze_returns (models\bronze\bronze_returns.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_returns` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_returns.sql
[0m17:44:45.484683 [info ] [MainThread]: 
[0m17:44:45.485724 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_returns.sql
[0m17:44:45.485724 [info ] [MainThread]: 
[0m17:44:45.486738 [error] [MainThread]: [31mFailure in model bronze_sales (models\bronze\bronze_sales.sql)[0m
[0m17:44:45.486738 [error] [MainThread]:   Database Error in model bronze_sales (models\bronze\bronze_sales.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`fact_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 11 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_sales.sql
[0m17:44:45.486738 [info ] [MainThread]: 
[0m17:44:45.487952 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_sales.sql
[0m17:44:45.487952 [info ] [MainThread]: 
[0m17:44:45.487952 [error] [MainThread]: [31mFailure in model bronze_store (models\bronze\bronze_store.sql)[0m
[0m17:44:45.488957 [error] [MainThread]:   Database Error in model bronze_store (models\bronze\bronze_store.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`dim_store` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 4
  compiled code at target\run\octy_dbt_learn\models\bronze\bronze_store.sql
[0m17:44:45.488957 [info ] [MainThread]: 
[0m17:44:45.489952 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\bronze\bronze_store.sql
[0m17:44:45.489952 [info ] [MainThread]: 
[0m17:44:45.489952 [error] [MainThread]: [31mFailure in model source_gold_items (models\gold\source_gold_items.sql)[0m
[0m17:44:45.489952 [error] [MainThread]:   Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_tutorial_prod}`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 22 pos 8
  compiled code at target\run\octy_dbt_learn\models\gold\source_gold_items.sql
[0m17:44:45.491807 [info ] [MainThread]: 
[0m17:44:45.491807 [info ] [MainThread]:   compiled code at target\compiled\octy_dbt_learn\models\gold\source_gold_items.sql
[0m17:44:45.491807 [info ] [MainThread]: 
[0m17:44:45.492947 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=7 SKIP=10 NO-OP=0 TOTAL=18
[0m17:44:45.493968 [debug] [MainThread]: Command `dbt build` failed at 17:44:45.492947 after 24.52 seconds
[0m17:44:45.493968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB4C65640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB6079760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019BB8153EC0>]}
[0m17:44:45.493968 [debug] [MainThread]: Flushing usage events
[0m17:44:46.257092 [debug] [MainThread]: An error was encountered while trying to flush usage events
